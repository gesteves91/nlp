{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciando com Word2Vec com Gensim!\n",
    "  \n",
    "A ideia por trás do Word2Vec é bem simples. Estamos supondo que você pode inferir o significado de uma palavra pela composição que ela mantém. Isso é análogo ao ditado popular \"mostre-me seus amigos e eu direi quem você é\". Então, se você tem duas palavras que têm vizinhos muito semelhantes (ou seja, o contexto de uso é aproximadamente o mesmo), então essas palavras são provavelmente muito semelhantes em significado ou pelo menos altamente relacionadas. Por exemplo, as palavras em inglês `shocked`,` appalled` e `astonished` são tipicamente usadas em um contexto similar.\n",
    "\n",
    "A implementação do Gensim é baseada no artigo [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) e foi extendido com funcionalidades novas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports e logging\n",
    "\n",
    "Primeiro, começamos com os imports e o logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports necessários para configurar o logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Em seguida, manipularemos nosso conjunto de dados. O segredo para fazer o Word2Vec funcionar é ter muitos dados no formato de texto. Neste caso, uma boa base de dados pode ser encontrada no seguinte link: [OpinRank] (http://kavita-ganesan.com/entity-ranking-data/). Este conjunto de dados tem avaliações completas de usuários de carros e hotéis. Eu concatenei especificamente todas as avaliações de hotéis em um arquivo grande que é de cerca de 97MB comprimido e 229MB não compactado. Vamos usar o arquivo compactado. Cada linha neste arquivo representa uma resenha do hotel. Você pode fazer o download do conjunto de dados do Word2Vec do OpinRank aqui.\n",
    "\n",
    "Agora, vamos dar uma olhada mais de perto nesses dados, imprimindo a primeira linha. Você pode ver que esta é uma revisão bastante robusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file = \"data/reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open ('data/reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler os arquivos dentro de listas\n",
    "Agora que tivemos uma ideia do nosso conjunto de dados, podemos lê-lo em uma lista para que possamos passar isso para o modelo Word2Vec. Observe no código abaixo, que estou lendo diretamente o arquivo compactado. Também estamos fazendo um pré-processamento moderado das revisões usando `gensim.utils.simple_preprocess (line)`. Isso faz um pré-processamento básico, como tokenização, letras minúsculas, etc, e retorna uma lista de tokens (palavras). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 16:59:57,634 : INFO : lendo arquivo data/reviews_data.txt.gz...esse processo pode demorar\n",
      "2019-07-14 16:59:57,636 : INFO : lido 0 revisoes\n",
      "2019-07-14 16:59:58,963 : INFO : lido 10000 revisoes\n",
      "2019-07-14 17:00:01,041 : INFO : lido 20000 revisoes\n",
      "2019-07-14 17:00:02,569 : INFO : lido 30000 revisoes\n",
      "2019-07-14 17:00:03,980 : INFO : lido 40000 revisoes\n",
      "2019-07-14 17:00:05,524 : INFO : lido 50000 revisoes\n",
      "2019-07-14 17:00:07,021 : INFO : lido 60000 revisoes\n",
      "2019-07-14 17:00:08,291 : INFO : lido 70000 revisoes\n",
      "2019-07-14 17:00:09,458 : INFO : lido 80000 revisoes\n",
      "2019-07-14 17:00:10,691 : INFO : lido 90000 revisoes\n",
      "2019-07-14 17:00:11,872 : INFO : lido 100000 revisoes\n",
      "2019-07-14 17:00:14,005 : INFO : lido 110000 revisoes\n",
      "2019-07-14 17:00:15,181 : INFO : lido 120000 revisoes\n",
      "2019-07-14 17:00:16,379 : INFO : lido 130000 revisoes\n",
      "2019-07-14 17:00:17,678 : INFO : lido 140000 revisoes\n",
      "2019-07-14 17:00:18,860 : INFO : lido 150000 revisoes\n",
      "2019-07-14 17:00:20,077 : INFO : lido 160000 revisoes\n",
      "2019-07-14 17:00:21,270 : INFO : lido 170000 revisoes\n",
      "2019-07-14 17:00:22,542 : INFO : lido 180000 revisoes\n",
      "2019-07-14 17:00:23,779 : INFO : lido 190000 revisoes\n",
      "2019-07-14 17:00:25,114 : INFO : lido 200000 revisoes\n",
      "2019-07-14 17:00:26,390 : INFO : lido 210000 revisoes\n",
      "2019-07-14 17:00:27,685 : INFO : lido 220000 revisoes\n",
      "2019-07-14 17:00:30,111 : INFO : lido 230000 revisoes\n",
      "2019-07-14 17:00:31,366 : INFO : lido 240000 revisoes\n",
      "2019-07-14 17:00:32,597 : INFO : lido 250000 revisoes\n",
      "2019-07-14 17:00:33,797 : INFO : Terminado de ler os arquivos\n"
     ]
    }
   ],
   "source": [
    "def read_input(input_file):\n",
    "    \"\"\"Esse método lê o arquivo de entrada no formato gzip\"\"\"\n",
    "    \n",
    "    logging.info(\"lendo arquivo {0}...esse processo pode demorar\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"lido {0} revisoes\".format (i))\n",
    "            # feito alguns pre-processamentos e retorna uma lista de palavras\n",
    "            # para cada revisão no formato texto\n",
    "            yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "# ler uma revisão tokenizada em uma lista\n",
    "# cada revisão se torna um série de palavras \n",
    "# então isso se torna uma lista de listas\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Terminado de ler os arquivos\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do modelo Word2Vec\n",
    "\n",
    "Treinar o modelo é bastante simples. Você apenas instancia o Word2Vec e passa os comentários que lemos na etapa anterior (os `documentos`). Então, estamos essencialmente passando uma lista de listas. Onde cada lista na lista principal contém um conjunto de tokens de uma revisão do usuário. O Word2Vec usa todos esses tokens para criar internamente um vocabulário. E por vocabulário, quero dizer um conjunto de palavras únicas.\n",
    "\n",
    "Depois de construir o vocabulário, só precisamos chamar `train(...)` para começar a treinar o modelo Word2Vec. O treinamento no conjunto de dados [OpinRank] (http://kavita-ganesan.com/entity-ranking-data/) leva cerca de 10 minutos, portanto, seja paciente ao executar seu código neste conjunto de dados.\n",
    "\n",
    "Nos bastidores, na verdade, estamos treinando uma rede neural simples com uma única camada oculta. Mas, na verdade, não vamos usar a rede neural após o treinamento. Em vez disso, o objetivo é aprender os pesos da camada oculta. Esses pesos são essencialmente os vetores de palavras que estamos tentando aprender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 17:05:48,958 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-07-14 17:05:48,959 : INFO : collecting all words and their counts\n",
      "2019-07-14 17:05:48,960 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-07-14 17:05:49,156 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2019-07-14 17:05:49,330 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2019-07-14 17:05:49,538 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2019-07-14 17:05:49,738 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2019-07-14 17:05:49,952 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2019-07-14 17:05:50,172 : INFO : PROGRESS: at sentence #60000, processed 11013726 words, keeping 76786 word types\n",
      "2019-07-14 17:05:50,438 : INFO : PROGRESS: at sentence #70000, processed 12637528 words, keeping 83199 word types\n",
      "2019-07-14 17:05:50,692 : INFO : PROGRESS: at sentence #80000, processed 14099754 words, keeping 88459 word types\n",
      "2019-07-14 17:05:50,863 : INFO : PROGRESS: at sentence #90000, processed 15662152 words, keeping 93357 word types\n",
      "2019-07-14 17:05:51,030 : INFO : PROGRESS: at sentence #100000, processed 17164490 words, keeping 97886 word types\n",
      "2019-07-14 17:05:51,334 : INFO : PROGRESS: at sentence #110000, processed 18652295 words, keeping 102132 word types\n",
      "2019-07-14 17:05:51,637 : INFO : PROGRESS: at sentence #120000, processed 20152532 words, keeping 105923 word types\n",
      "2019-07-14 17:05:51,805 : INFO : PROGRESS: at sentence #130000, processed 21684333 words, keeping 110104 word types\n",
      "2019-07-14 17:05:51,997 : INFO : PROGRESS: at sentence #140000, processed 23330209 words, keeping 114108 word types\n",
      "2019-07-14 17:05:52,235 : INFO : PROGRESS: at sentence #150000, processed 24838757 words, keeping 118174 word types\n",
      "2019-07-14 17:05:52,498 : INFO : PROGRESS: at sentence #160000, processed 26390913 words, keeping 118670 word types\n",
      "2019-07-14 17:05:52,752 : INFO : PROGRESS: at sentence #170000, processed 27913919 words, keeping 123356 word types\n",
      "2019-07-14 17:05:53,015 : INFO : PROGRESS: at sentence #180000, processed 29535615 words, keeping 126748 word types\n",
      "2019-07-14 17:05:53,235 : INFO : PROGRESS: at sentence #190000, processed 31096462 words, keeping 129847 word types\n",
      "2019-07-14 17:05:53,510 : INFO : PROGRESS: at sentence #200000, processed 32805274 words, keeping 133255 word types\n",
      "2019-07-14 17:05:53,738 : INFO : PROGRESS: at sentence #210000, processed 34434201 words, keeping 136364 word types\n",
      "2019-07-14 17:05:53,990 : INFO : PROGRESS: at sentence #220000, processed 36083485 words, keeping 139418 word types\n",
      "2019-07-14 17:05:54,184 : INFO : PROGRESS: at sentence #230000, processed 37571765 words, keeping 142399 word types\n",
      "2019-07-14 17:05:54,414 : INFO : PROGRESS: at sentence #240000, processed 39138193 words, keeping 145232 word types\n",
      "2019-07-14 17:05:54,625 : INFO : PROGRESS: at sentence #250000, processed 40695052 words, keeping 147966 word types\n",
      "2019-07-14 17:05:54,742 : INFO : collected 150059 word types from a corpus of 41519358 raw words and 255404 sentences\n",
      "2019-07-14 17:05:54,742 : INFO : Loading a fresh vocabulary\n",
      "2019-07-14 17:05:54,894 : INFO : effective_min_count=2 retains 70537 unique words (47% of original 150059, drops 79522)\n",
      "2019-07-14 17:05:54,894 : INFO : effective_min_count=2 leaves 41439836 word corpus (99% of original 41519358, drops 79522)\n",
      "2019-07-14 17:05:55,084 : INFO : deleting the raw counts dictionary of 150059 items\n",
      "2019-07-14 17:05:55,092 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2019-07-14 17:05:55,093 : INFO : downsampling leaves estimated 30349251 word corpus (73.2% of prior 41439836)\n",
      "2019-07-14 17:05:55,368 : INFO : estimated required memory for 70537 words and 150 dimensions: 119912900 bytes\n",
      "2019-07-14 17:05:55,368 : INFO : resetting layer weights\n",
      "2019-07-14 17:05:56,043 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-07-14 17:05:57,048 : INFO : EPOCH 1 - PROGRESS: at 2.67% examples, 836193 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:05:58,059 : INFO : EPOCH 1 - PROGRESS: at 5.52% examples, 845938 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:05:59,062 : INFO : EPOCH 1 - PROGRESS: at 9.13% examples, 943559 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:00,065 : INFO : EPOCH 1 - PROGRESS: at 12.45% examples, 1022809 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 17:06:01,079 : INFO : EPOCH 1 - PROGRESS: at 16.18% examples, 1067691 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:02,082 : INFO : EPOCH 1 - PROGRESS: at 19.59% examples, 1101881 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:03,083 : INFO : EPOCH 1 - PROGRESS: at 24.90% examples, 1216603 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:04,091 : INFO : EPOCH 1 - PROGRESS: at 30.11% examples, 1242609 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:05,094 : INFO : EPOCH 1 - PROGRESS: at 37.05% examples, 1322697 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:06,100 : INFO : EPOCH 1 - PROGRESS: at 43.80% examples, 1376590 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:07,108 : INFO : EPOCH 1 - PROGRESS: at 48.89% examples, 1380851 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:08,113 : INFO : EPOCH 1 - PROGRESS: at 52.10% examples, 1343888 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:09,115 : INFO : EPOCH 1 - PROGRESS: at 55.87% examples, 1325326 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:10,117 : INFO : EPOCH 1 - PROGRESS: at 59.79% examples, 1312101 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:11,123 : INFO : EPOCH 1 - PROGRESS: at 63.73% examples, 1298507 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:12,130 : INFO : EPOCH 1 - PROGRESS: at 67.76% examples, 1290388 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:06:13,136 : INFO : EPOCH 1 - PROGRESS: at 71.63% examples, 1283990 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:14,146 : INFO : EPOCH 1 - PROGRESS: at 75.50% examples, 1275254 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:15,150 : INFO : EPOCH 1 - PROGRESS: at 78.88% examples, 1264676 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:06:16,153 : INFO : EPOCH 1 - PROGRESS: at 82.26% examples, 1252454 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:17,159 : INFO : EPOCH 1 - PROGRESS: at 85.37% examples, 1238745 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:18,177 : INFO : EPOCH 1 - PROGRESS: at 89.23% examples, 1230340 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:19,189 : INFO : EPOCH 1 - PROGRESS: at 92.67% examples, 1219241 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:06:20,199 : INFO : EPOCH 1 - PROGRESS: at 96.16% examples, 1211042 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:21,215 : INFO : EPOCH 1 - PROGRESS: at 99.78% examples, 1203363 words/s, in_qsize 9, out_qsize 1\n",
      "2019-07-14 17:06:21,223 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:06:21,232 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:06:21,233 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:06:21,234 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:06:21,237 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:06:21,240 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:06:21,248 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:06:21,259 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:06:21,261 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:06:21,263 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:06:21,263 : INFO : EPOCH - 1 : training on 41519358 raw words (30347415 effective words) took 25.2s, 1203465 effective words/s\n",
      "2019-07-14 17:06:22,284 : INFO : EPOCH 2 - PROGRESS: at 3.23% examples, 988802 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 17:06:23,287 : INFO : EPOCH 2 - PROGRESS: at 6.21% examples, 950340 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:06:24,292 : INFO : EPOCH 2 - PROGRESS: at 9.56% examples, 991095 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:25,292 : INFO : EPOCH 2 - PROGRESS: at 12.40% examples, 1016253 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:26,298 : INFO : EPOCH 2 - PROGRESS: at 15.67% examples, 1029617 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:06:27,303 : INFO : EPOCH 2 - PROGRESS: at 18.69% examples, 1043031 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:28,308 : INFO : EPOCH 2 - PROGRESS: at 21.79% examples, 1049385 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:29,310 : INFO : EPOCH 2 - PROGRESS: at 24.60% examples, 1054682 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:30,328 : INFO : EPOCH 2 - PROGRESS: at 28.61% examples, 1055716 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:31,351 : INFO : EPOCH 2 - PROGRESS: at 32.59% examples, 1057977 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:06:32,358 : INFO : EPOCH 2 - PROGRESS: at 36.35% examples, 1060285 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:33,358 : INFO : EPOCH 2 - PROGRESS: at 40.21% examples, 1062599 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:34,364 : INFO : EPOCH 2 - PROGRESS: at 43.91% examples, 1058591 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:35,379 : INFO : EPOCH 2 - PROGRESS: at 47.21% examples, 1048751 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:36,406 : INFO : EPOCH 2 - PROGRESS: at 49.95% examples, 1028985 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 17:06:37,412 : INFO : EPOCH 2 - PROGRESS: at 52.60% examples, 1013846 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:06:38,424 : INFO : EPOCH 2 - PROGRESS: at 55.14% examples, 998294 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:39,440 : INFO : EPOCH 2 - PROGRESS: at 57.97% examples, 987401 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:06:40,441 : INFO : EPOCH 2 - PROGRESS: at 60.95% examples, 980452 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 17:06:41,458 : INFO : EPOCH 2 - PROGRESS: at 64.01% examples, 973267 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:42,460 : INFO : EPOCH 2 - PROGRESS: at 67.27% examples, 972639 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:43,461 : INFO : EPOCH 2 - PROGRESS: at 69.86% examples, 964110 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:44,462 : INFO : EPOCH 2 - PROGRESS: at 72.63% examples, 958877 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:45,473 : INFO : EPOCH 2 - PROGRESS: at 75.27% examples, 950646 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:46,487 : INFO : EPOCH 2 - PROGRESS: at 77.82% examples, 944945 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:47,491 : INFO : EPOCH 2 - PROGRESS: at 80.34% examples, 938192 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:48,503 : INFO : EPOCH 2 - PROGRESS: at 83.80% examples, 941909 words/s, in_qsize 19, out_qsize 1\n",
      "2019-07-14 17:06:49,507 : INFO : EPOCH 2 - PROGRESS: at 87.88% examples, 950726 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:50,517 : INFO : EPOCH 2 - PROGRESS: at 92.21% examples, 959854 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:51,522 : INFO : EPOCH 2 - PROGRESS: at 95.72% examples, 962372 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:52,522 : INFO : EPOCH 2 - PROGRESS: at 99.02% examples, 962199 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:06:52,753 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:06:52,761 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:06:52,773 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:06:52,775 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:06:52,777 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:06:52,778 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:06:52,788 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:06:52,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:06:52,796 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:06:52,804 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:06:52,805 : INFO : EPOCH - 2 : training on 41519358 raw words (30349296 effective words) took 31.5s, 962382 effective words/s\n",
      "2019-07-14 17:06:53,824 : INFO : EPOCH 3 - PROGRESS: at 2.66% examples, 825870 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:54,843 : INFO : EPOCH 3 - PROGRESS: at 5.59% examples, 848507 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:06:55,843 : INFO : EPOCH 3 - PROGRESS: at 8.48% examples, 865013 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:56,862 : INFO : EPOCH 3 - PROGRESS: at 11.08% examples, 883321 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:57,874 : INFO : EPOCH 3 - PROGRESS: at 13.76% examples, 895838 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:06:58,878 : INFO : EPOCH 3 - PROGRESS: at 16.51% examples, 905474 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:06:59,895 : INFO : EPOCH 3 - PROGRESS: at 19.14% examples, 913476 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:07:00,905 : INFO : EPOCH 3 - PROGRESS: at 22.17% examples, 930349 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:01,906 : INFO : EPOCH 3 - PROGRESS: at 25.05% examples, 944892 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:02,921 : INFO : EPOCH 3 - PROGRESS: at 28.91% examples, 953640 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:07:03,926 : INFO : EPOCH 3 - PROGRESS: at 32.73% examples, 963360 words/s, in_qsize 18, out_qsize 2\n",
      "2019-07-14 17:07:04,940 : INFO : EPOCH 3 - PROGRESS: at 36.43% examples, 970915 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:05,955 : INFO : EPOCH 3 - PROGRESS: at 40.27% examples, 978736 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 17:07:06,956 : INFO : EPOCH 3 - PROGRESS: at 44.22% examples, 985921 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:07:07,973 : INFO : EPOCH 3 - PROGRESS: at 48.00% examples, 991019 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:08,989 : INFO : EPOCH 3 - PROGRESS: at 51.81% examples, 996406 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 17:07:10,006 : INFO : EPOCH 3 - PROGRESS: at 55.48% examples, 1000849 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:07:11,007 : INFO : EPOCH 3 - PROGRESS: at 59.19% examples, 1004943 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:12,015 : INFO : EPOCH 3 - PROGRESS: at 62.87% examples, 1008028 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:13,016 : INFO : EPOCH 3 - PROGRESS: at 66.65% examples, 1011422 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:07:14,038 : INFO : EPOCH 3 - PROGRESS: at 70.21% examples, 1013494 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:07:15,050 : INFO : EPOCH 3 - PROGRESS: at 74.04% examples, 1016969 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:07:16,052 : INFO : EPOCH 3 - PROGRESS: at 77.46% examples, 1020213 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:07:17,057 : INFO : EPOCH 3 - PROGRESS: at 80.96% examples, 1022744 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:07:18,070 : INFO : EPOCH 3 - PROGRESS: at 84.56% examples, 1025308 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:19,075 : INFO : EPOCH 3 - PROGRESS: at 88.29% examples, 1026635 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:20,086 : INFO : EPOCH 3 - PROGRESS: at 92.18% examples, 1028875 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:21,091 : INFO : EPOCH 3 - PROGRESS: at 95.79% examples, 1030088 words/s, in_qsize 17, out_qsize 1\n",
      "2019-07-14 17:07:22,099 : INFO : EPOCH 3 - PROGRESS: at 99.56% examples, 1032018 words/s, in_qsize 17, out_qsize 0\n",
      "2019-07-14 17:07:22,153 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:07:22,155 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:07:22,171 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:07:22,172 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:07:22,176 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 17:07:22,178 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:07:22,186 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:07:22,187 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:07:22,188 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:07:22,201 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:07:22,202 : INFO : EPOCH - 3 : training on 41519358 raw words (30345701 effective words) took 29.4s, 1032466 effective words/s\n",
      "2019-07-14 17:07:23,209 : INFO : EPOCH 4 - PROGRESS: at 3.36% examples, 1044977 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:07:24,210 : INFO : EPOCH 4 - PROGRESS: at 6.94% examples, 1065981 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:25,216 : INFO : EPOCH 4 - PROGRESS: at 10.14% examples, 1075075 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:26,216 : INFO : EPOCH 4 - PROGRESS: at 13.14% examples, 1079595 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:27,217 : INFO : EPOCH 4 - PROGRESS: at 16.31% examples, 1082609 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:28,222 : INFO : EPOCH 4 - PROGRESS: at 19.21% examples, 1080908 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:29,223 : INFO : EPOCH 4 - PROGRESS: at 22.34% examples, 1082963 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:07:30,240 : INFO : EPOCH 4 - PROGRESS: at 25.36% examples, 1081245 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:31,240 : INFO : EPOCH 4 - PROGRESS: at 29.36% examples, 1082191 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:32,253 : INFO : EPOCH 4 - PROGRESS: at 33.18% examples, 1078570 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:07:33,257 : INFO : EPOCH 4 - PROGRESS: at 36.89% examples, 1078717 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:34,261 : INFO : EPOCH 4 - PROGRESS: at 40.76% examples, 1079698 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:07:35,265 : INFO : EPOCH 4 - PROGRESS: at 44.92% examples, 1082216 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:07:36,273 : INFO : EPOCH 4 - PROGRESS: at 48.60% examples, 1080992 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:07:37,274 : INFO : EPOCH 4 - PROGRESS: at 52.33% examples, 1081183 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:38,276 : INFO : EPOCH 4 - PROGRESS: at 55.93% examples, 1079407 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:39,281 : INFO : EPOCH 4 - PROGRESS: at 59.70% examples, 1079726 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:40,292 : INFO : EPOCH 4 - PROGRESS: at 63.47% examples, 1079055 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:07:41,294 : INFO : EPOCH 4 - PROGRESS: at 67.16% examples, 1078411 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:42,298 : INFO : EPOCH 4 - PROGRESS: at 70.74% examples, 1078975 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:43,305 : INFO : EPOCH 4 - PROGRESS: at 74.47% examples, 1078720 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:44,310 : INFO : EPOCH 4 - PROGRESS: at 77.85% examples, 1078510 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:45,316 : INFO : EPOCH 4 - PROGRESS: at 81.32% examples, 1078008 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:07:46,322 : INFO : EPOCH 4 - PROGRESS: at 84.95% examples, 1079256 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:47,332 : INFO : EPOCH 4 - PROGRESS: at 88.83% examples, 1079235 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 17:07:48,345 : INFO : EPOCH 4 - PROGRESS: at 92.67% examples, 1079718 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:07:49,358 : INFO : EPOCH 4 - PROGRESS: at 96.35% examples, 1079297 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 17:07:50,259 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:07:50,261 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:07:50,279 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:07:50,288 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:07:50,289 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:07:50,297 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:07:50,298 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:07:50,303 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:07:50,313 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:07:50,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:07:50,316 : INFO : EPOCH - 4 : training on 41519358 raw words (30351386 effective words) took 28.1s, 1079794 effective words/s\n",
      "2019-07-14 17:07:51,322 : INFO : EPOCH 5 - PROGRESS: at 3.34% examples, 1038388 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:52,351 : INFO : EPOCH 5 - PROGRESS: at 6.96% examples, 1054952 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:07:53,360 : INFO : EPOCH 5 - PROGRESS: at 10.17% examples, 1068891 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:54,362 : INFO : EPOCH 5 - PROGRESS: at 13.14% examples, 1070970 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:55,363 : INFO : EPOCH 5 - PROGRESS: at 16.27% examples, 1072742 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:56,368 : INFO : EPOCH 5 - PROGRESS: at 19.18% examples, 1072613 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:57,369 : INFO : EPOCH 5 - PROGRESS: at 22.22% examples, 1071693 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:58,370 : INFO : EPOCH 5 - PROGRESS: at 25.19% examples, 1072527 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:07:59,382 : INFO : EPOCH 5 - PROGRESS: at 29.12% examples, 1070692 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:00,386 : INFO : EPOCH 5 - PROGRESS: at 33.00% examples, 1070586 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:01,394 : INFO : EPOCH 5 - PROGRESS: at 36.66% examples, 1069745 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:08:02,397 : INFO : EPOCH 5 - PROGRESS: at 40.47% examples, 1070933 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:03,404 : INFO : EPOCH 5 - PROGRESS: at 44.54% examples, 1072342 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:04,406 : INFO : EPOCH 5 - PROGRESS: at 48.15% examples, 1070202 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:05,416 : INFO : EPOCH 5 - PROGRESS: at 51.90% examples, 1070061 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:08:06,418 : INFO : EPOCH 5 - PROGRESS: at 55.54% examples, 1070714 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:07,424 : INFO : EPOCH 5 - PROGRESS: at 59.23% examples, 1070210 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:08,430 : INFO : EPOCH 5 - PROGRESS: at 62.97% examples, 1070793 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:09,435 : INFO : EPOCH 5 - PROGRESS: at 66.82% examples, 1071954 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:10,439 : INFO : EPOCH 5 - PROGRESS: at 70.31% examples, 1071026 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:08:11,445 : INFO : EPOCH 5 - PROGRESS: at 74.15% examples, 1072617 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:12,445 : INFO : EPOCH 5 - PROGRESS: at 77.48% examples, 1072312 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:13,465 : INFO : EPOCH 5 - PROGRESS: at 81.11% examples, 1073535 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:08:14,467 : INFO : EPOCH 5 - PROGRESS: at 84.67% examples, 1074287 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:15,474 : INFO : EPOCH 5 - PROGRESS: at 88.07% examples, 1069621 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 17:08:16,478 : INFO : EPOCH 5 - PROGRESS: at 90.77% examples, 1057588 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:17,496 : INFO : EPOCH 5 - PROGRESS: at 93.79% examples, 1050906 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:18,497 : INFO : EPOCH 5 - PROGRESS: at 96.44% examples, 1040735 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:08:19,508 : INFO : EPOCH 5 - PROGRESS: at 99.25% examples, 1032595 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:19,682 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:08:19,709 : INFO : worker thread finished; awaiting finish of 8 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 17:08:19,715 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:08:19,717 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:08:19,724 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:08:19,725 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:08:19,733 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:08:19,735 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:08:19,737 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:08:19,752 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:08:19,753 : INFO : EPOCH - 5 : training on 41519358 raw words (30350223 effective words) took 29.4s, 1031217 effective words/s\n",
      "2019-07-14 17:08:19,754 : INFO : training on a 207596790 raw words (151744021 effective words) took 143.7s, 1055904 effective words/s\n",
      "2019-07-14 17:08:19,756 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-07-14 17:08:19,757 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-07-14 17:08:20,766 : INFO : EPOCH 1 - PROGRESS: at 3.73% examples, 1150400 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:21,778 : INFO : EPOCH 1 - PROGRESS: at 7.50% examples, 1147590 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:22,791 : INFO : EPOCH 1 - PROGRESS: at 10.24% examples, 1081238 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:23,794 : INFO : EPOCH 1 - PROGRESS: at 12.51% examples, 1026278 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:08:24,810 : INFO : EPOCH 1 - PROGRESS: at 15.92% examples, 1046951 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:25,812 : INFO : EPOCH 1 - PROGRESS: at 19.26% examples, 1077754 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:26,818 : INFO : EPOCH 1 - PROGRESS: at 22.51% examples, 1085550 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:08:27,827 : INFO : EPOCH 1 - PROGRESS: at 25.85% examples, 1093328 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:28,830 : INFO : EPOCH 1 - PROGRESS: at 30.14% examples, 1102869 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:29,838 : INFO : EPOCH 1 - PROGRESS: at 34.51% examples, 1114368 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:30,843 : INFO : EPOCH 1 - PROGRESS: at 38.80% examples, 1123251 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:31,857 : INFO : EPOCH 1 - PROGRESS: at 43.11% examples, 1127973 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:32,870 : INFO : EPOCH 1 - PROGRESS: at 47.15% examples, 1127705 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:33,871 : INFO : EPOCH 1 - PROGRESS: at 51.40% examples, 1133912 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:34,875 : INFO : EPOCH 1 - PROGRESS: at 55.55% examples, 1140140 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:35,880 : INFO : EPOCH 1 - PROGRESS: at 59.77% examples, 1144876 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:36,887 : INFO : EPOCH 1 - PROGRESS: at 64.01% examples, 1147261 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:37,889 : INFO : EPOCH 1 - PROGRESS: at 68.10% examples, 1150400 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:38,911 : INFO : EPOCH 1 - PROGRESS: at 71.92% examples, 1151075 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:39,922 : INFO : EPOCH 1 - PROGRESS: at 75.86% examples, 1150519 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 17:08:40,930 : INFO : EPOCH 1 - PROGRESS: at 79.65% examples, 1152108 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:41,943 : INFO : EPOCH 1 - PROGRESS: at 83.61% examples, 1153437 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:42,953 : INFO : EPOCH 1 - PROGRESS: at 87.51% examples, 1153161 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:43,955 : INFO : EPOCH 1 - PROGRESS: at 91.66% examples, 1154097 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:44,959 : INFO : EPOCH 1 - PROGRESS: at 95.46% examples, 1152218 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:08:45,964 : INFO : EPOCH 1 - PROGRESS: at 99.25% examples, 1150165 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:46,089 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:08:46,095 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:08:46,098 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:08:46,101 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:08:46,106 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:08:46,108 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:08:46,113 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:08:46,115 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:08:46,119 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:08:46,124 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:08:46,125 : INFO : EPOCH - 1 : training on 41519358 raw words (30347496 effective words) took 26.4s, 1151161 effective words/s\n",
      "2019-07-14 17:08:47,141 : INFO : EPOCH 2 - PROGRESS: at 3.26% examples, 1000275 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 17:08:48,144 : INFO : EPOCH 2 - PROGRESS: at 6.47% examples, 992430 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:49,150 : INFO : EPOCH 2 - PROGRESS: at 9.58% examples, 995162 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:08:50,163 : INFO : EPOCH 2 - PROGRESS: at 12.16% examples, 992958 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:51,168 : INFO : EPOCH 2 - PROGRESS: at 15.75% examples, 1033720 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:52,185 : INFO : EPOCH 2 - PROGRESS: at 18.94% examples, 1056129 words/s, in_qsize 19, out_qsize 3\n",
      "2019-07-14 17:08:53,198 : INFO : EPOCH 2 - PROGRESS: at 22.03% examples, 1058740 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:08:54,205 : INFO : EPOCH 2 - PROGRESS: at 24.94% examples, 1061281 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:55,209 : INFO : EPOCH 2 - PROGRESS: at 29.04% examples, 1066260 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:56,213 : INFO : EPOCH 2 - PROGRESS: at 32.96% examples, 1067480 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:57,221 : INFO : EPOCH 2 - PROGRESS: at 36.70% examples, 1069534 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:08:58,230 : INFO : EPOCH 2 - PROGRESS: at 40.31% examples, 1064868 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:08:59,239 : INFO : EPOCH 2 - PROGRESS: at 44.35% examples, 1066515 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:00,243 : INFO : EPOCH 2 - PROGRESS: at 47.94% examples, 1064190 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:01,245 : INFO : EPOCH 2 - PROGRESS: at 51.43% examples, 1059868 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:02,260 : INFO : EPOCH 2 - PROGRESS: at 54.72% examples, 1055789 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:03,263 : INFO : EPOCH 2 - PROGRESS: at 58.54% examples, 1057178 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:09:04,271 : INFO : EPOCH 2 - PROGRESS: at 62.10% examples, 1055617 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 17:09:05,272 : INFO : EPOCH 2 - PROGRESS: at 66.13% examples, 1059424 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:09:06,278 : INFO : EPOCH 2 - PROGRESS: at 70.09% examples, 1066418 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:07,287 : INFO : EPOCH 2 - PROGRESS: at 74.19% examples, 1071813 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:08,293 : INFO : EPOCH 2 - PROGRESS: at 77.87% examples, 1076078 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:09,296 : INFO : EPOCH 2 - PROGRESS: at 81.74% examples, 1080729 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:09:10,298 : INFO : EPOCH 2 - PROGRESS: at 85.52% examples, 1084106 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:11,301 : INFO : EPOCH 2 - PROGRESS: at 89.54% examples, 1085375 words/s, in_qsize 19, out_qsize 1\n",
      "2019-07-14 17:09:12,305 : INFO : EPOCH 2 - PROGRESS: at 93.62% examples, 1089191 words/s, in_qsize 18, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 17:09:13,309 : INFO : EPOCH 2 - PROGRESS: at 97.89% examples, 1094631 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:13,758 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:09:13,762 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:09:13,772 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:09:13,773 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:09:13,778 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:09:13,786 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:09:13,790 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:09:13,792 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:09:13,792 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:09:13,797 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:09:13,798 : INFO : EPOCH - 2 : training on 41519358 raw words (30352379 effective words) took 27.7s, 1097045 effective words/s\n",
      "2019-07-14 17:09:14,811 : INFO : EPOCH 3 - PROGRESS: at 3.68% examples, 1131622 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:15,819 : INFO : EPOCH 3 - PROGRESS: at 7.58% examples, 1162816 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:09:16,839 : INFO : EPOCH 3 - PROGRESS: at 10.55% examples, 1113209 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:09:17,847 : INFO : EPOCH 3 - PROGRESS: at 13.79% examples, 1127223 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:09:18,863 : INFO : EPOCH 3 - PROGRESS: at 17.11% examples, 1130221 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:19,870 : INFO : EPOCH 3 - PROGRESS: at 19.89% examples, 1115289 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:20,873 : INFO : EPOCH 3 - PROGRESS: at 22.98% examples, 1109208 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:21,878 : INFO : EPOCH 3 - PROGRESS: at 26.32% examples, 1107640 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:22,901 : INFO : EPOCH 3 - PROGRESS: at 30.81% examples, 1119527 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:23,908 : INFO : EPOCH 3 - PROGRESS: at 35.13% examples, 1130784 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:24,911 : INFO : EPOCH 3 - PROGRESS: at 39.53% examples, 1140210 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:25,912 : INFO : EPOCH 3 - PROGRESS: at 43.93% examples, 1145352 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:26,920 : INFO : EPOCH 3 - PROGRESS: at 47.97% examples, 1145169 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:27,924 : INFO : EPOCH 3 - PROGRESS: at 52.21% examples, 1150362 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:28,929 : INFO : EPOCH 3 - PROGRESS: at 56.13% examples, 1150327 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:29,936 : INFO : EPOCH 3 - PROGRESS: at 60.07% examples, 1149749 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:30,948 : INFO : EPOCH 3 - PROGRESS: at 64.30% examples, 1150294 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:31,970 : INFO : EPOCH 3 - PROGRESS: at 68.42% examples, 1153526 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:32,974 : INFO : EPOCH 3 - PROGRESS: at 72.49% examples, 1157795 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:33,978 : INFO : EPOCH 3 - PROGRESS: at 76.53% examples, 1160815 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:34,989 : INFO : EPOCH 3 - PROGRESS: at 80.50% examples, 1163540 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:36,000 : INFO : EPOCH 3 - PROGRESS: at 84.30% examples, 1162766 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:09:37,005 : INFO : EPOCH 3 - PROGRESS: at 88.54% examples, 1165120 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:38,006 : INFO : EPOCH 3 - PROGRESS: at 92.80% examples, 1167595 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:09:39,012 : INFO : EPOCH 3 - PROGRESS: at 97.05% examples, 1170253 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:39,651 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:09:39,655 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:09:39,665 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:09:39,670 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:09:39,676 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:09:39,678 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:09:39,682 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:09:39,684 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:09:39,687 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:09:39,695 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:09:39,696 : INFO : EPOCH - 3 : training on 41519358 raw words (30348234 effective words) took 25.9s, 1172079 effective words/s\n",
      "2019-07-14 17:09:40,703 : INFO : EPOCH 4 - PROGRESS: at 3.85% examples, 1189436 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:41,710 : INFO : EPOCH 4 - PROGRESS: at 7.83% examples, 1206061 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:42,713 : INFO : EPOCH 4 - PROGRESS: at 10.76% examples, 1147827 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:43,721 : INFO : EPOCH 4 - PROGRESS: at 13.92% examples, 1144546 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:44,724 : INFO : EPOCH 4 - PROGRESS: at 17.05% examples, 1132630 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:45,748 : INFO : EPOCH 4 - PROGRESS: at 19.83% examples, 1115413 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:46,760 : INFO : EPOCH 4 - PROGRESS: at 23.14% examples, 1121210 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:47,770 : INFO : EPOCH 4 - PROGRESS: at 27.12% examples, 1134508 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:48,776 : INFO : EPOCH 4 - PROGRESS: at 31.62% examples, 1144565 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:49,780 : INFO : EPOCH 4 - PROGRESS: at 35.76% examples, 1151094 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:09:50,781 : INFO : EPOCH 4 - PROGRESS: at 40.19% examples, 1158913 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:51,793 : INFO : EPOCH 4 - PROGRESS: at 44.70% examples, 1163818 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:52,801 : INFO : EPOCH 4 - PROGRESS: at 48.70% examples, 1162335 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 17:09:53,808 : INFO : EPOCH 4 - PROGRESS: at 51.92% examples, 1145578 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:09:54,830 : INFO : EPOCH 4 - PROGRESS: at 55.57% examples, 1139778 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:55,841 : INFO : EPOCH 4 - PROGRESS: at 59.33% examples, 1135934 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:56,843 : INFO : EPOCH 4 - PROGRESS: at 63.18% examples, 1134290 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:57,849 : INFO : EPOCH 4 - PROGRESS: at 66.67% examples, 1126411 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 17:09:58,859 : INFO : EPOCH 4 - PROGRESS: at 70.06% examples, 1121089 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:09:59,861 : INFO : EPOCH 4 - PROGRESS: at 73.74% examples, 1117879 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:00,862 : INFO : EPOCH 4 - PROGRESS: at 77.31% examples, 1118459 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:01,865 : INFO : EPOCH 4 - PROGRESS: at 80.92% examples, 1118485 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:10:02,867 : INFO : EPOCH 4 - PROGRESS: at 84.87% examples, 1122301 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:03,873 : INFO : EPOCH 4 - PROGRESS: at 89.23% examples, 1126588 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:10:04,878 : INFO : EPOCH 4 - PROGRESS: at 93.28% examples, 1128618 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:05,887 : INFO : EPOCH 4 - PROGRESS: at 97.53% examples, 1131945 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:06,420 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:10:06,425 : INFO : worker thread finished; awaiting finish of 8 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 17:10:06,431 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:10:06,437 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:10:06,438 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:10:06,449 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:10:06,451 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:10:06,454 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:10:06,455 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:10:06,464 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:10:06,465 : INFO : EPOCH - 4 : training on 41519358 raw words (30351907 effective words) took 26.8s, 1134088 effective words/s\n",
      "2019-07-14 17:10:07,473 : INFO : EPOCH 5 - PROGRESS: at 3.90% examples, 1202361 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:08,484 : INFO : EPOCH 5 - PROGRESS: at 7.85% examples, 1206605 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:09,489 : INFO : EPOCH 5 - PROGRESS: at 11.31% examples, 1211823 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:10:10,496 : INFO : EPOCH 5 - PROGRESS: at 14.77% examples, 1214217 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:11,504 : INFO : EPOCH 5 - PROGRESS: at 18.21% examples, 1216027 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:10:12,506 : INFO : EPOCH 5 - PROGRESS: at 21.48% examples, 1205019 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:13,511 : INFO : EPOCH 5 - PROGRESS: at 24.64% examples, 1206679 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:14,518 : INFO : EPOCH 5 - PROGRESS: at 28.99% examples, 1201144 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:15,525 : INFO : EPOCH 5 - PROGRESS: at 33.28% examples, 1199552 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:10:16,532 : INFO : EPOCH 5 - PROGRESS: at 36.54% examples, 1173612 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:17,556 : INFO : EPOCH 5 - PROGRESS: at 39.26% examples, 1134691 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:18,557 : INFO : EPOCH 5 - PROGRESS: at 41.86% examples, 1098712 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:19,562 : INFO : EPOCH 5 - PROGRESS: at 44.51% examples, 1071011 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:20,563 : INFO : EPOCH 5 - PROGRESS: at 46.87% examples, 1042960 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:21,575 : INFO : EPOCH 5 - PROGRESS: at 49.55% examples, 1023636 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 17:10:22,578 : INFO : EPOCH 5 - PROGRESS: at 52.56% examples, 1015240 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:23,594 : INFO : EPOCH 5 - PROGRESS: at 55.66% examples, 1008136 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:24,595 : INFO : EPOCH 5 - PROGRESS: at 59.23% examples, 1009837 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:10:25,607 : INFO : EPOCH 5 - PROGRESS: at 62.90% examples, 1012094 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:26,611 : INFO : EPOCH 5 - PROGRESS: at 66.59% examples, 1013768 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:10:27,612 : INFO : EPOCH 5 - PROGRESS: at 70.04% examples, 1015393 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:28,626 : INFO : EPOCH 5 - PROGRESS: at 73.64% examples, 1015800 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:29,632 : INFO : EPOCH 5 - PROGRESS: at 77.05% examples, 1018002 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:30,636 : INFO : EPOCH 5 - PROGRESS: at 80.02% examples, 1014135 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:31,636 : INFO : EPOCH 5 - PROGRESS: at 83.55% examples, 1016177 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 17:10:32,641 : INFO : EPOCH 5 - PROGRESS: at 86.92% examples, 1015876 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:33,655 : INFO : EPOCH 5 - PROGRESS: at 90.73% examples, 1017333 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:10:34,674 : INFO : EPOCH 5 - PROGRESS: at 94.44% examples, 1018941 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:35,677 : INFO : EPOCH 5 - PROGRESS: at 98.01% examples, 1019732 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:10:36,140 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:10:36,145 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:10:36,148 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:10:36,149 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:10:36,162 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:10:36,169 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:10:36,170 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:10:36,176 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:10:36,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:10:36,183 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:10:36,184 : INFO : EPOCH - 5 : training on 41519358 raw words (30349096 effective words) took 29.7s, 1021401 effective words/s\n",
      "2019-07-14 17:10:37,192 : INFO : EPOCH 6 - PROGRESS: at 3.34% examples, 1035673 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:10:38,193 : INFO : EPOCH 6 - PROGRESS: at 6.87% examples, 1053905 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:39,193 : INFO : EPOCH 6 - PROGRESS: at 9.90% examples, 1049923 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:40,208 : INFO : EPOCH 6 - PROGRESS: at 12.37% examples, 1013826 words/s, in_qsize 19, out_qsize 2\n",
      "2019-07-14 17:10:41,222 : INFO : EPOCH 6 - PROGRESS: at 14.82% examples, 975463 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:42,242 : INFO : EPOCH 6 - PROGRESS: at 17.64% examples, 977994 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:43,251 : INFO : EPOCH 6 - PROGRESS: at 19.71% examples, 948901 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:44,269 : INFO : EPOCH 6 - PROGRESS: at 22.03% examples, 925945 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:45,308 : INFO : EPOCH 6 - PROGRESS: at 24.02% examples, 906450 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:46,321 : INFO : EPOCH 6 - PROGRESS: at 27.22% examples, 906323 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:47,327 : INFO : EPOCH 6 - PROGRESS: at 31.00% examples, 919036 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:48,352 : INFO : EPOCH 6 - PROGRESS: at 34.74% examples, 930019 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:10:49,355 : INFO : EPOCH 6 - PROGRESS: at 38.42% examples, 937930 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:10:50,359 : INFO : EPOCH 6 - PROGRESS: at 41.86% examples, 937199 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:51,374 : INFO : EPOCH 6 - PROGRESS: at 45.21% examples, 936210 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:52,374 : INFO : EPOCH 6 - PROGRESS: at 47.89% examples, 926415 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:53,383 : INFO : EPOCH 6 - PROGRESS: at 51.64% examples, 934788 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:54,387 : INFO : EPOCH 6 - PROGRESS: at 55.18% examples, 941549 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:55,406 : INFO : EPOCH 6 - PROGRESS: at 58.91% examples, 947611 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:10:56,417 : INFO : EPOCH 6 - PROGRESS: at 62.45% examples, 951149 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:57,421 : INFO : EPOCH 6 - PROGRESS: at 66.01% examples, 953649 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:10:58,422 : INFO : EPOCH 6 - PROGRESS: at 69.64% examples, 959443 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:10:59,434 : INFO : EPOCH 6 - PROGRESS: at 73.24% examples, 963610 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:00,438 : INFO : EPOCH 6 - PROGRESS: at 75.72% examples, 954885 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:01,445 : INFO : EPOCH 6 - PROGRESS: at 79.02% examples, 958363 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:02,448 : INFO : EPOCH 6 - PROGRESS: at 82.70% examples, 964029 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 17:11:03,450 : INFO : EPOCH 6 - PROGRESS: at 86.64% examples, 972370 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:04,465 : INFO : EPOCH 6 - PROGRESS: at 89.92% examples, 969902 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 17:11:05,469 : INFO : EPOCH 6 - PROGRESS: at 92.51% examples, 962063 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:06,490 : INFO : EPOCH 6 - PROGRESS: at 95.38% examples, 957473 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:07,497 : INFO : EPOCH 6 - PROGRESS: at 98.09% examples, 951973 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 17:11:08,105 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:11:08,123 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:11:08,127 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:11:08,130 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:11:08,134 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:11:08,140 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:11:08,149 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:11:08,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:11:08,155 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:11:08,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:11:08,167 : INFO : EPOCH - 6 : training on 41519358 raw words (30349099 effective words) took 32.0s, 949073 effective words/s\n",
      "2019-07-14 17:11:09,173 : INFO : EPOCH 7 - PROGRESS: at 2.68% examples, 843581 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:10,174 : INFO : EPOCH 7 - PROGRESS: at 6.33% examples, 976841 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:11,175 : INFO : EPOCH 7 - PROGRESS: at 9.67% examples, 1012606 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:12,186 : INFO : EPOCH 7 - PROGRESS: at 12.02% examples, 981592 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:13,193 : INFO : EPOCH 7 - PROGRESS: at 15.20% examples, 1004122 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:14,195 : INFO : EPOCH 7 - PROGRESS: at 17.86% examples, 996518 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:15,215 : INFO : EPOCH 7 - PROGRESS: at 19.96% examples, 964940 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:16,217 : INFO : EPOCH 7 - PROGRESS: at 22.40% examples, 947146 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:11:17,243 : INFO : EPOCH 7 - PROGRESS: at 25.16% examples, 950996 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:18,252 : INFO : EPOCH 7 - PROGRESS: at 28.50% examples, 946203 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:19,252 : INFO : EPOCH 7 - PROGRESS: at 32.01% examples, 947982 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:20,258 : INFO : EPOCH 7 - PROGRESS: at 35.18% examples, 946757 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:21,258 : INFO : EPOCH 7 - PROGRESS: at 38.50% examples, 945255 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:22,261 : INFO : EPOCH 7 - PROGRESS: at 42.05% examples, 946568 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:23,284 : INFO : EPOCH 7 - PROGRESS: at 45.62% examples, 947861 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 17:11:24,285 : INFO : EPOCH 7 - PROGRESS: at 48.87% examples, 947648 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:25,293 : INFO : EPOCH 7 - PROGRESS: at 52.20% examples, 948915 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:26,324 : INFO : EPOCH 7 - PROGRESS: at 54.86% examples, 940362 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:27,335 : INFO : EPOCH 7 - PROGRESS: at 58.46% examples, 943919 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:11:28,343 : INFO : EPOCH 7 - PROGRESS: at 61.35% examples, 938070 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:11:29,351 : INFO : EPOCH 7 - PROGRESS: at 64.53% examples, 933996 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:30,384 : INFO : EPOCH 7 - PROGRESS: at 66.78% examples, 922138 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:31,395 : INFO : EPOCH 7 - PROGRESS: at 69.68% examples, 919178 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:32,396 : INFO : EPOCH 7 - PROGRESS: at 72.69% examples, 918711 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:33,398 : INFO : EPOCH 7 - PROGRESS: at 75.92% examples, 920514 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 17:11:34,401 : INFO : EPOCH 7 - PROGRESS: at 79.27% examples, 925345 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:35,410 : INFO : EPOCH 7 - PROGRESS: at 82.61% examples, 928346 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:36,412 : INFO : EPOCH 7 - PROGRESS: at 85.67% examples, 929215 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:37,416 : INFO : EPOCH 7 - PROGRESS: at 88.84% examples, 927185 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:38,419 : INFO : EPOCH 7 - PROGRESS: at 92.13% examples, 927476 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:39,420 : INFO : EPOCH 7 - PROGRESS: at 95.01% examples, 925230 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:40,431 : INFO : EPOCH 7 - PROGRESS: at 98.22% examples, 925271 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:40,894 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:11:40,898 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:11:40,901 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:11:40,905 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:11:40,909 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:11:40,911 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:11:40,919 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:11:40,922 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:11:40,928 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:11:40,931 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:11:40,932 : INFO : EPOCH - 7 : training on 41519358 raw words (30348935 effective words) took 32.8s, 926422 effective words/s\n",
      "2019-07-14 17:11:41,957 : INFO : EPOCH 8 - PROGRESS: at 3.46% examples, 1054751 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:11:42,959 : INFO : EPOCH 8 - PROGRESS: at 6.94% examples, 1055750 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:43,959 : INFO : EPOCH 8 - PROGRESS: at 9.83% examples, 1031981 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:44,964 : INFO : EPOCH 8 - PROGRESS: at 12.36% examples, 1011927 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:11:45,968 : INFO : EPOCH 8 - PROGRESS: at 14.81% examples, 976112 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:46,968 : INFO : EPOCH 8 - PROGRESS: at 17.85% examples, 993892 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:47,980 : INFO : EPOCH 8 - PROGRESS: at 20.34% examples, 985939 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:48,992 : INFO : EPOCH 8 - PROGRESS: at 23.18% examples, 984168 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:49,995 : INFO : EPOCH 8 - PROGRESS: at 26.20% examples, 984153 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:51,007 : INFO : EPOCH 8 - PROGRESS: at 29.69% examples, 979713 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:52,008 : INFO : EPOCH 8 - PROGRESS: at 32.76% examples, 967389 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:53,014 : INFO : EPOCH 8 - PROGRESS: at 36.75% examples, 983159 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:11:54,027 : INFO : EPOCH 8 - PROGRESS: at 40.67% examples, 992399 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:55,032 : INFO : EPOCH 8 - PROGRESS: at 44.57% examples, 995809 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:56,033 : INFO : EPOCH 8 - PROGRESS: at 47.94% examples, 994742 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:57,043 : INFO : EPOCH 8 - PROGRESS: at 51.81% examples, 1001139 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:11:58,044 : INFO : EPOCH 8 - PROGRESS: at 55.78% examples, 1011286 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 17:11:59,048 : INFO : EPOCH 8 - PROGRESS: at 59.88% examples, 1021087 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:00,050 : INFO : EPOCH 8 - PROGRESS: at 64.02% examples, 1028166 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:01,066 : INFO : EPOCH 8 - PROGRESS: at 67.28% examples, 1024346 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:02,097 : INFO : EPOCH 8 - PROGRESS: at 70.54% examples, 1021406 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:03,101 : INFO : EPOCH 8 - PROGRESS: at 74.47% examples, 1026825 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:04,104 : INFO : EPOCH 8 - PROGRESS: at 77.99% examples, 1031133 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:05,106 : INFO : EPOCH 8 - PROGRESS: at 81.92% examples, 1037907 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:06,115 : INFO : EPOCH 8 - PROGRESS: at 85.94% examples, 1045132 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:07,118 : INFO : EPOCH 8 - PROGRESS: at 90.33% examples, 1052010 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:08,126 : INFO : EPOCH 8 - PROGRESS: at 94.21% examples, 1054694 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:09,134 : INFO : EPOCH 8 - PROGRESS: at 98.15% examples, 1057864 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:09,505 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:12:09,519 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:12:09,526 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:12:09,527 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:12:09,534 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:12:09,541 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:12:09,542 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:12:09,547 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:12:09,551 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:12:09,554 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:12:09,555 : INFO : EPOCH - 8 : training on 41519358 raw words (30351604 effective words) took 28.6s, 1060628 effective words/s\n",
      "2019-07-14 17:12:10,561 : INFO : EPOCH 9 - PROGRESS: at 3.86% examples, 1195723 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:11,573 : INFO : EPOCH 9 - PROGRESS: at 7.88% examples, 1210221 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:12,575 : INFO : EPOCH 9 - PROGRESS: at 11.33% examples, 1212890 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:12:13,576 : INFO : EPOCH 9 - PROGRESS: at 14.44% examples, 1188247 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:14,579 : INFO : EPOCH 9 - PROGRESS: at 17.65% examples, 1179441 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:12:15,585 : INFO : EPOCH 9 - PROGRESS: at 20.82% examples, 1184902 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:16,590 : INFO : EPOCH 9 - PROGRESS: at 23.96% examples, 1172685 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:17,597 : INFO : EPOCH 9 - PROGRESS: at 27.94% examples, 1165857 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:18,602 : INFO : EPOCH 9 - PROGRESS: at 32.37% examples, 1172499 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:19,604 : INFO : EPOCH 9 - PROGRESS: at 36.35% examples, 1170642 words/s, in_qsize 19, out_qsize 1\n",
      "2019-07-14 17:12:20,606 : INFO : EPOCH 9 - PROGRESS: at 40.27% examples, 1164805 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:21,609 : INFO : EPOCH 9 - PROGRESS: at 44.51% examples, 1163590 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:12:22,620 : INFO : EPOCH 9 - PROGRESS: at 48.75% examples, 1166742 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:23,620 : INFO : EPOCH 9 - PROGRESS: at 52.86% examples, 1170689 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:24,629 : INFO : EPOCH 9 - PROGRESS: at 57.09% examples, 1173319 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:25,631 : INFO : EPOCH 9 - PROGRESS: at 61.29% examples, 1175791 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:12:26,634 : INFO : EPOCH 9 - PROGRESS: at 65.65% examples, 1178939 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:12:27,638 : INFO : EPOCH 9 - PROGRESS: at 69.69% examples, 1180573 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:12:28,640 : INFO : EPOCH 9 - PROGRESS: at 73.85% examples, 1182791 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:29,640 : INFO : EPOCH 9 - PROGRESS: at 77.65% examples, 1184089 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:30,641 : INFO : EPOCH 9 - PROGRESS: at 81.63% examples, 1185937 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:12:31,646 : INFO : EPOCH 9 - PROGRESS: at 85.64% examples, 1187639 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:12:32,656 : INFO : EPOCH 9 - PROGRESS: at 90.09% examples, 1189505 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:12:33,671 : INFO : EPOCH 9 - PROGRESS: at 94.33% examples, 1190607 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:34,672 : INFO : EPOCH 9 - PROGRESS: at 98.47% examples, 1191387 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 17:12:34,957 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:12:34,975 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:12:34,977 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:12:34,980 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:12:34,981 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:12:34,989 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:12:34,997 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:12:34,998 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:12:35,005 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:12:35,006 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:12:35,007 : INFO : EPOCH - 9 : training on 41519358 raw words (30347363 effective words) took 25.4s, 1192578 effective words/s\n",
      "2019-07-14 17:12:36,016 : INFO : EPOCH 10 - PROGRESS: at 3.91% examples, 1207911 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:37,027 : INFO : EPOCH 10 - PROGRESS: at 7.91% examples, 1216822 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:38,036 : INFO : EPOCH 10 - PROGRESS: at 11.27% examples, 1205457 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:39,043 : INFO : EPOCH 10 - PROGRESS: at 14.48% examples, 1187583 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:40,055 : INFO : EPOCH 10 - PROGRESS: at 17.58% examples, 1168524 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:12:41,056 : INFO : EPOCH 10 - PROGRESS: at 20.77% examples, 1177777 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:42,059 : INFO : EPOCH 10 - PROGRESS: at 24.26% examples, 1185292 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:43,072 : INFO : EPOCH 10 - PROGRESS: at 28.33% examples, 1177144 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:44,090 : INFO : EPOCH 10 - PROGRESS: at 32.71% examples, 1179356 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:45,094 : INFO : EPOCH 10 - PROGRESS: at 36.66% examples, 1175125 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:46,106 : INFO : EPOCH 10 - PROGRESS: at 40.27% examples, 1160032 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:47,108 : INFO : EPOCH 10 - PROGRESS: at 44.44% examples, 1157570 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:48,112 : INFO : EPOCH 10 - PROGRESS: at 48.67% examples, 1161819 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:12:49,112 : INFO : EPOCH 10 - PROGRESS: at 52.47% examples, 1157857 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:50,132 : INFO : EPOCH 10 - PROGRESS: at 56.65% examples, 1161035 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:51,135 : INFO : EPOCH 10 - PROGRESS: at 60.85% examples, 1164199 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:52,146 : INFO : EPOCH 10 - PROGRESS: at 65.14% examples, 1165422 words/s, in_qsize 17, out_qsize 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 17:12:53,154 : INFO : EPOCH 10 - PROGRESS: at 69.26% examples, 1169196 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:54,165 : INFO : EPOCH 10 - PROGRESS: at 73.39% examples, 1171893 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:55,170 : INFO : EPOCH 10 - PROGRESS: at 77.26% examples, 1173425 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 17:12:56,177 : INFO : EPOCH 10 - PROGRESS: at 81.22% examples, 1175769 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 17:12:57,180 : INFO : EPOCH 10 - PROGRESS: at 85.19% examples, 1177402 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:58,188 : INFO : EPOCH 10 - PROGRESS: at 89.57% examples, 1179413 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:12:59,195 : INFO : EPOCH 10 - PROGRESS: at 93.80% examples, 1180985 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 17:13:00,201 : INFO : EPOCH 10 - PROGRESS: at 97.96% examples, 1181960 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 17:13:00,625 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 17:13:00,635 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 17:13:00,639 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 17:13:00,647 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 17:13:00,652 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 17:13:00,660 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 17:13:00,664 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 17:13:00,669 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 17:13:00,670 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 17:13:00,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 17:13:00,671 : INFO : EPOCH - 10 : training on 41519358 raw words (30352716 effective words) took 25.7s, 1182915 effective words/s\n",
      "2019-07-14 17:13:00,672 : INFO : training on a 415193580 raw words (303498829 effective words) took 280.9s, 1080397 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(303498829, 415193580)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos checar o output \n",
    "Este primeiro exemplo mostra um caso simples de procurar palavras semelhantes à palavra `dirty`. Tudo o que precisamos fazer aqui é chamar a função `most_similar` e fornecer a palavra` dirty` como o exemplo positivo. Isso retorna o top 10 palavras semelhantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 17:15:58,245 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.8671504259109497),\n",
       " ('stained', 0.7767190933227539),\n",
       " ('dusty', 0.7680657505989075),\n",
       " ('unclean', 0.7639098167419434),\n",
       " ('smelly', 0.7537983655929565),\n",
       " ('grubby', 0.7474677562713623),\n",
       " ('soiled', 0.7356410026550293),\n",
       " ('dingy', 0.718575656414032),\n",
       " ('disgusting', 0.7163524031639099),\n",
       " ('gross', 0.7155978679656982)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"dirty\"\n",
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso parece muito bom, certo? Vamos dar uma olhada em mais alguns. Vamos ver a similaridade de `educado`,` frança` e `chocado`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.9205291271209717),\n",
       " ('friendly', 0.8392852544784546),\n",
       " ('cordial', 0.8127507567405701),\n",
       " ('professional', 0.788678765296936),\n",
       " ('attentive', 0.782365083694458),\n",
       " ('curteous', 0.7751853466033936)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos ver as 6 palavras mais similares a 'polite'\n",
    "w1 = [\"polite\"]\n",
    "model.wv.most_similar (positive=w1, topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canada', 0.6721209287643433),\n",
       " ('germany', 0.6644063591957092),\n",
       " ('spain', 0.6451458930969238),\n",
       " ('mexico', 0.6338759660720825),\n",
       " ('hawaii', 0.6228253841400146),\n",
       " ('rome', 0.6122733354568481)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos ver as 6 palavras mais similares a 'france'\n",
    "w1 = [\"france\"]\n",
    "model.wv.most_similar(positive=w1, topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrified', 0.8059837818145752),\n",
       " ('amazed', 0.7890470027923584),\n",
       " ('appalled', 0.768475353717804),\n",
       " ('astonished', 0.7476360201835632),\n",
       " ('stunned', 0.735933244228363),\n",
       " ('dismayed', 0.7296151518821716)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos ver as 6 palavras mais similares a 'france'\n",
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso é bom. Você pode até especificar vários exemplos positivos para obter coisas que estão relacionadas no contexto fornecido e fornecer exemplos negativos para dizer o que não deve ser considerado como relacionado. No exemplo abaixo, estamos pedindo todos os itens que se referem *cama* (*bed* em inglês):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duvet', 0.718425989151001),\n",
       " ('blanket', 0.6985957622528076),\n",
       " ('matress', 0.694139838218689),\n",
       " ('pillowcase', 0.689792811870575),\n",
       " ('mattress', 0.6870702505111694),\n",
       " ('quilt', 0.6829710602760315),\n",
       " ('pillows', 0.6435014009475708),\n",
       " ('foam', 0.6245807409286499),\n",
       " ('sheets', 0.6244121789932251),\n",
       " ('comforter', 0.5996685028076172)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# palavras relacionadas com cama\n",
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade entre duas palavras no vocabulário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode até usar o modelo Word2Vec para retornar a semelhança entre duas palavras que estão presentes no vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7537983"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similaridade de duas palavras diferentes\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similaridades de duas palavras idênticas\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.286456"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similaridade de duas palavras opostas\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debaixo dos panos, os três trechos acima calculam a semelhança de cosseno entre as duas palavras especificadas usando vetores de palavras de cada um. A partir das pontuações, faz sentido que `dirty` seja altamente similar a` smelly`, mas `dirty` é diferente de` clean`. Se você fizer uma semelhança entre duas palavras idênticas, a pontuação será 1.0, já que o intervalo da pontuação de semelhança do cosseno será sempre entre [0.0-1.0]. Você pode ler mais sobre a pontuação de semelhança de cosseno [aqui] (https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontre o estranho\n",
    "Você pode até usar o Word2Vec para encontrar itens estranhos com uma lista de itens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geanderson/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:876: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual dos items abaixo é o estranho da lista?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual dos items abaixo é o estranho da lista?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"car\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo os parâmetros que podem ser utilizados\n",
    "Para treinar o modelo anteriormente, tivemos que definir alguns parâmetros. Agora, vamos tentar entender o que alguns deles significam. Para referência, este é o comando que usamos para treinar o modelo.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec(documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `size`\n",
    "O tamanho do vetor denso para representar cada token ou palavra. Se você tiver dados muito limitados, o tamanho deverá ser um valor muito menor. Se você tiver muitos dados, é bom experimentar vários tamanhos. Um valor de 100-150 funcionou bem para o dataset treinado.\n",
    "\n",
    "### `window`\n",
    "A distância máxima entre a palavra alvo e a palavra vizinha. Se a posição do seu vizinho for maior que a largura máxima da janela à esquerda e à direita, alguns vizinhos não serão considerados como relacionados à palavra de destino. Em teoria, uma janela menor deve fornecer termos mais relacionados. Se você tiver muitos dados, o tamanho da janela não deve importar muito, desde que seja uma janela de tamanho decente. \n",
    "\n",
    "### `min_count`\n",
    "Contagem de frequência mínima de palavras. O modelo ignoraria as palavras que não statisfy o `min_count`. Palavras extremamente raras geralmente não são importantes, então é melhor livrar-se delas. A menos que seu conjunto de dados seja realmente pequeno, isso não afeta realmente o modelo.\n",
    "\n",
    "### `workers`\n",
    "Quantas threads deveríamos usar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quando usar Word2Vec?\n",
    "\n",
    "Existem muitos cenários de aplicativos para o Word2Vec. Imagine se você precisa construir um léxico de sentimento. Treinar um modelo Word2Vec em grandes quantidades de comentários de usuários ajuda você a conseguir isso. Você tem um léxico não apenas para o sentimento, mas para a maioria das palavras no vocabulário.\n",
    "\n",
    "Além dos dados de texto bruto não estruturados, você também pode usar o Word2Vec para obter dados mais estruturados. Por exemplo, se você tivesse tags para um milhão de perguntas e respostas do stackoverflow, poderia encontrar tags relacionadas a uma determinada tag e recomendar as relacionadas para exploração. Você pode fazer isso tratando cada conjunto de tags de coexistência como uma \"frase\" e treinar um modelo Word2Vec nesses dados. Concedido, você ainda precisa de um grande número de exemplos para fazê-lo funcionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
