{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Word2Vec in Gensim and making it work!\n",
    "\n",
    "The idea behind Word2Vec is pretty simple. We are making and assumption that you can tell the meaning of a word by the company it keeps. This is analogous to the saying *show me your friends, and I'll tell who you are*. So if you have two words that have very similar neighbors (i.e. the usage context is about the same), then these words are probably quite similar in meaning or are at least highly related. For example, the words `shocked`,`appalled` and `astonished` are typically used in a similar context. \n",
    "\n",
    "In this tutorial, you will learn how to use the Gensim implementation of Word2Vec and actually get it to work! I have heard a lot of complaints about poor performance etc, but its really a combination of two things, (1) your input data and (2) your parameter settings. Note that the training algorithms in this package were ported from the [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) and extended with additional functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and logging\n",
    "\n",
    "First, we start with our imports and get logging established:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed and set up logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Next, is our dataset. The secret to getting Word2Vec really working for you is to have lots and lots of text data. In this case I am going to use data from the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset. This dataset has full user reviews of cars and hotels. I have specifically concatenated all of the hotel reviews into one big file which is about 97MB compressed and 229MB uncompressed. We will use the compressed file for this tutorial. Each line in this file represents a hotel review. You can download the OpinRank Word2Vec dataset here.\n",
    "\n",
    "To avoid confusion, while gensim’s word2vec tutorial says that you need to pass it a sequence of sentences as its input, you can always pass it a whole review as a sentence (i.e. a much larger size of text), and it should not make much of a difference. \n",
    "\n",
    "Now, let's take a closer look at this data below by printing the first line. You can see that this is a pretty hefty review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file=\"data/reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open ('data/reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files into a list\n",
    "Now that we've had a sneak peak of our dataset, we can read it into a list so that we can pass this on to the Word2Vec model. Notice in the code below, that I am directly reading the \n",
    "compressed file. I'm also doing a mild pre-processing of the reviews using `gensim.utils.simple_preprocess (line)`. This does some basic pre-processing such as tokenization, lowercasing, etc and returns back a list of tokens (words). Documentation of this pre-processing method can be found on the official [Gensim documentation site](https://radimrehurek.com/gensim/utils.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:21:06,506 : INFO : reading file data/reviews_data.txt.gz...this may take a while\n",
      "2019-07-14 13:21:06,507 : INFO : read 0 reviews\n",
      "2019-07-14 13:21:07,830 : INFO : read 10000 reviews\n",
      "2019-07-14 13:21:09,139 : INFO : read 20000 reviews\n",
      "2019-07-14 13:21:10,647 : INFO : read 30000 reviews\n",
      "2019-07-14 13:21:12,062 : INFO : read 40000 reviews\n",
      "2019-07-14 13:21:13,614 : INFO : read 50000 reviews\n",
      "2019-07-14 13:21:15,336 : INFO : read 60000 reviews\n",
      "2019-07-14 13:21:16,621 : INFO : read 70000 reviews\n",
      "2019-07-14 13:21:17,788 : INFO : read 80000 reviews\n",
      "2019-07-14 13:21:19,045 : INFO : read 90000 reviews\n",
      "2019-07-14 13:21:20,256 : INFO : read 100000 reviews\n",
      "2019-07-14 13:21:21,502 : INFO : read 110000 reviews\n",
      "2019-07-14 13:21:22,706 : INFO : read 120000 reviews\n",
      "2019-07-14 13:21:23,940 : INFO : read 130000 reviews\n",
      "2019-07-14 13:21:25,267 : INFO : read 140000 reviews\n",
      "2019-07-14 13:21:26,530 : INFO : read 150000 reviews\n",
      "2019-07-14 13:21:28,218 : INFO : read 160000 reviews\n",
      "2019-07-14 13:21:29,438 : INFO : read 170000 reviews\n",
      "2019-07-14 13:21:30,903 : INFO : read 180000 reviews\n",
      "2019-07-14 13:21:32,415 : INFO : read 190000 reviews\n",
      "2019-07-14 13:21:34,057 : INFO : read 200000 reviews\n",
      "2019-07-14 13:21:35,632 : INFO : read 210000 reviews\n",
      "2019-07-14 13:21:37,013 : INFO : read 220000 reviews\n",
      "2019-07-14 13:21:38,200 : INFO : read 230000 reviews\n",
      "2019-07-14 13:21:39,481 : INFO : read 240000 reviews\n",
      "2019-07-14 13:21:41,410 : INFO : read 250000 reviews\n",
      "2019-07-14 13:21:42,104 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "            yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "# read the tokenized reviews into a list\n",
    "# each review item becomes a serries of words\n",
    "# so this becomes a list of lists\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Done reading data file\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec model\n",
    "\n",
    "Training the model is fairly straightforward. You just instantiate Word2Vec and pass the reviews that we read in the previous step (the `documents`). So, we are essentially passing on a list of lists. Where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary. And by vocabulary, I mean a set of unique words.\n",
    "\n",
    "After building the vocabulary, we just need to call `train(...)` to start training the Word2Vec model. Training on the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset takes about 10 minutes so please be patient while running your code on this dataset.\n",
    "\n",
    "Behind the scenes we are actually training a simple neural network with a single hidden layer. But, we are actually not going to use the neural network after training. Instead, the goal is to learn the weights of the hidden layer. These weights are essentially the word vectors that we’re trying to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:21:42,109 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-07-14 13:21:42,109 : INFO : collecting all words and their counts\n",
      "2019-07-14 13:21:42,110 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-07-14 13:21:42,294 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2019-07-14 13:21:42,475 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2019-07-14 13:21:42,681 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2019-07-14 13:21:42,876 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2019-07-14 13:21:43,087 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2019-07-14 13:21:43,293 : INFO : PROGRESS: at sentence #60000, processed 11013726 words, keeping 76786 word types\n",
      "2019-07-14 13:21:43,480 : INFO : PROGRESS: at sentence #70000, processed 12637528 words, keeping 83199 word types\n",
      "2019-07-14 13:21:43,673 : INFO : PROGRESS: at sentence #80000, processed 14099754 words, keeping 88459 word types\n",
      "2019-07-14 13:21:43,845 : INFO : PROGRESS: at sentence #90000, processed 15662152 words, keeping 93357 word types\n",
      "2019-07-14 13:21:44,010 : INFO : PROGRESS: at sentence #100000, processed 17164490 words, keeping 97886 word types\n",
      "2019-07-14 13:21:44,175 : INFO : PROGRESS: at sentence #110000, processed 18652295 words, keeping 102132 word types\n",
      "2019-07-14 13:21:44,341 : INFO : PROGRESS: at sentence #120000, processed 20152532 words, keeping 105923 word types\n",
      "2019-07-14 13:21:44,512 : INFO : PROGRESS: at sentence #130000, processed 21684333 words, keeping 110104 word types\n",
      "2019-07-14 13:21:44,691 : INFO : PROGRESS: at sentence #140000, processed 23330209 words, keeping 114108 word types\n",
      "2019-07-14 13:21:44,858 : INFO : PROGRESS: at sentence #150000, processed 24838757 words, keeping 118174 word types\n",
      "2019-07-14 13:21:45,030 : INFO : PROGRESS: at sentence #160000, processed 26390913 words, keeping 118670 word types\n",
      "2019-07-14 13:21:45,201 : INFO : PROGRESS: at sentence #170000, processed 27913919 words, keeping 123356 word types\n",
      "2019-07-14 13:21:45,378 : INFO : PROGRESS: at sentence #180000, processed 29535615 words, keeping 126748 word types\n",
      "2019-07-14 13:21:45,549 : INFO : PROGRESS: at sentence #190000, processed 31096462 words, keeping 129847 word types\n",
      "2019-07-14 13:21:45,739 : INFO : PROGRESS: at sentence #200000, processed 32805274 words, keeping 133255 word types\n",
      "2019-07-14 13:21:45,919 : INFO : PROGRESS: at sentence #210000, processed 34434201 words, keeping 136364 word types\n",
      "2019-07-14 13:21:46,100 : INFO : PROGRESS: at sentence #220000, processed 36083485 words, keeping 139418 word types\n",
      "2019-07-14 13:21:46,265 : INFO : PROGRESS: at sentence #230000, processed 37571765 words, keeping 142399 word types\n",
      "2019-07-14 13:21:46,440 : INFO : PROGRESS: at sentence #240000, processed 39138193 words, keeping 145232 word types\n",
      "2019-07-14 13:21:46,617 : INFO : PROGRESS: at sentence #250000, processed 40695052 words, keeping 147966 word types\n",
      "2019-07-14 13:21:46,713 : INFO : collected 150059 word types from a corpus of 41519358 raw words and 255404 sentences\n",
      "2019-07-14 13:21:46,714 : INFO : Loading a fresh vocabulary\n",
      "2019-07-14 13:21:46,839 : INFO : effective_min_count=2 retains 70537 unique words (47% of original 150059, drops 79522)\n",
      "2019-07-14 13:21:46,840 : INFO : effective_min_count=2 leaves 41439836 word corpus (99% of original 41519358, drops 79522)\n",
      "2019-07-14 13:21:46,980 : INFO : deleting the raw counts dictionary of 150059 items\n",
      "2019-07-14 13:21:46,985 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2019-07-14 13:21:46,985 : INFO : downsampling leaves estimated 30349251 word corpus (73.2% of prior 41439836)\n",
      "2019-07-14 13:21:47,306 : INFO : estimated required memory for 70537 words and 150 dimensions: 119912900 bytes\n",
      "2019-07-14 13:21:47,307 : INFO : resetting layer weights\n",
      "2019-07-14 13:21:47,840 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-07-14 13:21:48,856 : INFO : EPOCH 1 - PROGRESS: at 4.16% examples, 1273254 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:21:49,870 : INFO : EPOCH 1 - PROGRESS: at 7.95% examples, 1218426 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:21:50,890 : INFO : EPOCH 1 - PROGRESS: at 11.17% examples, 1187984 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:21:51,893 : INFO : EPOCH 1 - PROGRESS: at 14.24% examples, 1163785 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:21:52,895 : INFO : EPOCH 1 - PROGRESS: at 17.03% examples, 1125641 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:21:53,896 : INFO : EPOCH 1 - PROGRESS: at 19.79% examples, 1112507 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:21:54,902 : INFO : EPOCH 1 - PROGRESS: at 22.75% examples, 1098196 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:21:55,907 : INFO : EPOCH 1 - PROGRESS: at 25.62% examples, 1086126 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:21:56,907 : INFO : EPOCH 1 - PROGRESS: at 29.82% examples, 1092865 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:21:57,914 : INFO : EPOCH 1 - PROGRESS: at 34.07% examples, 1104136 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:21:58,933 : INFO : EPOCH 1 - PROGRESS: at 38.36% examples, 1111844 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:21:59,933 : INFO : EPOCH 1 - PROGRESS: at 42.68% examples, 1119957 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:00,946 : INFO : EPOCH 1 - PROGRESS: at 47.01% examples, 1125303 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:01,953 : INFO : EPOCH 1 - PROGRESS: at 51.22% examples, 1130790 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:02,956 : INFO : EPOCH 1 - PROGRESS: at 55.29% examples, 1135865 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:03,964 : INFO : EPOCH 1 - PROGRESS: at 59.50% examples, 1140134 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:04,970 : INFO : EPOCH 1 - PROGRESS: at 63.72% examples, 1143332 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:05,974 : INFO : EPOCH 1 - PROGRESS: at 67.86% examples, 1146542 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:06,983 : INFO : EPOCH 1 - PROGRESS: at 71.77% examples, 1149372 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:07,989 : INFO : EPOCH 1 - PROGRESS: at 75.91% examples, 1152394 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:08,991 : INFO : EPOCH 1 - PROGRESS: at 79.72% examples, 1154314 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 13:22:09,998 : INFO : EPOCH 1 - PROGRESS: at 83.78% examples, 1157781 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:11,010 : INFO : EPOCH 1 - PROGRESS: at 87.95% examples, 1159994 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:12,017 : INFO : EPOCH 1 - PROGRESS: at 92.25% examples, 1162167 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:13,018 : INFO : EPOCH 1 - PROGRESS: at 96.36% examples, 1164171 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:13,826 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:22:13,838 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:22:13,843 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:22:13,846 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:22:13,847 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:22:13,858 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:22:13,860 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:22:13,863 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:22:13,866 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:22:13,871 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:22:13,872 : INFO : EPOCH - 1 : training on 41519358 raw words (30351149 effective words) took 26.0s, 1166222 effective words/s\n",
      "2019-07-14 13:22:14,877 : INFO : EPOCH 2 - PROGRESS: at 3.80% examples, 1176372 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:22:15,884 : INFO : EPOCH 2 - PROGRESS: at 7.75% examples, 1196186 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:16,887 : INFO : EPOCH 2 - PROGRESS: at 11.24% examples, 1208001 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:17,897 : INFO : EPOCH 2 - PROGRESS: at 14.16% examples, 1164174 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:18,906 : INFO : EPOCH 2 - PROGRESS: at 16.61% examples, 1101252 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:22:19,914 : INFO : EPOCH 2 - PROGRESS: at 19.26% examples, 1080198 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:20,932 : INFO : EPOCH 2 - PROGRESS: at 22.54% examples, 1089038 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 13:22:21,941 : INFO : EPOCH 2 - PROGRESS: at 25.69% examples, 1088294 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:22,957 : INFO : EPOCH 2 - PROGRESS: at 29.49% examples, 1080209 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 13:22:23,966 : INFO : EPOCH 2 - PROGRESS: at 33.23% examples, 1075097 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:24,987 : INFO : EPOCH 2 - PROGRESS: at 37.10% examples, 1078495 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:25,990 : INFO : EPOCH 2 - PROGRESS: at 40.92% examples, 1077734 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:27,005 : INFO : EPOCH 2 - PROGRESS: at 44.46% examples, 1066925 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:28,014 : INFO : EPOCH 2 - PROGRESS: at 48.52% examples, 1073349 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:29,014 : INFO : EPOCH 2 - PROGRESS: at 51.87% examples, 1066521 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:30,022 : INFO : EPOCH 2 - PROGRESS: at 54.59% examples, 1051832 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 13:22:31,043 : INFO : EPOCH 2 - PROGRESS: at 57.86% examples, 1043054 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:22:32,045 : INFO : EPOCH 2 - PROGRESS: at 61.10% examples, 1036967 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:33,048 : INFO : EPOCH 2 - PROGRESS: at 64.55% examples, 1032075 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:34,062 : INFO : EPOCH 2 - PROGRESS: at 67.68% examples, 1027132 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:22:35,063 : INFO : EPOCH 2 - PROGRESS: at 70.51% examples, 1019721 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:36,081 : INFO : EPOCH 2 - PROGRESS: at 74.38% examples, 1023605 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:37,094 : INFO : EPOCH 2 - PROGRESS: at 77.07% examples, 1015875 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:38,097 : INFO : EPOCH 2 - PROGRESS: at 79.67% examples, 1007374 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:39,123 : INFO : EPOCH 2 - PROGRESS: at 82.63% examples, 1001803 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:22:40,157 : INFO : EPOCH 2 - PROGRESS: at 85.57% examples, 997389 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:41,159 : INFO : EPOCH 2 - PROGRESS: at 88.83% examples, 993796 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:42,179 : INFO : EPOCH 2 - PROGRESS: at 92.01% examples, 990163 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:43,186 : INFO : EPOCH 2 - PROGRESS: at 95.04% examples, 986697 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:22:44,193 : INFO : EPOCH 2 - PROGRESS: at 98.19% examples, 984292 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:22:44,686 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:22:44,688 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:22:44,697 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:22:44,703 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:22:44,706 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:22:44,707 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:22:44,708 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:22:44,709 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:22:44,714 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:22:44,722 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:22:44,723 : INFO : EPOCH - 2 : training on 41519358 raw words (30348150 effective words) took 30.8s, 983877 effective words/s\n",
      "2019-07-14 13:22:45,740 : INFO : EPOCH 3 - PROGRESS: at 2.87% examples, 883775 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:46,746 : INFO : EPOCH 3 - PROGRESS: at 6.03% examples, 921789 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:22:47,759 : INFO : EPOCH 3 - PROGRESS: at 8.90% examples, 912970 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:48,763 : INFO : EPOCH 3 - PROGRESS: at 11.43% examples, 919108 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:49,775 : INFO : EPOCH 3 - PROGRESS: at 14.08% examples, 921541 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:22:50,776 : INFO : EPOCH 3 - PROGRESS: at 16.82% examples, 926542 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:51,785 : INFO : EPOCH 3 - PROGRESS: at 19.25% examples, 923374 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:22:52,810 : INFO : EPOCH 3 - PROGRESS: at 22.03% examples, 925790 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:53,823 : INFO : EPOCH 3 - PROGRESS: at 24.48% examples, 927829 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:54,824 : INFO : EPOCH 3 - PROGRESS: at 28.01% examples, 930197 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:22:55,830 : INFO : EPOCH 3 - PROGRESS: at 31.32% examples, 928553 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:22:56,840 : INFO : EPOCH 3 - PROGRESS: at 34.43% examples, 925467 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:57,858 : INFO : EPOCH 3 - PROGRESS: at 37.55% examples, 922342 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:22:58,865 : INFO : EPOCH 3 - PROGRESS: at 40.76% examples, 920363 words/s, in_qsize 19, out_qsize 1\n",
      "2019-07-14 13:22:59,872 : INFO : EPOCH 3 - PROGRESS: at 44.29% examples, 922051 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:23:00,876 : INFO : EPOCH 3 - PROGRESS: at 47.94% examples, 929803 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:23:01,899 : INFO : EPOCH 3 - PROGRESS: at 51.25% examples, 929344 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:02,911 : INFO : EPOCH 3 - PROGRESS: at 53.61% examples, 918291 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:23:03,936 : INFO : EPOCH 3 - PROGRESS: at 56.28% examples, 908098 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:04,952 : INFO : EPOCH 3 - PROGRESS: at 59.12% examples, 903179 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:05,965 : INFO : EPOCH 3 - PROGRESS: at 62.22% examples, 903089 words/s, in_qsize 17, out_qsize 3\n",
      "2019-07-14 13:23:06,972 : INFO : EPOCH 3 - PROGRESS: at 65.71% examples, 905926 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 13:23:07,972 : INFO : EPOCH 3 - PROGRESS: at 69.03% examples, 909260 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:08,974 : INFO : EPOCH 3 - PROGRESS: at 72.58% examples, 916582 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 13:23:09,981 : INFO : EPOCH 3 - PROGRESS: at 76.30% examples, 924491 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:10,990 : INFO : EPOCH 3 - PROGRESS: at 79.93% examples, 932013 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:23:11,990 : INFO : EPOCH 3 - PROGRESS: at 83.59% examples, 938514 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:12,992 : INFO : EPOCH 3 - PROGRESS: at 87.40% examples, 945459 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:13,994 : INFO : EPOCH 3 - PROGRESS: at 91.34% examples, 950829 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:23:15,007 : INFO : EPOCH 3 - PROGRESS: at 94.54% examples, 950259 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 13:23:16,011 : INFO : EPOCH 3 - PROGRESS: at 97.40% examples, 946231 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:23:16,793 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:23:16,798 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:23:16,805 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:23:16,808 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:23:16,810 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:23:16,819 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:23:16,826 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:23:16,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:23:16,831 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:23:16,838 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:23:16,839 : INFO : EPOCH - 3 : training on 41519358 raw words (30348494 effective words) took 32.1s, 945095 effective words/s\n",
      "2019-07-14 13:23:17,855 : INFO : EPOCH 4 - PROGRESS: at 2.52% examples, 786797 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 13:23:18,865 : INFO : EPOCH 4 - PROGRESS: at 5.62% examples, 857565 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:19,865 : INFO : EPOCH 4 - PROGRESS: at 8.30% examples, 851891 words/s, in_qsize 19, out_qsize 1\n",
      "2019-07-14 13:23:20,889 : INFO : EPOCH 4 - PROGRESS: at 10.49% examples, 830016 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:21,910 : INFO : EPOCH 4 - PROGRESS: at 12.47% examples, 812962 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:22,924 : INFO : EPOCH 4 - PROGRESS: at 15.21% examples, 830216 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:23:23,934 : INFO : EPOCH 4 - PROGRESS: at 18.39% examples, 872509 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:23:24,935 : INFO : EPOCH 4 - PROGRESS: at 21.81% examples, 913982 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:25,945 : INFO : EPOCH 4 - PROGRESS: at 25.19% examples, 948547 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:23:26,958 : INFO : EPOCH 4 - PROGRESS: at 29.73% examples, 977026 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:27,960 : INFO : EPOCH 4 - PROGRESS: at 34.02% examples, 998687 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:28,963 : INFO : EPOCH 4 - PROGRESS: at 38.34% examples, 1017122 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:29,966 : INFO : EPOCH 4 - PROGRESS: at 42.70% examples, 1032117 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:30,967 : INFO : EPOCH 4 - PROGRESS: at 47.03% examples, 1044176 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:23:31,968 : INFO : EPOCH 4 - PROGRESS: at 51.32% examples, 1056530 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:32,979 : INFO : EPOCH 4 - PROGRESS: at 55.42% examples, 1065877 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:33,985 : INFO : EPOCH 4 - PROGRESS: at 59.65% examples, 1074550 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:34,999 : INFO : EPOCH 4 - PROGRESS: at 63.96% examples, 1081573 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:36,003 : INFO : EPOCH 4 - PROGRESS: at 68.10% examples, 1088588 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:23:37,018 : INFO : EPOCH 4 - PROGRESS: at 72.16% examples, 1095635 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:23:38,032 : INFO : EPOCH 4 - PROGRESS: at 76.26% examples, 1101366 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:39,032 : INFO : EPOCH 4 - PROGRESS: at 80.09% examples, 1105580 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:40,037 : INFO : EPOCH 4 - PROGRESS: at 83.78% examples, 1105739 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:41,041 : INFO : EPOCH 4 - PROGRESS: at 87.34% examples, 1103574 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:23:42,045 : INFO : EPOCH 4 - PROGRESS: at 91.11% examples, 1101754 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:43,045 : INFO : EPOCH 4 - PROGRESS: at 95.00% examples, 1103201 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:23:44,055 : INFO : EPOCH 4 - PROGRESS: at 98.81% examples, 1102793 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:44,289 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:23:44,299 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:23:44,308 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:23:44,310 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:23:44,311 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:23:44,314 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:23:44,316 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:23:44,323 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:23:44,330 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:23:44,332 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:23:44,332 : INFO : EPOCH - 4 : training on 41519358 raw words (30348412 effective words) took 27.5s, 1104124 effective words/s\n",
      "2019-07-14 13:23:45,355 : INFO : EPOCH 5 - PROGRESS: at 3.92% examples, 1191137 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:46,362 : INFO : EPOCH 5 - PROGRESS: at 7.53% examples, 1150293 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:47,363 : INFO : EPOCH 5 - PROGRESS: at 10.72% examples, 1135612 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:48,369 : INFO : EPOCH 5 - PROGRESS: at 13.89% examples, 1139180 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:49,373 : INFO : EPOCH 5 - PROGRESS: at 17.27% examples, 1147262 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:23:50,382 : INFO : EPOCH 5 - PROGRESS: at 20.42% examples, 1153598 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:51,384 : INFO : EPOCH 5 - PROGRESS: at 23.71% examples, 1154718 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:23:52,389 : INFO : EPOCH 5 - PROGRESS: at 27.75% examples, 1157524 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:53,400 : INFO : EPOCH 5 - PROGRESS: at 32.01% examples, 1158937 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:54,402 : INFO : EPOCH 5 - PROGRESS: at 35.80% examples, 1154068 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:23:55,403 : INFO : EPOCH 5 - PROGRESS: at 39.57% examples, 1145982 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:23:56,405 : INFO : EPOCH 5 - PROGRESS: at 43.66% examples, 1143337 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:57,420 : INFO : EPOCH 5 - PROGRESS: at 47.72% examples, 1142222 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:58,426 : INFO : EPOCH 5 - PROGRESS: at 51.92% examples, 1146927 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:23:59,429 : INFO : EPOCH 5 - PROGRESS: at 55.81% examples, 1146748 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:00,433 : INFO : EPOCH 5 - PROGRESS: at 59.61% examples, 1143892 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:01,438 : INFO : EPOCH 5 - PROGRESS: at 63.59% examples, 1142773 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:02,449 : INFO : EPOCH 5 - PROGRESS: at 66.92% examples, 1132826 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:03,455 : INFO : EPOCH 5 - PROGRESS: at 70.43% examples, 1128901 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:04,467 : INFO : EPOCH 5 - PROGRESS: at 74.47% examples, 1130606 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:24:05,469 : INFO : EPOCH 5 - PROGRESS: at 77.87% examples, 1128407 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:06,470 : INFO : EPOCH 5 - PROGRESS: at 81.33% examples, 1125552 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:07,473 : INFO : EPOCH 5 - PROGRESS: at 84.98% examples, 1125196 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:08,502 : INFO : EPOCH 5 - PROGRESS: at 88.35% examples, 1116650 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:09,506 : INFO : EPOCH 5 - PROGRESS: at 91.44% examples, 1106894 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:10,515 : INFO : EPOCH 5 - PROGRESS: at 94.13% examples, 1094512 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:11,525 : INFO : EPOCH 5 - PROGRESS: at 97.89% examples, 1094145 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:11,979 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:24:11,982 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:24:11,984 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:24:11,985 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:24:11,996 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:24:11,998 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:24:11,999 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:24:12,000 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:24:12,009 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:24:12,011 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:24:12,011 : INFO : EPOCH - 5 : training on 41519358 raw words (30350535 effective words) took 27.7s, 1096714 effective words/s\n",
      "2019-07-14 13:24:12,012 : INFO : training on a 207596790 raw words (151746740 effective words) took 144.2s, 1052544 effective words/s\n",
      "2019-07-14 13:24:12,012 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-07-14 13:24:12,013 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-07-14 13:24:13,020 : INFO : EPOCH 1 - PROGRESS: at 3.90% examples, 1203380 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:14,022 : INFO : EPOCH 1 - PROGRESS: at 7.64% examples, 1179959 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:15,030 : INFO : EPOCH 1 - PROGRESS: at 11.11% examples, 1192823 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:16,037 : INFO : EPOCH 1 - PROGRESS: at 14.52% examples, 1194707 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:17,041 : INFO : EPOCH 1 - PROGRESS: at 17.39% examples, 1160069 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:24:18,051 : INFO : EPOCH 1 - PROGRESS: at 20.18% examples, 1141446 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:19,074 : INFO : EPOCH 1 - PROGRESS: at 22.90% examples, 1106143 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 13:24:20,082 : INFO : EPOCH 1 - PROGRESS: at 25.45% examples, 1079353 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:21,087 : INFO : EPOCH 1 - PROGRESS: at 28.54% examples, 1052147 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:22,102 : INFO : EPOCH 1 - PROGRESS: at 31.68% examples, 1031377 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:23,102 : INFO : EPOCH 1 - PROGRESS: at 35.00% examples, 1027050 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:24,103 : INFO : EPOCH 1 - PROGRESS: at 38.04% examples, 1013476 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:25,103 : INFO : EPOCH 1 - PROGRESS: at 41.85% examples, 1014804 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:26,126 : INFO : EPOCH 1 - PROGRESS: at 45.28% examples, 1008636 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:27,137 : INFO : EPOCH 1 - PROGRESS: at 48.11% examples, 995983 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:24:28,143 : INFO : EPOCH 1 - PROGRESS: at 51.78% examples, 999437 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:29,148 : INFO : EPOCH 1 - PROGRESS: at 55.00% examples, 998066 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:30,153 : INFO : EPOCH 1 - PROGRESS: at 58.20% examples, 992901 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:31,162 : INFO : EPOCH 1 - PROGRESS: at 61.37% examples, 988612 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 13:24:32,184 : INFO : EPOCH 1 - PROGRESS: at 64.80% examples, 984330 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:24:33,195 : INFO : EPOCH 1 - PROGRESS: at 68.09% examples, 984744 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:34,214 : INFO : EPOCH 1 - PROGRESS: at 71.59% examples, 987913 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:35,216 : INFO : EPOCH 1 - PROGRESS: at 75.07% examples, 988990 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:24:36,217 : INFO : EPOCH 1 - PROGRESS: at 78.37% examples, 991813 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:24:37,228 : INFO : EPOCH 1 - PROGRESS: at 81.87% examples, 994299 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:38,234 : INFO : EPOCH 1 - PROGRESS: at 85.29% examples, 996469 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:39,235 : INFO : EPOCH 1 - PROGRESS: at 89.28% examples, 1000942 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:40,253 : INFO : EPOCH 1 - PROGRESS: at 92.75% examples, 1000381 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:24:41,264 : INFO : EPOCH 1 - PROGRESS: at 95.89% examples, 997170 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:42,266 : INFO : EPOCH 1 - PROGRESS: at 98.94% examples, 993177 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:42,509 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:24:42,523 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:24:42,527 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:24:42,529 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:24:42,533 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:24:42,538 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:24:42,539 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:24:42,546 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:24:42,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:24:42,563 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:24:42,564 : INFO : EPOCH - 1 : training on 41519358 raw words (30348300 effective words) took 30.5s, 993533 effective words/s\n",
      "2019-07-14 13:24:43,587 : INFO : EPOCH 2 - PROGRESS: at 3.34% examples, 1024887 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:24:44,590 : INFO : EPOCH 2 - PROGRESS: at 6.86% examples, 1047356 words/s, in_qsize 18, out_qsize 0\n",
      "2019-07-14 13:24:45,590 : INFO : EPOCH 2 - PROGRESS: at 10.16% examples, 1076509 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:46,601 : INFO : EPOCH 2 - PROGRESS: at 13.59% examples, 1111732 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:24:47,630 : INFO : EPOCH 2 - PROGRESS: at 17.08% examples, 1127615 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:48,630 : INFO : EPOCH 2 - PROGRESS: at 20.32% examples, 1145190 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:49,632 : INFO : EPOCH 2 - PROGRESS: at 23.73% examples, 1153647 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:50,633 : INFO : EPOCH 2 - PROGRESS: at 27.75% examples, 1156162 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:51,634 : INFO : EPOCH 2 - PROGRESS: at 31.75% examples, 1150268 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:24:52,637 : INFO : EPOCH 2 - PROGRESS: at 35.27% examples, 1138931 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:53,644 : INFO : EPOCH 2 - PROGRESS: at 38.62% examples, 1119846 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:24:54,651 : INFO : EPOCH 2 - PROGRESS: at 42.41% examples, 1113582 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:55,654 : INFO : EPOCH 2 - PROGRESS: at 45.97% examples, 1102655 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:56,672 : INFO : EPOCH 2 - PROGRESS: at 50.11% examples, 1107761 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:57,675 : INFO : EPOCH 2 - PROGRESS: at 53.87% examples, 1110386 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:24:58,679 : INFO : EPOCH 2 - PROGRESS: at 57.52% examples, 1104967 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:24:59,691 : INFO : EPOCH 2 - PROGRESS: at 61.66% examples, 1110652 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:00,692 : INFO : EPOCH 2 - PROGRESS: at 65.96% examples, 1116506 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:25:01,692 : INFO : EPOCH 2 - PROGRESS: at 69.94% examples, 1120434 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:02,700 : INFO : EPOCH 2 - PROGRESS: at 74.17% examples, 1125879 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:25:03,723 : INFO : EPOCH 2 - PROGRESS: at 77.82% examples, 1126526 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:25:04,759 : INFO : EPOCH 2 - PROGRESS: at 80.92% examples, 1117095 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 13:25:05,768 : INFO : EPOCH 2 - PROGRESS: at 84.88% examples, 1120557 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:25:06,770 : INFO : EPOCH 2 - PROGRESS: at 89.08% examples, 1123378 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:07,772 : INFO : EPOCH 2 - PROGRESS: at 92.93% examples, 1123106 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:08,781 : INFO : EPOCH 2 - PROGRESS: at 96.71% examples, 1121986 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:09,511 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:25:09,517 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:25:09,526 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:25:09,527 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:25:09,528 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:25:09,529 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:25:09,531 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:25:09,535 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:25:09,543 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:25:09,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:25:09,552 : INFO : EPOCH - 2 : training on 41519358 raw words (30345473 effective words) took 27.0s, 1124781 effective words/s\n",
      "2019-07-14 13:25:10,558 : INFO : EPOCH 3 - PROGRESS: at 3.90% examples, 1204284 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:11,567 : INFO : EPOCH 3 - PROGRESS: at 7.82% examples, 1204419 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:12,571 : INFO : EPOCH 3 - PROGRESS: at 11.30% examples, 1210969 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:13,585 : INFO : EPOCH 3 - PROGRESS: at 14.52% examples, 1191881 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:14,586 : INFO : EPOCH 3 - PROGRESS: at 17.94% examples, 1198356 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:15,592 : INFO : EPOCH 3 - PROGRESS: at 21.03% examples, 1197151 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:16,612 : INFO : EPOCH 3 - PROGRESS: at 24.54% examples, 1198886 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:17,625 : INFO : EPOCH 3 - PROGRESS: at 29.10% examples, 1201284 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:25:18,634 : INFO : EPOCH 3 - PROGRESS: at 33.47% examples, 1202778 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:19,644 : INFO : EPOCH 3 - PROGRESS: at 37.10% examples, 1187691 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:20,659 : INFO : EPOCH 3 - PROGRESS: at 41.25% examples, 1182234 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:21,675 : INFO : EPOCH 3 - PROGRESS: at 45.72% examples, 1184202 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:22,687 : INFO : EPOCH 3 - PROGRESS: at 50.06% examples, 1188362 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:23,703 : INFO : EPOCH 3 - PROGRESS: at 53.96% examples, 1186910 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:24,710 : INFO : EPOCH 3 - PROGRESS: at 57.86% examples, 1181561 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:25,715 : INFO : EPOCH 3 - PROGRESS: at 61.86% examples, 1180230 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:26,718 : INFO : EPOCH 3 - PROGRESS: at 65.87% examples, 1177187 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:27,727 : INFO : EPOCH 3 - PROGRESS: at 69.86% examples, 1177423 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:28,727 : INFO : EPOCH 3 - PROGRESS: at 73.93% examples, 1178020 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:29,733 : INFO : EPOCH 3 - PROGRESS: at 77.63% examples, 1178138 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:30,742 : INFO : EPOCH 3 - PROGRESS: at 81.43% examples, 1177446 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:25:31,744 : INFO : EPOCH 3 - PROGRESS: at 85.44% examples, 1179652 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:32,751 : INFO : EPOCH 3 - PROGRESS: at 89.85% examples, 1181678 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:33,762 : INFO : EPOCH 3 - PROGRESS: at 93.80% examples, 1179733 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:34,765 : INFO : EPOCH 3 - PROGRESS: at 97.41% examples, 1174275 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:35,350 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:25:35,357 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:25:35,359 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:25:35,368 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:25:35,374 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:25:35,375 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:25:35,379 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:25:35,385 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:25:35,386 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:25:35,386 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:25:35,387 : INFO : EPOCH - 3 : training on 41519358 raw words (30348326 effective words) took 25.8s, 1174917 effective words/s\n",
      "2019-07-14 13:25:36,396 : INFO : EPOCH 4 - PROGRESS: at 3.49% examples, 1079007 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:37,401 : INFO : EPOCH 4 - PROGRESS: at 7.22% examples, 1109812 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:38,413 : INFO : EPOCH 4 - PROGRESS: at 10.20% examples, 1080279 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:25:39,425 : INFO : EPOCH 4 - PROGRESS: at 12.89% examples, 1055287 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:25:40,439 : INFO : EPOCH 4 - PROGRESS: at 15.49% examples, 1016024 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:25:41,451 : INFO : EPOCH 4 - PROGRESS: at 17.82% examples, 988127 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:42,465 : INFO : EPOCH 4 - PROGRESS: at 20.13% examples, 970764 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 13:25:43,468 : INFO : EPOCH 4 - PROGRESS: at 22.90% examples, 966665 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:44,472 : INFO : EPOCH 4 - PROGRESS: at 25.60% examples, 963520 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:45,496 : INFO : EPOCH 4 - PROGRESS: at 28.78% examples, 951024 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:25:46,498 : INFO : EPOCH 4 - PROGRESS: at 32.35% examples, 954176 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:47,500 : INFO : EPOCH 4 - PROGRESS: at 35.94% examples, 962344 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:25:48,518 : INFO : EPOCH 4 - PROGRESS: at 39.54% examples, 965105 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:49,521 : INFO : EPOCH 4 - PROGRESS: at 43.31% examples, 970014 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:50,529 : INFO : EPOCH 4 - PROGRESS: at 47.16% examples, 976816 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:51,546 : INFO : EPOCH 4 - PROGRESS: at 50.72% examples, 978241 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:52,547 : INFO : EPOCH 4 - PROGRESS: at 54.22% examples, 983628 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:53,562 : INFO : EPOCH 4 - PROGRESS: at 58.01% examples, 988375 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:54,574 : INFO : EPOCH 4 - PROGRESS: at 61.73% examples, 992469 words/s, in_qsize 18, out_qsize 2\n",
      "2019-07-14 13:25:55,580 : INFO : EPOCH 4 - PROGRESS: at 65.30% examples, 991607 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:56,582 : INFO : EPOCH 4 - PROGRESS: at 68.87% examples, 995199 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:25:57,594 : INFO : EPOCH 4 - PROGRESS: at 72.37% examples, 998556 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:58,607 : INFO : EPOCH 4 - PROGRESS: at 75.97% examples, 1000907 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:25:59,619 : INFO : EPOCH 4 - PROGRESS: at 78.93% examples, 997951 words/s, in_qsize 18, out_qsize 2\n",
      "2019-07-14 13:26:00,623 : INFO : EPOCH 4 - PROGRESS: at 82.52% examples, 1001340 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:01,629 : INFO : EPOCH 4 - PROGRESS: at 86.22% examples, 1006245 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:26:02,630 : INFO : EPOCH 4 - PROGRESS: at 90.50% examples, 1013014 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:03,647 : INFO : EPOCH 4 - PROGRESS: at 94.71% examples, 1020239 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:04,651 : INFO : EPOCH 4 - PROGRESS: at 98.94% examples, 1026851 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:04,842 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:26:04,856 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:26:04,858 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:26:04,861 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:26:04,862 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:26:04,870 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:26:04,880 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:26:04,881 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:26:04,887 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:26:04,890 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:26:04,891 : INFO : EPOCH - 4 : training on 41519358 raw words (30350051 effective words) took 29.5s, 1028898 effective words/s\n",
      "2019-07-14 13:26:05,900 : INFO : EPOCH 5 - PROGRESS: at 3.84% examples, 1187597 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:06,911 : INFO : EPOCH 5 - PROGRESS: at 7.85% examples, 1206487 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:07,920 : INFO : EPOCH 5 - PROGRESS: at 11.30% examples, 1207697 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:08,921 : INFO : EPOCH 5 - PROGRESS: at 14.65% examples, 1203987 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:09,930 : INFO : EPOCH 5 - PROGRESS: at 18.09% examples, 1207816 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:10,936 : INFO : EPOCH 5 - PROGRESS: at 21.54% examples, 1207940 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:11,942 : INFO : EPOCH 5 - PROGRESS: at 24.67% examples, 1207066 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:12,942 : INFO : EPOCH 5 - PROGRESS: at 29.15% examples, 1206815 words/s, in_qsize 19, out_qsize 1\n",
      "2019-07-14 13:26:13,944 : INFO : EPOCH 5 - PROGRESS: at 33.50% examples, 1207901 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:14,953 : INFO : EPOCH 5 - PROGRESS: at 37.68% examples, 1207952 words/s, in_qsize 18, out_qsize 2\n",
      "2019-07-14 13:26:15,965 : INFO : EPOCH 5 - PROGRESS: at 42.16% examples, 1208168 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:16,968 : INFO : EPOCH 5 - PROGRESS: at 46.45% examples, 1206931 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:17,968 : INFO : EPOCH 5 - PROGRESS: at 50.68% examples, 1208209 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:18,970 : INFO : EPOCH 5 - PROGRESS: at 54.63% examples, 1207674 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:19,970 : INFO : EPOCH 5 - PROGRESS: at 58.90% examples, 1208001 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:20,974 : INFO : EPOCH 5 - PROGRESS: at 63.11% examples, 1208340 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:26:21,980 : INFO : EPOCH 5 - PROGRESS: at 67.38% examples, 1208570 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:22,987 : INFO : EPOCH 5 - PROGRESS: at 71.36% examples, 1208699 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:24,000 : INFO : EPOCH 5 - PROGRESS: at 75.54% examples, 1209131 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:25,006 : INFO : EPOCH 5 - PROGRESS: at 79.47% examples, 1210050 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:26,015 : INFO : EPOCH 5 - PROGRESS: at 83.50% examples, 1209912 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:27,018 : INFO : EPOCH 5 - PROGRESS: at 87.70% examples, 1211329 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:28,026 : INFO : EPOCH 5 - PROGRESS: at 91.96% examples, 1211002 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:29,036 : INFO : EPOCH 5 - PROGRESS: at 96.09% examples, 1210868 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:29,900 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:26:29,910 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:26:29,914 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:26:29,921 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:26:29,930 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:26:29,935 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:26:29,937 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:26:29,940 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:26:29,941 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:26:29,944 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:26:29,944 : INFO : EPOCH - 5 : training on 41519358 raw words (30347769 effective words) took 25.0s, 1211644 effective words/s\n",
      "2019-07-14 13:26:30,955 : INFO : EPOCH 6 - PROGRESS: at 3.86% examples, 1193997 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:31,959 : INFO : EPOCH 6 - PROGRESS: at 7.85% examples, 1210179 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:32,969 : INFO : EPOCH 6 - PROGRESS: at 11.30% examples, 1210228 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:33,976 : INFO : EPOCH 6 - PROGRESS: at 14.69% examples, 1207715 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:34,977 : INFO : EPOCH 6 - PROGRESS: at 18.05% examples, 1206861 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:35,990 : INFO : EPOCH 6 - PROGRESS: at 21.52% examples, 1206864 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:36,992 : INFO : EPOCH 6 - PROGRESS: at 24.69% examples, 1208946 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:38,003 : INFO : EPOCH 6 - PROGRESS: at 29.17% examples, 1206899 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:39,003 : INFO : EPOCH 6 - PROGRESS: at 33.48% examples, 1207335 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:40,010 : INFO : EPOCH 6 - PROGRESS: at 37.45% examples, 1201414 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:41,011 : INFO : EPOCH 6 - PROGRESS: at 41.38% examples, 1190404 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:42,012 : INFO : EPOCH 6 - PROGRESS: at 45.81% examples, 1192496 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:43,020 : INFO : EPOCH 6 - PROGRESS: at 50.00% examples, 1193170 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 13:26:44,021 : INFO : EPOCH 6 - PROGRESS: at 54.02% examples, 1195182 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:45,024 : INFO : EPOCH 6 - PROGRESS: at 58.27% examples, 1196230 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:46,025 : INFO : EPOCH 6 - PROGRESS: at 62.37% examples, 1195636 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:47,037 : INFO : EPOCH 6 - PROGRESS: at 66.73% examples, 1197608 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:48,039 : INFO : EPOCH 6 - PROGRESS: at 70.64% examples, 1196870 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:49,046 : INFO : EPOCH 6 - PROGRESS: at 74.84% examples, 1197592 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:50,055 : INFO : EPOCH 6 - PROGRESS: at 78.74% examples, 1199448 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:51,058 : INFO : EPOCH 6 - PROGRESS: at 82.80% examples, 1200770 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:52,060 : INFO : EPOCH 6 - PROGRESS: at 86.78% examples, 1200934 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:53,064 : INFO : EPOCH 6 - PROGRESS: at 91.11% examples, 1201289 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:26:54,069 : INFO : EPOCH 6 - PROGRESS: at 95.21% examples, 1200906 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:55,071 : INFO : EPOCH 6 - PROGRESS: at 99.32% examples, 1200672 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:26:55,177 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:26:55,179 : INFO : worker thread finished; awaiting finish of 8 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:26:55,185 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:26:55,190 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:26:55,192 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:26:55,193 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:26:55,204 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:26:55,209 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:26:55,215 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:26:55,220 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:26:55,221 : INFO : EPOCH - 6 : training on 41519358 raw words (30350522 effective words) took 25.3s, 1201083 effective words/s\n",
      "2019-07-14 13:26:56,231 : INFO : EPOCH 7 - PROGRESS: at 3.53% examples, 1092052 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:57,234 : INFO : EPOCH 7 - PROGRESS: at 7.51% examples, 1155846 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:58,240 : INFO : EPOCH 7 - PROGRESS: at 11.00% examples, 1178082 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:26:59,241 : INFO : EPOCH 7 - PROGRESS: at 14.44% examples, 1188670 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:00,246 : INFO : EPOCH 7 - PROGRESS: at 17.85% examples, 1193796 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:01,248 : INFO : EPOCH 7 - PROGRESS: at 20.92% examples, 1192695 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:27:02,250 : INFO : EPOCH 7 - PROGRESS: at 24.31% examples, 1191097 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:03,261 : INFO : EPOCH 7 - PROGRESS: at 28.49% examples, 1185899 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:27:04,265 : INFO : EPOCH 7 - PROGRESS: at 32.85% examples, 1188243 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:05,278 : INFO : EPOCH 7 - PROGRESS: at 37.00% examples, 1189903 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:06,279 : INFO : EPOCH 7 - PROGRESS: at 41.43% examples, 1192376 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:07,285 : INFO : EPOCH 7 - PROGRESS: at 45.92% examples, 1195051 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:08,290 : INFO : EPOCH 7 - PROGRESS: at 50.16% examples, 1196780 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:09,297 : INFO : EPOCH 7 - PROGRESS: at 54.12% examples, 1197008 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:10,303 : INFO : EPOCH 7 - PROGRESS: at 58.41% examples, 1198748 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:11,322 : INFO : EPOCH 7 - PROGRESS: at 62.68% examples, 1199317 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:12,336 : INFO : EPOCH 7 - PROGRESS: at 66.95% examples, 1199671 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:27:13,341 : INFO : EPOCH 7 - PROGRESS: at 70.97% examples, 1201058 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:14,347 : INFO : EPOCH 7 - PROGRESS: at 75.13% examples, 1201225 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:15,350 : INFO : EPOCH 7 - PROGRESS: at 78.97% examples, 1202135 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:16,359 : INFO : EPOCH 7 - PROGRESS: at 83.05% examples, 1202729 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:17,365 : INFO : EPOCH 7 - PROGRESS: at 87.06% examples, 1202641 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:27:18,380 : INFO : EPOCH 7 - PROGRESS: at 91.22% examples, 1200724 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:19,401 : INFO : EPOCH 7 - PROGRESS: at 95.49% examples, 1201425 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:27:20,404 : INFO : EPOCH 7 - PROGRESS: at 99.68% examples, 1201952 words/s, in_qsize 12, out_qsize 1\n",
      "2019-07-14 13:27:20,423 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:27:20,428 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:27:20,441 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:27:20,449 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:27:20,453 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:27:20,460 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:27:20,464 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:27:20,465 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:27:20,469 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:27:20,479 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:27:20,480 : INFO : EPOCH - 7 : training on 41519358 raw words (30352383 effective words) took 25.3s, 1201873 effective words/s\n",
      "2019-07-14 13:27:21,488 : INFO : EPOCH 8 - PROGRESS: at 3.82% examples, 1182742 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:22,493 : INFO : EPOCH 8 - PROGRESS: at 7.75% examples, 1197186 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:23,495 : INFO : EPOCH 8 - PROGRESS: at 11.11% examples, 1195101 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:24,495 : INFO : EPOCH 8 - PROGRESS: at 14.50% examples, 1196289 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:25,510 : INFO : EPOCH 8 - PROGRESS: at 17.91% examples, 1197408 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:27:26,513 : INFO : EPOCH 8 - PROGRESS: at 21.04% examples, 1200445 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:27,520 : INFO : EPOCH 8 - PROGRESS: at 24.52% examples, 1201993 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:28,522 : INFO : EPOCH 8 - PROGRESS: at 28.97% examples, 1202036 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:29,534 : INFO : EPOCH 8 - PROGRESS: at 33.31% examples, 1201409 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:30,536 : INFO : EPOCH 8 - PROGRESS: at 37.45% examples, 1202328 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:31,546 : INFO : EPOCH 8 - PROGRESS: at 41.92% examples, 1202558 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:32,557 : INFO : EPOCH 8 - PROGRESS: at 46.29% examples, 1202709 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:33,574 : INFO : EPOCH 8 - PROGRESS: at 50.50% examples, 1202205 words/s, in_qsize 18, out_qsize 2\n",
      "2019-07-14 13:27:34,575 : INFO : EPOCH 8 - PROGRESS: at 54.30% examples, 1199078 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:35,580 : INFO : EPOCH 8 - PROGRESS: at 58.39% examples, 1196824 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:27:36,581 : INFO : EPOCH 8 - PROGRESS: at 62.62% examples, 1198415 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:37,585 : INFO : EPOCH 8 - PROGRESS: at 66.83% examples, 1198628 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:38,585 : INFO : EPOCH 8 - PROGRESS: at 70.82% examples, 1199232 words/s, in_qsize 16, out_qsize 3\n",
      "2019-07-14 13:27:39,589 : INFO : EPOCH 8 - PROGRESS: at 75.07% examples, 1201036 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:40,589 : INFO : EPOCH 8 - PROGRESS: at 78.86% examples, 1201409 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:41,591 : INFO : EPOCH 8 - PROGRESS: at 82.69% examples, 1199048 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:42,597 : INFO : EPOCH 8 - PROGRESS: at 86.68% examples, 1199489 words/s, in_qsize 20, out_qsize 2\n",
      "2019-07-14 13:27:43,598 : INFO : EPOCH 8 - PROGRESS: at 90.83% examples, 1197887 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:44,603 : INFO : EPOCH 8 - PROGRESS: at 95.01% examples, 1198862 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:45,611 : INFO : EPOCH 8 - PROGRESS: at 99.28% examples, 1199861 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:45,736 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:27:45,741 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:27:45,748 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:27:45,753 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:27:45,759 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:27:45,764 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:27:45,777 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:27:45,778 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:27:45,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:27:45,782 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:27:45,783 : INFO : EPOCH - 8 : training on 41519358 raw words (30348177 effective words) took 25.3s, 1199775 effective words/s\n",
      "2019-07-14 13:27:46,813 : INFO : EPOCH 9 - PROGRESS: at 3.86% examples, 1169595 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:47,825 : INFO : EPOCH 9 - PROGRESS: at 7.79% examples, 1185905 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:27:48,830 : INFO : EPOCH 9 - PROGRESS: at 11.28% examples, 1200116 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:49,831 : INFO : EPOCH 9 - PROGRESS: at 14.67% examples, 1200180 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:27:50,832 : INFO : EPOCH 9 - PROGRESS: at 18.04% examples, 1202286 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:27:51,833 : INFO : EPOCH 9 - PROGRESS: at 21.52% examples, 1205665 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:52,842 : INFO : EPOCH 9 - PROGRESS: at 24.62% examples, 1203549 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:27:53,850 : INFO : EPOCH 9 - PROGRESS: at 29.17% examples, 1205259 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:54,858 : INFO : EPOCH 9 - PROGRESS: at 33.48% examples, 1204866 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:55,863 : INFO : EPOCH 9 - PROGRESS: at 37.59% examples, 1203669 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:56,870 : INFO : EPOCH 9 - PROGRESS: at 42.10% examples, 1204823 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:27:57,870 : INFO : EPOCH 9 - PROGRESS: at 46.44% examples, 1205910 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:27:58,874 : INFO : EPOCH 9 - PROGRESS: at 50.61% examples, 1204783 words/s, in_qsize 17, out_qsize 2\n",
      "2019-07-14 13:27:59,874 : INFO : EPOCH 9 - PROGRESS: at 54.59% examples, 1205673 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:28:00,877 : INFO : EPOCH 9 - PROGRESS: at 58.88% examples, 1206450 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:01,894 : INFO : EPOCH 9 - PROGRESS: at 63.10% examples, 1205803 words/s, in_qsize 20, out_qsize 1\n",
      "2019-07-14 13:28:02,899 : INFO : EPOCH 9 - PROGRESS: at 67.30% examples, 1205508 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:28:03,902 : INFO : EPOCH 9 - PROGRESS: at 71.29% examples, 1206360 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:28:04,902 : INFO : EPOCH 9 - PROGRESS: at 75.43% examples, 1206187 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:05,904 : INFO : EPOCH 9 - PROGRESS: at 79.27% examples, 1206584 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:06,913 : INFO : EPOCH 9 - PROGRESS: at 83.29% examples, 1206574 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:07,916 : INFO : EPOCH 9 - PROGRESS: at 87.32% examples, 1206763 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:08,919 : INFO : EPOCH 9 - PROGRESS: at 91.63% examples, 1206926 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:09,927 : INFO : EPOCH 9 - PROGRESS: at 95.71% examples, 1205865 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:10,892 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:28:10,904 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:28:10,913 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:28:10,914 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:28:10,916 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:28:10,929 : INFO : EPOCH 9 - PROGRESS: at 99.92% examples, 1206167 words/s, in_qsize 4, out_qsize 1\n",
      "2019-07-14 13:28:10,931 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:28:10,932 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:28:10,933 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:28:10,941 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:28:10,944 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:28:10,945 : INFO : EPOCH - 9 : training on 41519358 raw words (30349386 effective words) took 25.2s, 1206430 effective words/s\n",
      "2019-07-14 13:28:11,962 : INFO : EPOCH 10 - PROGRESS: at 3.85% examples, 1177360 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:12,965 : INFO : EPOCH 10 - PROGRESS: at 7.84% examples, 1205199 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:13,973 : INFO : EPOCH 10 - PROGRESS: at 11.30% examples, 1207846 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:14,974 : INFO : EPOCH 10 - PROGRESS: at 14.72% examples, 1209441 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:28:15,991 : INFO : EPOCH 10 - PROGRESS: at 18.09% examples, 1205856 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:16,991 : INFO : EPOCH 10 - PROGRESS: at 21.57% examples, 1209834 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:17,997 : INFO : EPOCH 10 - PROGRESS: at 24.76% examples, 1209446 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:19,003 : INFO : EPOCH 10 - PROGRESS: at 29.26% examples, 1209805 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:28:20,011 : INFO : EPOCH 10 - PROGRESS: at 33.66% examples, 1212157 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:21,018 : INFO : EPOCH 10 - PROGRESS: at 37.85% examples, 1210584 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:22,023 : INFO : EPOCH 10 - PROGRESS: at 42.28% examples, 1210577 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:28:23,026 : INFO : EPOCH 10 - PROGRESS: at 46.62% examples, 1210330 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:24,031 : INFO : EPOCH 10 - PROGRESS: at 50.83% examples, 1209800 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:28:25,035 : INFO : EPOCH 10 - PROGRESS: at 54.82% examples, 1210547 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:26,042 : INFO : EPOCH 10 - PROGRESS: at 59.10% examples, 1209684 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:28:27,047 : INFO : EPOCH 10 - PROGRESS: at 63.33% examples, 1209719 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:28,060 : INFO : EPOCH 10 - PROGRESS: at 67.42% examples, 1207331 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:29,075 : INFO : EPOCH 10 - PROGRESS: at 71.54% examples, 1208897 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:30,082 : INFO : EPOCH 10 - PROGRESS: at 75.66% examples, 1208932 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:31,085 : INFO : EPOCH 10 - PROGRESS: at 79.55% examples, 1209477 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:32,093 : INFO : EPOCH 10 - PROGRESS: at 83.55% examples, 1209341 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:33,095 : INFO : EPOCH 10 - PROGRESS: at 87.64% examples, 1209217 words/s, in_qsize 20, out_qsize 0\n",
      "2019-07-14 13:28:34,099 : INFO : EPOCH 10 - PROGRESS: at 91.91% examples, 1209194 words/s, in_qsize 18, out_qsize 1\n",
      "2019-07-14 13:28:35,101 : INFO : EPOCH 10 - PROGRESS: at 96.05% examples, 1209518 words/s, in_qsize 19, out_qsize 0\n",
      "2019-07-14 13:28:35,992 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-07-14 13:28:35,993 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-07-14 13:28:36,004 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-07-14 13:28:36,014 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-07-14 13:28:36,017 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-07-14 13:28:36,022 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-07-14 13:28:36,029 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-07-14 13:28:36,030 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-07-14 13:28:36,035 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-07-14 13:28:36,042 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-07-14 13:28:36,043 : INFO : EPOCH - 10 : training on 41519358 raw words (30343997 effective words) took 25.1s, 1209293 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:28:36,044 : INFO : training on a 415193580 raw words (303484384 effective words) took 264.0s, 1149428 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(303484384, 415193580)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's look at some output \n",
    "This first example shows a simple case of looking up words similar to the word `dirty`. All we need to do here is to call the `most_similar` function and provide the word `dirty` as the positive example. This returns the top 10 similar words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-14 13:28:36,059 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.8629568815231323),\n",
       " ('stained', 0.7823047637939453),\n",
       " ('grubby', 0.7788145542144775),\n",
       " ('dusty', 0.7734365463256836),\n",
       " ('smelly', 0.7699148654937744),\n",
       " ('unclean', 0.7689845561981201),\n",
       " ('dingy', 0.7349340319633484),\n",
       " ('mouldy', 0.7272517681121826),\n",
       " ('soiled', 0.7271710634231567),\n",
       " ('gross', 0.719116747379303)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w1 = \"dirty\"\n",
    "model.wv.most_similar (positive=w1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good, right? Let's look at a few more. Let's look at similarity for `polite`, `france` and `shocked`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.9275883436203003),\n",
       " ('friendly', 0.8336566686630249),\n",
       " ('cordial', 0.8042970895767212),\n",
       " ('professional', 0.788394570350647),\n",
       " ('attentive', 0.7790228724479675),\n",
       " ('curteous', 0.7520910501480103)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'polite'\n",
    "w1 = [\"polite\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canada', 0.6419494152069092),\n",
       " ('germany', 0.6231887340545654),\n",
       " ('spain', 0.6080336570739746),\n",
       " ('england', 0.6063601970672607),\n",
       " ('gaulle', 0.5965712666511536),\n",
       " ('angeles', 0.59413743019104)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'france'\n",
    "w1 = [\"france\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amazed', 0.7959094643592834),\n",
       " ('horrified', 0.7951109409332275),\n",
       " ('stunned', 0.778906524181366),\n",
       " ('appalled', 0.7667439579963684),\n",
       " ('dismayed', 0.7525988817214966),\n",
       " ('astonished', 0.7487436532974243)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'shocked'\n",
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's, nice. You can even specify several positive examples to get things that are related in the provided context and provide negative examples to say what should not be considered as related. In the example below we are asking for all items that *relate to bed* only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duvet', 0.7161251306533813),\n",
       " ('blanket', 0.709022045135498),\n",
       " ('mattress', 0.7010205984115601),\n",
       " ('quilt', 0.6725625991821289),\n",
       " ('pillowcase', 0.6602649092674255),\n",
       " ('matress', 0.6564290523529053),\n",
       " ('pillows', 0.6434866189956665),\n",
       " ('sheets', 0.637667179107666),\n",
       " ('foam', 0.6116433143615723),\n",
       " ('satin', 0.6027736663818359)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get everything related to stuff on the bed\n",
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between two words in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even use the Word2Vec model to return the similarity between two words that are present in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7699148"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two identical words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2670418"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two unrelated words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the above three snippets computes the cosine similarity between the two specified words using word vectors of each. From the scores, it makes sense that `dirty` is highly similar to `smelly` but `dirty` is dissimilar to `clean`. If you do a similarity between two identical words, the score will be 1.0 as the range of the cosine similarity score will always be between [0.0-1.0]. You can read more about cosine similarity scoring [here](https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the odd one out\n",
    "You can even use Word2Vec to find odd items given a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geanderson/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:876: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding some of the parameters\n",
    "To train the model earlier, we had to set some parameters. Now, let's try to understand what some of them mean. For reference, this is the command that we used to train the model.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `size`\n",
    "The size of the dense vector to represent each token or word. If you have very limited data, then size should be a much smaller value. If you have lots of data, its good to experiment with various sizes. A value of 100-150 has worked well for me. \n",
    "\n",
    "### `window`\n",
    "The maximum distance between the target word and its neighboring word. If your neighbor's position is greater than the maximum window width to the left and the right, then, some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as its a decent sized window. \n",
    "\n",
    "### `min_count`\n",
    "Minimium frequency count of words. The model would ignore words that do not statisfy the `min_count`. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.\n",
    "\n",
    "### `workers`\n",
    "How many threads to use behind the scenes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When should you use Word2Vec?\n",
    "\n",
    "There are many application scenarios for Word2Vec. Imagine if you need to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you achieve that. You have a lexicon for not just sentiment, but for most words in the vocabulary. \n",
    "\n",
    "Beyond, raw unstructured text data, you could also use Word2Vec for more structured data. For example, if you had tags for a million stackoverflow questions and answers, you could find tags that are related to a given tag and recommend the related ones for exploration. You can do this by treating each set of co-occuring tags as a \"sentence\" and train a Word2Vec model on this data. Granted, you still need a large number of examples to make it work. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
