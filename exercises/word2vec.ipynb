{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a85b978e287eaa4218d41d2884c53e1c77ae576"
   },
   "source": [
    "# Word Embeddings em um Dataset Aberto\n",
    "\n",
    "## Atividade Avaliativa\n",
    "\n",
    "Neste TP você deve explorar e criar os embeddings utilizando uma base de dados de sua preferência. Uma sugestão para encontrar bases que podem ser utilizadas seria a partir das competições do [Kaggle](https://www.kaggle.com/).\n",
    "\n",
    "Para essa prática, solicito que o aluno prepare a base de dados e gere os embeddings utilizando obrigatoriamente o algoritmo Word2Vec. Dependendo do contexto da base, você pode utilizar o Doc2Vec em vez do Word2Vec ou ambos. \n",
    "\n",
    "As 4 etapas descritas abaixo devem ser seguidas obrigatoriamente:\n",
    "\n",
    "1. Preparação da base de dados utilizando no mínimo uma técnica de tokenização. (25 pontos).\n",
    "2. Execução do Modelo Word2Vec usando o Gensim, ou outra implementação similar. (30 pontos)\n",
    "3. Teste do seu embedding assim como foi realizado na [demo](https://github.com/gesteves91/nlp/blob/master/notebooks/06-word2vec.ipynb). (30 pontos)\n",
    "4. O seu notebook deve ser comentado explicando cada célula executada no notebook. (15 pontos)\n",
    "\n",
    "A atividade deve ser enviada para **esteves.gean@gmail.com**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}