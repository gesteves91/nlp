{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciando com Word2Vec com Gensim!\n",
    "  \n",
    "A ideia por trás do Word2Vec é bem simples. Estamos supondo que você pode inferir o significado de uma palavra pela composição que ela mantém. Isso é análogo ao ditado popular \"mostre-me seus amigos e eu direi quem você é\". Então, se você tem duas palavras que têm vizinhos muito semelhantes (ou seja, o contexto de uso é aproximadamente o mesmo), então essas palavras são provavelmente muito semelhantes em significado ou pelo menos altamente relacionadas. Por exemplo, as palavras em inglês `shocked`,` appalled` e `astonished` são tipicamente usadas em um contexto similar.\n",
    "\n",
    "A implementação do Gensim é baseada no artigo [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) e foi extendido com funcionalidades novas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports e logging\n",
    "\n",
    "Primeiro, começamos com os imports e o logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports necessários para configurar o logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Em seguida, manipularemos nosso conjunto de dados. O segredo para fazer o Word2Vec funcionar é ter muitos dados no formato de texto. Neste caso, uma boa base de dados pode ser encontrada no seguinte link: [OpinRank] (http://kavita-ganesan.com/entity-ranking-data/). Este conjunto de dados tem avaliações completas de usuários de carros e hotéis. Eu concatenei especificamente todas as avaliações de hotéis em um arquivo grande que é de cerca de 97MB comprimido e 229MB não compactado. Vamos usar o arquivo compactado. Cada linha neste arquivo representa uma revisão sobre o serviço do hotel. Você pode fazer o download do conjunto de dados do Word2Vec do OpinRank aqui.\n",
    "\n",
    "Agora, vamos dar uma olhada mais de perto nesses dados, imprimindo a primeira linha. Você pode ver que esta é uma revisão bastante robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file = \"../data/reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open ('../data/reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler os arquivos dentro de listas\n",
    "Agora que tivemos uma ideia do nosso conjunto de dados, podemos lê-lo em uma lista para que possamos passar isso para o modelo Word2Vec. Observe no código abaixo, que estou lendo diretamente o arquivo compactado. Também estamos fazendo um pré-processamento moderado das revisões usando `gensim.utils.simple_preprocess (line)`. Isso faz um pré-processamento básico, como tokenização, letras minúsculas, etc, e retorna uma lista de tokens (palavras). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 17:53:46,373 : INFO : lendo arquivo ../data/reviews_data.txt.gz...esse processo pode demorar\n",
      "2019-09-12 17:53:46,375 : INFO : lido 0 revisoes\n",
      "2019-09-12 17:53:48,150 : INFO : lido 10000 revisoes\n",
      "2019-09-12 17:53:49,607 : INFO : lido 20000 revisoes\n",
      "2019-09-12 17:53:51,244 : INFO : lido 30000 revisoes\n",
      "2019-09-12 17:53:53,055 : INFO : lido 40000 revisoes\n",
      "2019-09-12 17:53:54,738 : INFO : lido 50000 revisoes\n",
      "2019-09-12 17:53:56,368 : INFO : lido 60000 revisoes\n",
      "2019-09-12 17:53:58,196 : INFO : lido 70000 revisoes\n",
      "2019-09-12 17:53:59,711 : INFO : lido 80000 revisoes\n",
      "2019-09-12 17:54:01,039 : INFO : lido 90000 revisoes\n",
      "2019-09-12 17:54:02,328 : INFO : lido 100000 revisoes\n",
      "2019-09-12 17:54:03,610 : INFO : lido 110000 revisoes\n",
      "2019-09-12 17:54:04,922 : INFO : lido 120000 revisoes\n",
      "2019-09-12 17:54:06,265 : INFO : lido 130000 revisoes\n",
      "2019-09-12 17:54:07,699 : INFO : lido 140000 revisoes\n",
      "2019-09-12 17:54:09,041 : INFO : lido 150000 revisoes\n",
      "2019-09-12 17:54:10,872 : INFO : lido 160000 revisoes\n",
      "2019-09-12 17:54:12,201 : INFO : lido 170000 revisoes\n",
      "2019-09-12 17:54:13,629 : INFO : lido 180000 revisoes\n",
      "2019-09-12 17:54:14,958 : INFO : lido 190000 revisoes\n",
      "2019-09-12 17:54:16,414 : INFO : lido 200000 revisoes\n",
      "2019-09-12 17:54:17,787 : INFO : lido 210000 revisoes\n",
      "2019-09-12 17:54:19,175 : INFO : lido 220000 revisoes\n",
      "2019-09-12 17:54:20,525 : INFO : lido 230000 revisoes\n",
      "2019-09-12 17:54:21,858 : INFO : lido 240000 revisoes\n",
      "2019-09-12 17:54:23,846 : INFO : lido 250000 revisoes\n",
      "2019-09-12 17:54:24,987 : INFO : Terminado de ler os arquivos\n"
     ]
    }
   ],
   "source": [
    "def read_input(input_file):\n",
    "    \"\"\"Esse método lê o arquivo de entrada no formato gzip\"\"\"\n",
    "    \n",
    "    logging.info(\"lendo arquivo {0}...esse processo pode demorar\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"lido {0} revisoes\".format (i))\n",
    "            # feito alguns pre-processamentos e retorna uma lista de palavras\n",
    "            # para cada revisão no formato texto\n",
    "            yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "# ler uma revisão tokenizada em uma lista\n",
    "# cada revisão se torna um série de palavras \n",
    "# então isso se torna uma lista de listas\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Terminado de ler os arquivos\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do modelo Word2Vec\n",
    "\n",
    "Treinar o modelo é bastante simples. Você apenas instancia o Word2Vec e passa os comentários que lemos na etapa anterior (os `documentos`). Então, estamos essencialmente passando uma lista de listas. Onde cada lista na lista principal contém um conjunto de tokens de uma revisão do usuário. O Word2Vec usa todos esses tokens para criar internamente um vocabulário. E por vocabulário, quero dizer um conjunto de palavras únicas.\n",
    "\n",
    "Depois de construir o vocabulário, só precisamos chamar `train(...)` para começar a treinar o modelo Word2Vec. O treinamento no conjunto de dados [OpinRank] (http://kavita-ganesan.com/entity-ranking-data/) leva cerca de 10 minutos, portanto, seja paciente ao executar seu código neste conjunto de dados.\n",
    "\n",
    "Nos bastidores, na verdade, estamos treinando uma rede neural simples com uma única camada oculta. Mas, na verdade, não vamos usar a rede neural após o treinamento. Em vez disso, o objetivo é aprender os pesos da camada oculta. Esses pesos são essencialmente os vetores de palavras que estamos tentando aprender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 17:54:35,642 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-09-12 17:54:35,643 : INFO : collecting all words and their counts\n",
      "2019-09-12 17:54:35,644 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-12 17:54:35,838 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2019-09-12 17:54:36,015 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2019-09-12 17:54:36,225 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2019-09-12 17:54:36,436 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2019-09-12 17:54:36,775 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2019-09-12 17:54:37,112 : INFO : PROGRESS: at sentence #60000, processed 11013726 words, keeping 76786 word types\n",
      "2019-09-12 17:54:37,361 : INFO : PROGRESS: at sentence #70000, processed 12637528 words, keeping 83199 word types\n",
      "2019-09-12 17:54:37,583 : INFO : PROGRESS: at sentence #80000, processed 14099754 words, keeping 88459 word types\n",
      "2019-09-12 17:54:37,759 : INFO : PROGRESS: at sentence #90000, processed 15662152 words, keeping 93357 word types\n",
      "2019-09-12 17:54:37,937 : INFO : PROGRESS: at sentence #100000, processed 17164490 words, keeping 97886 word types\n",
      "2019-09-12 17:54:38,111 : INFO : PROGRESS: at sentence #110000, processed 18652295 words, keeping 102132 word types\n",
      "2019-09-12 17:54:38,403 : INFO : PROGRESS: at sentence #120000, processed 20152532 words, keeping 105923 word types\n",
      "2019-09-12 17:54:38,603 : INFO : PROGRESS: at sentence #130000, processed 21684333 words, keeping 110104 word types\n",
      "2019-09-12 17:54:38,789 : INFO : PROGRESS: at sentence #140000, processed 23330209 words, keeping 114108 word types\n",
      "2019-09-12 17:54:38,970 : INFO : PROGRESS: at sentence #150000, processed 24838757 words, keeping 118174 word types\n",
      "2019-09-12 17:54:39,154 : INFO : PROGRESS: at sentence #160000, processed 26390913 words, keeping 118670 word types\n",
      "2019-09-12 17:54:39,446 : INFO : PROGRESS: at sentence #170000, processed 27913919 words, keeping 123356 word types\n",
      "2019-09-12 17:54:39,641 : INFO : PROGRESS: at sentence #180000, processed 29535615 words, keeping 126748 word types\n",
      "2019-09-12 17:54:39,827 : INFO : PROGRESS: at sentence #190000, processed 31096462 words, keeping 129847 word types\n",
      "2019-09-12 17:54:40,030 : INFO : PROGRESS: at sentence #200000, processed 32805274 words, keeping 133255 word types\n",
      "2019-09-12 17:54:40,221 : INFO : PROGRESS: at sentence #210000, processed 34434201 words, keeping 136364 word types\n",
      "2019-09-12 17:54:40,421 : INFO : PROGRESS: at sentence #220000, processed 36083485 words, keeping 139418 word types\n",
      "2019-09-12 17:54:40,725 : INFO : PROGRESS: at sentence #230000, processed 37571765 words, keeping 142399 word types\n",
      "2019-09-12 17:54:41,004 : INFO : PROGRESS: at sentence #240000, processed 39138193 words, keeping 145232 word types\n",
      "2019-09-12 17:54:41,297 : INFO : PROGRESS: at sentence #250000, processed 40695052 words, keeping 147966 word types\n",
      "2019-09-12 17:54:41,402 : INFO : collected 150059 word types from a corpus of 41519358 raw words and 255404 sentences\n",
      "2019-09-12 17:54:41,402 : INFO : Loading a fresh vocabulary\n",
      "2019-09-12 17:54:41,522 : INFO : effective_min_count=2 retains 70537 unique words (47% of original 150059, drops 79522)\n",
      "2019-09-12 17:54:41,522 : INFO : effective_min_count=2 leaves 41439836 word corpus (99% of original 41519358, drops 79522)\n",
      "2019-09-12 17:54:41,711 : INFO : deleting the raw counts dictionary of 150059 items\n",
      "2019-09-12 17:54:41,718 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2019-09-12 17:54:41,719 : INFO : downsampling leaves estimated 30349251 word corpus (73.2% of prior 41439836)\n",
      "2019-09-12 17:54:42,049 : INFO : estimated required memory for 70537 words and 150 dimensions: 119912900 bytes\n",
      "2019-09-12 17:54:42,050 : INFO : resetting layer weights\n",
      "2019-09-12 17:54:42,660 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-09-12 17:54:43,668 : INFO : EPOCH 1 - PROGRESS: at 4.30% examples, 1314509 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:54:44,677 : INFO : EPOCH 1 - PROGRESS: at 9.73% examples, 1520685 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:54:45,686 : INFO : EPOCH 1 - PROGRESS: at 14.38% examples, 1574762 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:54:46,701 : INFO : EPOCH 1 - PROGRESS: at 17.69% examples, 1471899 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:54:47,720 : INFO : EPOCH 1 - PROGRESS: at 19.98% examples, 1345326 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:54:48,740 : INFO : EPOCH 1 - PROGRESS: at 22.61% examples, 1268124 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:54:49,741 : INFO : EPOCH 1 - PROGRESS: at 25.33% examples, 1225969 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:54:50,754 : INFO : EPOCH 1 - PROGRESS: at 29.05% examples, 1196592 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:54:51,765 : INFO : EPOCH 1 - PROGRESS: at 32.52% examples, 1169777 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:54:52,767 : INFO : EPOCH 1 - PROGRESS: at 35.82% examples, 1150356 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:54:53,775 : INFO : EPOCH 1 - PROGRESS: at 38.48% examples, 1112681 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:54:54,778 : INFO : EPOCH 1 - PROGRESS: at 41.88% examples, 1096741 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:54:55,779 : INFO : EPOCH 1 - PROGRESS: at 45.58% examples, 1091039 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:54:56,799 : INFO : EPOCH 1 - PROGRESS: at 49.27% examples, 1087737 words/s, in_qsize 19, out_qsize 2\n",
      "2019-09-12 17:54:57,800 : INFO : EPOCH 1 - PROGRESS: at 52.60% examples, 1081338 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:54:58,808 : INFO : EPOCH 1 - PROGRESS: at 56.25% examples, 1080078 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:54:59,816 : INFO : EPOCH 1 - PROGRESS: at 59.82% examples, 1076843 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:00,818 : INFO : EPOCH 1 - PROGRESS: at 63.73% examples, 1078349 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:01,823 : INFO : EPOCH 1 - PROGRESS: at 67.43% examples, 1078337 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-12 17:55:02,829 : INFO : EPOCH 1 - PROGRESS: at 71.00% examples, 1079571 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:03,830 : INFO : EPOCH 1 - PROGRESS: at 74.77% examples, 1079583 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:04,840 : INFO : EPOCH 1 - PROGRESS: at 78.16% examples, 1079416 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:05,859 : INFO : EPOCH 1 - PROGRESS: at 81.52% examples, 1076391 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:55:06,867 : INFO : EPOCH 1 - PROGRESS: at 85.22% examples, 1078502 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:55:07,877 : INFO : EPOCH 1 - PROGRESS: at 89.33% examples, 1081117 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:08,883 : INFO : EPOCH 1 - PROGRESS: at 93.31% examples, 1083896 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:55:09,889 : INFO : EPOCH 1 - PROGRESS: at 97.24% examples, 1085485 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:10,516 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:55:10,524 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:55:10,530 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:55:10,534 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:55:10,546 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:55:10,547 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 17:55:10,548 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:55:10,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 17:55:10,559 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:55:10,564 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:55:10,565 : INFO : EPOCH - 1 : training on 41519358 raw words (30349177 effective words) took 27.9s, 1087747 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 17:55:11,581 : INFO : EPOCH 2 - PROGRESS: at 3.60% examples, 1113227 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:12,586 : INFO : EPOCH 2 - PROGRESS: at 7.43% examples, 1140714 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:13,590 : INFO : EPOCH 2 - PROGRESS: at 10.52% examples, 1116188 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:14,592 : INFO : EPOCH 2 - PROGRESS: at 13.78% examples, 1132823 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:15,594 : INFO : EPOCH 2 - PROGRESS: at 17.23% examples, 1148219 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:16,594 : INFO : EPOCH 2 - PROGRESS: at 20.32% examples, 1152636 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:17,598 : INFO : EPOCH 2 - PROGRESS: at 23.35% examples, 1138338 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:18,602 : INFO : EPOCH 2 - PROGRESS: at 27.19% examples, 1143080 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:19,608 : INFO : EPOCH 2 - PROGRESS: at 31.53% examples, 1147558 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:20,618 : INFO : EPOCH 2 - PROGRESS: at 35.70% examples, 1153042 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:21,619 : INFO : EPOCH 2 - PROGRESS: at 40.16% examples, 1161925 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:22,620 : INFO : EPOCH 2 - PROGRESS: at 44.70% examples, 1168464 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:23,628 : INFO : EPOCH 2 - PROGRESS: at 49.08% examples, 1173656 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:55:24,632 : INFO : EPOCH 2 - PROGRESS: at 53.05% examples, 1175736 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:55:25,644 : INFO : EPOCH 2 - PROGRESS: at 56.35% examples, 1159087 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:26,673 : INFO : EPOCH 2 - PROGRESS: at 59.25% examples, 1137467 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-12 17:55:27,676 : INFO : EPOCH 2 - PROGRESS: at 62.80% examples, 1130905 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:28,688 : INFO : EPOCH 2 - PROGRESS: at 67.10% examples, 1135515 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:55:29,693 : INFO : EPOCH 2 - PROGRESS: at 71.09% examples, 1139851 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:55:30,700 : INFO : EPOCH 2 - PROGRESS: at 75.46% examples, 1146259 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:31,702 : INFO : EPOCH 2 - PROGRESS: at 79.47% examples, 1151834 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:32,703 : INFO : EPOCH 2 - PROGRESS: at 83.71% examples, 1157973 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:33,704 : INFO : EPOCH 2 - PROGRESS: at 88.11% examples, 1163838 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:34,704 : INFO : EPOCH 2 - PROGRESS: at 92.62% examples, 1168883 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-12 17:55:35,721 : INFO : EPOCH 2 - PROGRESS: at 96.49% examples, 1166680 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:55:36,535 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:55:36,540 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:55:36,544 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:55:36,548 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:55:36,552 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:55:36,560 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 17:55:36,565 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:55:36,571 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 17:55:36,573 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:55:36,576 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:55:36,577 : INFO : EPOCH - 2 : training on 41519358 raw words (30347863 effective words) took 26.0s, 1167182 effective words/s\n",
      "2019-09-12 17:55:37,584 : INFO : EPOCH 3 - PROGRESS: at 3.63% examples, 1125487 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:38,585 : INFO : EPOCH 3 - PROGRESS: at 7.24% examples, 1117274 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:39,597 : INFO : EPOCH 3 - PROGRESS: at 10.59% examples, 1123678 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:40,598 : INFO : EPOCH 3 - PROGRESS: at 13.72% examples, 1126657 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:41,604 : INFO : EPOCH 3 - PROGRESS: at 16.94% examples, 1124875 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:42,621 : INFO : EPOCH 3 - PROGRESS: at 19.98% examples, 1126704 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:43,633 : INFO : EPOCH 3 - PROGRESS: at 23.25% examples, 1128926 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:44,645 : INFO : EPOCH 3 - PROGRESS: at 26.96% examples, 1131139 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:45,653 : INFO : EPOCH 3 - PROGRESS: at 30.80% examples, 1122399 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:46,655 : INFO : EPOCH 3 - PROGRESS: at 34.50% examples, 1115221 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:47,660 : INFO : EPOCH 3 - PROGRESS: at 38.52% examples, 1117504 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:48,675 : INFO : EPOCH 3 - PROGRESS: at 42.66% examples, 1119059 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:49,685 : INFO : EPOCH 3 - PROGRESS: at 46.99% examples, 1124704 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:50,693 : INFO : EPOCH 3 - PROGRESS: at 51.00% examples, 1125567 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:55:51,694 : INFO : EPOCH 3 - PROGRESS: at 54.86% examples, 1129184 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:55:52,697 : INFO : EPOCH 3 - PROGRESS: at 59.07% examples, 1132845 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:55:53,703 : INFO : EPOCH 3 - PROGRESS: at 62.52% examples, 1125051 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-12 17:55:54,704 : INFO : EPOCH 3 - PROGRESS: at 66.61% examples, 1127232 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:55:55,720 : INFO : EPOCH 3 - PROGRESS: at 70.46% examples, 1128246 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:56,720 : INFO : EPOCH 3 - PROGRESS: at 74.42% examples, 1129511 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-12 17:55:57,721 : INFO : EPOCH 3 - PROGRESS: at 78.03% examples, 1130810 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:58,726 : INFO : EPOCH 3 - PROGRESS: at 81.51% examples, 1127661 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:55:59,732 : INFO : EPOCH 3 - PROGRESS: at 83.87% examples, 1109145 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:56:00,753 : INFO : EPOCH 3 - PROGRESS: at 86.76% examples, 1098242 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:56:01,765 : INFO : EPOCH 3 - PROGRESS: at 89.86% examples, 1088507 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:02,768 : INFO : EPOCH 3 - PROGRESS: at 93.62% examples, 1088733 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:03,785 : INFO : EPOCH 3 - PROGRESS: at 97.69% examples, 1091743 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:04,275 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:56:04,283 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:56:04,292 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:56:04,293 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:56:04,294 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:56:04,296 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 17:56:04,311 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:56:04,315 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 17:56:04,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:56:04,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:56:04,324 : INFO : EPOCH - 3 : training on 41519358 raw words (30351339 effective words) took 27.7s, 1094120 effective words/s\n",
      "2019-09-12 17:56:05,336 : INFO : EPOCH 4 - PROGRESS: at 3.75% examples, 1155985 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:06,343 : INFO : EPOCH 4 - PROGRESS: at 7.66% examples, 1178425 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 17:56:07,347 : INFO : EPOCH 4 - PROGRESS: at 11.05% examples, 1181694 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:08,351 : INFO : EPOCH 4 - PROGRESS: at 14.36% examples, 1182051 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:09,364 : INFO : EPOCH 4 - PROGRESS: at 17.69% examples, 1180811 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:10,366 : INFO : EPOCH 4 - PROGRESS: at 20.66% examples, 1173576 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:56:11,368 : INFO : EPOCH 4 - PROGRESS: at 24.07% examples, 1176866 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:56:12,386 : INFO : EPOCH 4 - PROGRESS: at 28.36% examples, 1178604 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:56:13,392 : INFO : EPOCH 4 - PROGRESS: at 32.66% examples, 1179825 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:14,408 : INFO : EPOCH 4 - PROGRESS: at 36.61% examples, 1174112 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:56:15,413 : INFO : EPOCH 4 - PROGRESS: at 40.83% examples, 1176312 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:16,424 : INFO : EPOCH 4 - PROGRESS: at 45.29% examples, 1177428 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:17,425 : INFO : EPOCH 4 - PROGRESS: at 49.44% examples, 1178234 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:18,427 : INFO : EPOCH 4 - PROGRESS: at 53.31% examples, 1178116 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:19,436 : INFO : EPOCH 4 - PROGRESS: at 57.49% examples, 1178005 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:20,451 : INFO : EPOCH 4 - PROGRESS: at 61.59% examples, 1178337 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:56:21,461 : INFO : EPOCH 4 - PROGRESS: at 65.77% examples, 1177892 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:56:22,466 : INFO : EPOCH 4 - PROGRESS: at 69.73% examples, 1177910 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:23,476 : INFO : EPOCH 4 - PROGRESS: at 73.72% examples, 1176774 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:24,488 : INFO : EPOCH 4 - PROGRESS: at 77.37% examples, 1175187 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:25,490 : INFO : EPOCH 4 - PROGRESS: at 81.13% examples, 1174669 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:56:26,500 : INFO : EPOCH 4 - PROGRESS: at 84.98% examples, 1174318 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:27,504 : INFO : EPOCH 4 - PROGRESS: at 89.23% examples, 1175138 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:28,520 : INFO : EPOCH 4 - PROGRESS: at 93.30% examples, 1174958 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:29,527 : INFO : EPOCH 4 - PROGRESS: at 97.43% examples, 1175246 words/s, in_qsize 17, out_qsize 3\n",
      "2019-09-12 17:56:30,091 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:56:30,111 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:56:30,114 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:56:30,116 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:56:30,117 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:56:30,126 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 17:56:30,128 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:56:30,129 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 17:56:30,130 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:56:30,136 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:56:30,136 : INFO : EPOCH - 4 : training on 41519358 raw words (30350021 effective words) took 25.8s, 1176153 effective words/s\n",
      "2019-09-12 17:56:31,155 : INFO : EPOCH 5 - PROGRESS: at 3.80% examples, 1160910 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:32,166 : INFO : EPOCH 5 - PROGRESS: at 7.70% examples, 1178403 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:33,167 : INFO : EPOCH 5 - PROGRESS: at 11.00% examples, 1173461 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:34,175 : INFO : EPOCH 5 - PROGRESS: at 14.14% examples, 1158428 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:35,177 : INFO : EPOCH 5 - PROGRESS: at 17.48% examples, 1162987 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:36,188 : INFO : EPOCH 5 - PROGRESS: at 20.52% examples, 1160504 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:37,193 : INFO : EPOCH 5 - PROGRESS: at 23.86% examples, 1162971 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:38,197 : INFO : EPOCH 5 - PROGRESS: at 27.89% examples, 1161313 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:39,217 : INFO : EPOCH 5 - PROGRESS: at 32.09% examples, 1159542 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:56:40,224 : INFO : EPOCH 5 - PROGRESS: at 35.74% examples, 1149759 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:56:41,226 : INFO : EPOCH 5 - PROGRESS: at 39.22% examples, 1133497 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:56:42,246 : INFO : EPOCH 5 - PROGRESS: at 42.76% examples, 1120041 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:43,253 : INFO : EPOCH 5 - PROGRESS: at 46.28% examples, 1106715 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:44,274 : INFO : EPOCH 5 - PROGRESS: at 49.81% examples, 1099646 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:45,278 : INFO : EPOCH 5 - PROGRESS: at 52.54% examples, 1079834 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:46,282 : INFO : EPOCH 5 - PROGRESS: at 54.99% examples, 1059199 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:56:47,284 : INFO : EPOCH 5 - PROGRESS: at 57.95% examples, 1046166 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:56:48,293 : INFO : EPOCH 5 - PROGRESS: at 61.02% examples, 1036773 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:49,305 : INFO : EPOCH 5 - PROGRESS: at 64.33% examples, 1029562 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:56:50,314 : INFO : EPOCH 5 - PROGRESS: at 67.49% examples, 1025299 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:51,319 : INFO : EPOCH 5 - PROGRESS: at 71.01% examples, 1028011 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:52,323 : INFO : EPOCH 5 - PROGRESS: at 75.18% examples, 1036038 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:53,326 : INFO : EPOCH 5 - PROGRESS: at 78.88% examples, 1042083 words/s, in_qsize 19, out_qsize 2\n",
      "2019-09-12 17:56:54,354 : INFO : EPOCH 5 - PROGRESS: at 82.44% examples, 1042440 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:55,360 : INFO : EPOCH 5 - PROGRESS: at 85.98% examples, 1043922 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:56:56,377 : INFO : EPOCH 5 - PROGRESS: at 89.55% examples, 1041438 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:57,383 : INFO : EPOCH 5 - PROGRESS: at 92.93% examples, 1039031 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:56:58,388 : INFO : EPOCH 5 - PROGRESS: at 96.46% examples, 1038354 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:56:59,392 : INFO : EPOCH 5 - PROGRESS: at 99.47% examples, 1032519 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:56:59,490 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:56:59,502 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:56:59,508 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:56:59,510 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:56:59,511 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:56:59,531 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 17:56:59,534 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:56:59,544 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 17:56:59,550 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:56:59,552 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:56:59,553 : INFO : EPOCH - 5 : training on 41519358 raw words (30348094 effective words) took 29.4s, 1031853 effective words/s\n",
      "2019-09-12 17:56:59,554 : INFO : training on a 207596790 raw words (151746494 effective words) took 136.9s, 1108497 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 17:56:59,556 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-09-12 17:56:59,557 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-09-12 17:57:00,566 : INFO : EPOCH 1 - PROGRESS: at 2.74% examples, 858026 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:01,580 : INFO : EPOCH 1 - PROGRESS: at 6.38% examples, 976608 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:02,584 : INFO : EPOCH 1 - PROGRESS: at 9.79% examples, 1025590 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:03,588 : INFO : EPOCH 1 - PROGRESS: at 12.75% examples, 1046372 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:04,604 : INFO : EPOCH 1 - PROGRESS: at 16.29% examples, 1074137 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:57:05,610 : INFO : EPOCH 1 - PROGRESS: at 19.58% examples, 1098824 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:06,612 : INFO : EPOCH 1 - PROGRESS: at 23.02% examples, 1115586 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:07,619 : INFO : EPOCH 1 - PROGRESS: at 25.80% examples, 1093102 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:08,628 : INFO : EPOCH 1 - PROGRESS: at 29.08% examples, 1068683 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:09,634 : INFO : EPOCH 1 - PROGRESS: at 31.83% examples, 1036398 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:10,637 : INFO : EPOCH 1 - PROGRESS: at 34.46% examples, 1012968 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:11,643 : INFO : EPOCH 1 - PROGRESS: at 37.58% examples, 1003262 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:57:12,646 : INFO : EPOCH 1 - PROGRESS: at 41.19% examples, 1002445 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:13,655 : INFO : EPOCH 1 - PROGRESS: at 44.96% examples, 1003765 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:14,667 : INFO : EPOCH 1 - PROGRESS: at 47.79% examples, 990915 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:15,678 : INFO : EPOCH 1 - PROGRESS: at 51.86% examples, 1001472 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:16,680 : INFO : EPOCH 1 - PROGRESS: at 55.95% examples, 1013218 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:57:17,682 : INFO : EPOCH 1 - PROGRESS: at 59.73% examples, 1017850 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:18,683 : INFO : EPOCH 1 - PROGRESS: at 63.90% examples, 1026259 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:19,686 : INFO : EPOCH 1 - PROGRESS: at 67.93% examples, 1033985 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:57:20,691 : INFO : EPOCH 1 - PROGRESS: at 71.83% examples, 1042106 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:21,695 : INFO : EPOCH 1 - PROGRESS: at 75.91% examples, 1048900 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:22,696 : INFO : EPOCH 1 - PROGRESS: at 79.76% examples, 1055714 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:23,697 : INFO : EPOCH 1 - PROGRESS: at 83.80% examples, 1062913 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:57:24,709 : INFO : EPOCH 1 - PROGRESS: at 87.86% examples, 1067373 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:25,711 : INFO : EPOCH 1 - PROGRESS: at 92.13% examples, 1072882 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:26,726 : INFO : EPOCH 1 - PROGRESS: at 96.20% examples, 1077478 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:27,562 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:57:27,569 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:57:27,576 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:57:27,583 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:57:27,583 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:57:27,587 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 17:57:27,596 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:57:27,597 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 17:57:27,600 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:57:27,604 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:57:27,605 : INFO : EPOCH - 1 : training on 41519358 raw words (30349024 effective words) took 28.0s, 1082319 effective words/s\n",
      "2019-09-12 17:57:28,617 : INFO : EPOCH 2 - PROGRESS: at 3.82% examples, 1176324 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:57:29,621 : INFO : EPOCH 2 - PROGRESS: at 7.68% examples, 1183146 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:57:30,625 : INFO : EPOCH 2 - PROGRESS: at 11.11% examples, 1192133 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:31,636 : INFO : EPOCH 2 - PROGRESS: at 14.54% examples, 1194710 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-12 17:57:32,637 : INFO : EPOCH 2 - PROGRESS: at 18.00% examples, 1203737 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:33,643 : INFO : EPOCH 2 - PROGRESS: at 21.30% examples, 1203587 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:34,644 : INFO : EPOCH 2 - PROGRESS: at 24.50% examples, 1200942 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:35,654 : INFO : EPOCH 2 - PROGRESS: at 28.99% examples, 1201642 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:36,665 : INFO : EPOCH 2 - PROGRESS: at 33.38% examples, 1202704 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:57:37,666 : INFO : EPOCH 2 - PROGRESS: at 37.50% examples, 1202992 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:38,677 : INFO : EPOCH 2 - PROGRESS: at 41.93% examples, 1201851 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:39,690 : INFO : EPOCH 2 - PROGRESS: at 46.27% examples, 1201314 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:40,696 : INFO : EPOCH 2 - PROGRESS: at 50.46% examples, 1201874 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:41,697 : INFO : EPOCH 2 - PROGRESS: at 54.42% examples, 1201855 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:42,701 : INFO : EPOCH 2 - PROGRESS: at 58.71% examples, 1202779 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:43,702 : INFO : EPOCH 2 - PROGRESS: at 62.93% examples, 1203965 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:44,703 : INFO : EPOCH 2 - PROGRESS: at 67.21% examples, 1204908 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:45,703 : INFO : EPOCH 2 - PROGRESS: at 71.13% examples, 1205239 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:46,713 : INFO : EPOCH 2 - PROGRESS: at 75.36% examples, 1205670 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:47,714 : INFO : EPOCH 2 - PROGRESS: at 79.14% examples, 1205384 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:48,717 : INFO : EPOCH 2 - PROGRESS: at 83.17% examples, 1205797 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:49,728 : INFO : EPOCH 2 - PROGRESS: at 87.18% examples, 1205319 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:50,739 : INFO : EPOCH 2 - PROGRESS: at 91.45% examples, 1204743 words/s, in_qsize 16, out_qsize 3\n",
      "2019-09-12 17:57:51,741 : INFO : EPOCH 2 - PROGRESS: at 95.63% examples, 1205314 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:52,748 : INFO : EPOCH 2 - PROGRESS: at 99.79% examples, 1204842 words/s, in_qsize 9, out_qsize 1\n",
      "2019-09-12 17:57:52,753 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:57:52,756 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:57:52,758 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:57:52,761 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:57:52,767 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:57:52,769 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 17:57:52,771 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:57:52,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 17:57:52,781 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:57:52,785 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:57:52,785 : INFO : EPOCH - 2 : training on 41519358 raw words (30347412 effective words) took 25.2s, 1205483 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 17:57:53,799 : INFO : EPOCH 3 - PROGRESS: at 3.86% examples, 1187547 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:54,802 : INFO : EPOCH 3 - PROGRESS: at 7.58% examples, 1164307 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:57:55,812 : INFO : EPOCH 3 - PROGRESS: at 10.03% examples, 1058344 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:57:56,824 : INFO : EPOCH 3 - PROGRESS: at 11.69% examples, 948090 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:57:57,833 : INFO : EPOCH 3 - PROGRESS: at 14.03% examples, 919320 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:57:58,845 : INFO : EPOCH 3 - PROGRESS: at 16.36% examples, 897880 words/s, in_qsize 16, out_qsize 3\n",
      "2019-09-12 17:57:59,858 : INFO : EPOCH 3 - PROGRESS: at 18.81% examples, 896353 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:58:00,872 : INFO : EPOCH 3 - PROGRESS: at 20.72% examples, 878899 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:01,914 : INFO : EPOCH 3 - PROGRESS: at 23.40% examples, 878379 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:02,919 : INFO : EPOCH 3 - PROGRESS: at 26.53% examples, 887877 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:03,925 : INFO : EPOCH 3 - PROGRESS: at 30.14% examples, 898381 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:04,935 : INFO : EPOCH 3 - PROGRESS: at 33.42% examples, 897903 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:05,936 : INFO : EPOCH 3 - PROGRESS: at 36.86% examples, 905943 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:58:06,945 : INFO : EPOCH 3 - PROGRESS: at 40.71% examples, 918155 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:07,950 : INFO : EPOCH 3 - PROGRESS: at 44.84% examples, 930533 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:58:08,960 : INFO : EPOCH 3 - PROGRESS: at 48.78% examples, 942806 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:09,963 : INFO : EPOCH 3 - PROGRESS: at 52.59% examples, 953075 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:10,976 : INFO : EPOCH 3 - PROGRESS: at 56.46% examples, 962254 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:11,981 : INFO : EPOCH 3 - PROGRESS: at 60.30% examples, 969991 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-12 17:58:12,989 : INFO : EPOCH 3 - PROGRESS: at 64.53% examples, 979178 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:13,994 : INFO : EPOCH 3 - PROGRESS: at 68.17% examples, 984519 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:14,998 : INFO : EPOCH 3 - PROGRESS: at 71.63% examples, 988022 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:58:16,010 : INFO : EPOCH 3 - PROGRESS: at 75.48% examples, 993667 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:17,011 : INFO : EPOCH 3 - PROGRESS: at 78.88% examples, 997385 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:18,019 : INFO : EPOCH 3 - PROGRESS: at 82.63% examples, 1002412 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:19,038 : INFO : EPOCH 3 - PROGRESS: at 86.26% examples, 1005898 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:20,052 : INFO : EPOCH 3 - PROGRESS: at 90.31% examples, 1010130 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:21,055 : INFO : EPOCH 3 - PROGRESS: at 94.19% examples, 1014134 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:22,058 : INFO : EPOCH 3 - PROGRESS: at 97.93% examples, 1016801 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:58:22,531 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:58:22,539 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:58:22,542 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:58:22,544 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:58:22,551 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:58:22,554 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 17:58:22,555 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:58:22,557 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 17:58:22,573 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:58:22,574 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:58:22,575 : INFO : EPOCH - 3 : training on 41519358 raw words (30347287 effective words) took 29.8s, 1018890 effective words/s\n",
      "2019-09-12 17:58:23,595 : INFO : EPOCH 4 - PROGRESS: at 3.51% examples, 1075039 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:24,606 : INFO : EPOCH 4 - PROGRESS: at 7.16% examples, 1089333 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:58:25,613 : INFO : EPOCH 4 - PROGRESS: at 10.28% examples, 1085283 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:26,626 : INFO : EPOCH 4 - PROGRESS: at 13.40% examples, 1089209 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:27,635 : INFO : EPOCH 4 - PROGRESS: at 16.56% examples, 1091397 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:28,640 : INFO : EPOCH 4 - PROGRESS: at 19.48% examples, 1091783 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:58:29,643 : INFO : EPOCH 4 - PROGRESS: at 22.65% examples, 1092911 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:30,648 : INFO : EPOCH 4 - PROGRESS: at 25.85% examples, 1093293 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:31,650 : INFO : EPOCH 4 - PROGRESS: at 29.89% examples, 1094086 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:32,652 : INFO : EPOCH 4 - PROGRESS: at 33.75% examples, 1094192 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:33,676 : INFO : EPOCH 4 - PROGRESS: at 37.59% examples, 1092747 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:34,682 : INFO : EPOCH 4 - PROGRESS: at 41.68% examples, 1093679 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:58:35,685 : INFO : EPOCH 4 - PROGRESS: at 45.52% examples, 1090790 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:36,690 : INFO : EPOCH 4 - PROGRESS: at 49.39% examples, 1092202 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:58:37,715 : INFO : EPOCH 4 - PROGRESS: at 53.07% examples, 1092345 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:58:38,720 : INFO : EPOCH 4 - PROGRESS: at 56.79% examples, 1090143 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:58:39,730 : INFO : EPOCH 4 - PROGRESS: at 60.64% examples, 1090965 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:40,742 : INFO : EPOCH 4 - PROGRESS: at 64.71% examples, 1091812 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:41,752 : INFO : EPOCH 4 - PROGRESS: at 68.42% examples, 1093050 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:42,761 : INFO : EPOCH 4 - PROGRESS: at 72.01% examples, 1093374 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:43,764 : INFO : EPOCH 4 - PROGRESS: at 75.79% examples, 1094004 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:44,778 : INFO : EPOCH 4 - PROGRESS: at 79.36% examples, 1094568 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:45,784 : INFO : EPOCH 4 - PROGRESS: at 83.04% examples, 1095191 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:58:46,797 : INFO : EPOCH 4 - PROGRESS: at 86.78% examples, 1096279 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:47,803 : INFO : EPOCH 4 - PROGRESS: at 90.78% examples, 1096992 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:58:48,808 : INFO : EPOCH 4 - PROGRESS: at 94.60% examples, 1097621 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:49,810 : INFO : EPOCH 4 - PROGRESS: at 98.49% examples, 1098757 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:50,165 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:58:50,177 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:58:50,181 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:58:50,186 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:58:50,188 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:58:50,191 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 17:58:50,193 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:58:50,194 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 17:58:50,201 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:58:50,204 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:58:50,205 : INFO : EPOCH - 4 : training on 41519358 raw words (30347792 effective words) took 27.6s, 1098609 effective words/s\n",
      "2019-09-12 17:58:51,216 : INFO : EPOCH 5 - PROGRESS: at 3.49% examples, 1077700 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:52,222 : INFO : EPOCH 5 - PROGRESS: at 7.11% examples, 1090464 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:58:53,231 : INFO : EPOCH 5 - PROGRESS: at 10.25% examples, 1085188 words/s, in_qsize 20, out_qsize 3\n",
      "2019-09-12 17:58:54,232 : INFO : EPOCH 5 - PROGRESS: at 13.39% examples, 1095865 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:55,248 : INFO : EPOCH 5 - PROGRESS: at 16.57% examples, 1095247 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:56,253 : INFO : EPOCH 5 - PROGRESS: at 19.52% examples, 1097237 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:57,262 : INFO : EPOCH 5 - PROGRESS: at 22.78% examples, 1099871 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:58,279 : INFO : EPOCH 5 - PROGRESS: at 26.00% examples, 1098660 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:58:59,290 : INFO : EPOCH 5 - PROGRESS: at 30.01% examples, 1097910 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:00,294 : INFO : EPOCH 5 - PROGRESS: at 33.86% examples, 1096724 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:01,299 : INFO : EPOCH 5 - PROGRESS: at 37.70% examples, 1096212 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:02,313 : INFO : EPOCH 5 - PROGRESS: at 41.81% examples, 1096699 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:59:03,317 : INFO : EPOCH 5 - PROGRESS: at 45.77% examples, 1096154 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:59:04,336 : INFO : EPOCH 5 - PROGRESS: at 49.61% examples, 1096074 words/s, in_qsize 16, out_qsize 3\n",
      "2019-09-12 17:59:05,348 : INFO : EPOCH 5 - PROGRESS: at 53.33% examples, 1097402 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:06,350 : INFO : EPOCH 5 - PROGRESS: at 57.18% examples, 1096550 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:59:07,354 : INFO : EPOCH 5 - PROGRESS: at 61.02% examples, 1097764 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:59:08,355 : INFO : EPOCH 5 - PROGRESS: at 64.98% examples, 1097249 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:09,357 : INFO : EPOCH 5 - PROGRESS: at 68.64% examples, 1097944 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-12 17:59:10,359 : INFO : EPOCH 5 - PROGRESS: at 72.23% examples, 1098075 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:11,361 : INFO : EPOCH 5 - PROGRESS: at 75.97% examples, 1098488 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:12,363 : INFO : EPOCH 5 - PROGRESS: at 79.52% examples, 1099140 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:13,363 : INFO : EPOCH 5 - PROGRESS: at 83.17% examples, 1099224 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:14,368 : INFO : EPOCH 5 - PROGRESS: at 86.71% examples, 1098119 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:59:15,371 : INFO : EPOCH 5 - PROGRESS: at 90.70% examples, 1098876 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:16,377 : INFO : EPOCH 5 - PROGRESS: at 94.50% examples, 1099074 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:17,377 : INFO : EPOCH 5 - PROGRESS: at 98.22% examples, 1098660 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:59:17,772 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:59:17,782 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:59:17,786 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:59:17,791 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:59:17,794 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:59:17,799 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 17:59:17,803 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:59:17,811 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 17:59:17,811 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:59:17,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:59:17,817 : INFO : EPOCH - 5 : training on 41519358 raw words (30348115 effective words) took 27.6s, 1099356 effective words/s\n",
      "2019-09-12 17:59:18,828 : INFO : EPOCH 6 - PROGRESS: at 3.53% examples, 1090994 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:19,841 : INFO : EPOCH 6 - PROGRESS: at 7.26% examples, 1107215 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:20,843 : INFO : EPOCH 6 - PROGRESS: at 10.45% examples, 1106100 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:21,849 : INFO : EPOCH 6 - PROGRESS: at 13.54% examples, 1106806 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:22,853 : INFO : EPOCH 6 - PROGRESS: at 16.69% examples, 1105032 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:23,855 : INFO : EPOCH 6 - PROGRESS: at 19.61% examples, 1103469 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:24,872 : INFO : EPOCH 6 - PROGRESS: at 22.77% examples, 1099948 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:25,874 : INFO : EPOCH 6 - PROGRESS: at 25.98% examples, 1099786 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:26,877 : INFO : EPOCH 6 - PROGRESS: at 30.04% examples, 1101459 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:27,889 : INFO : EPOCH 6 - PROGRESS: at 34.00% examples, 1101846 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:28,895 : INFO : EPOCH 6 - PROGRESS: at 37.77% examples, 1098768 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:29,901 : INFO : EPOCH 6 - PROGRESS: at 41.91% examples, 1100406 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:30,910 : INFO : EPOCH 6 - PROGRESS: at 45.97% examples, 1102003 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:31,923 : INFO : EPOCH 6 - PROGRESS: at 49.85% examples, 1102982 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:32,925 : INFO : EPOCH 6 - PROGRESS: at 53.51% examples, 1103137 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:33,929 : INFO : EPOCH 6 - PROGRESS: at 57.32% examples, 1101269 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:34,931 : INFO : EPOCH 6 - PROGRESS: at 61.10% examples, 1101007 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 17:59:35,934 : INFO : EPOCH 6 - PROGRESS: at 65.11% examples, 1101452 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:36,939 : INFO : EPOCH 6 - PROGRESS: at 68.71% examples, 1100642 words/s, in_qsize 16, out_qsize 3\n",
      "2019-09-12 17:59:37,946 : INFO : EPOCH 6 - PROGRESS: at 72.35% examples, 1101135 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:38,948 : INFO : EPOCH 6 - PROGRESS: at 76.11% examples, 1102062 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 17:59:39,965 : INFO : EPOCH 6 - PROGRESS: at 79.08% examples, 1093658 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:40,969 : INFO : EPOCH 6 - PROGRESS: at 81.87% examples, 1082961 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:41,996 : INFO : EPOCH 6 - PROGRESS: at 84.79% examples, 1074125 words/s, in_qsize 16, out_qsize 3\n",
      "2019-09-12 17:59:42,997 : INFO : EPOCH 6 - PROGRESS: at 88.03% examples, 1068041 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:43,997 : INFO : EPOCH 6 - PROGRESS: at 91.30% examples, 1062812 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:45,003 : INFO : EPOCH 6 - PROGRESS: at 94.86% examples, 1062004 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:46,006 : INFO : EPOCH 6 - PROGRESS: at 97.75% examples, 1054056 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:46,582 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 17:59:46,592 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 17:59:46,595 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 17:59:46,600 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 17:59:46,613 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 17:59:46,617 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 17:59:46,619 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 17:59:46,620 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 17:59:46,623 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 17:59:46,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 17:59:46,628 : INFO : EPOCH - 6 : training on 41519358 raw words (30346052 effective words) took 28.8s, 1053523 effective words/s\n",
      "2019-09-12 17:59:47,641 : INFO : EPOCH 7 - PROGRESS: at 3.40% examples, 1052731 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:48,650 : INFO : EPOCH 7 - PROGRESS: at 7.08% examples, 1079876 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-12 17:59:49,656 : INFO : EPOCH 7 - PROGRESS: at 10.59% examples, 1120040 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:50,672 : INFO : EPOCH 7 - PROGRESS: at 13.31% examples, 1084047 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:51,675 : INFO : EPOCH 7 - PROGRESS: at 16.80% examples, 1111082 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:59:52,676 : INFO : EPOCH 7 - PROGRESS: at 19.91% examples, 1120993 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:53,678 : INFO : EPOCH 7 - PROGRESS: at 22.78% examples, 1101025 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 17:59:54,678 : INFO : EPOCH 7 - PROGRESS: at 25.72% examples, 1091951 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:55,684 : INFO : EPOCH 7 - PROGRESS: at 29.87% examples, 1095648 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 17:59:56,689 : INFO : EPOCH 7 - PROGRESS: at 33.58% examples, 1089455 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-12 17:59:57,698 : INFO : EPOCH 7 - PROGRESS: at 37.70% examples, 1098405 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:58,700 : INFO : EPOCH 7 - PROGRESS: at 42.14% examples, 1107467 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 17:59:59,708 : INFO : EPOCH 7 - PROGRESS: at 46.40% examples, 1113101 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:00,709 : INFO : EPOCH 7 - PROGRESS: at 49.71% examples, 1102019 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:01,710 : INFO : EPOCH 7 - PROGRESS: at 52.78% examples, 1089800 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:02,713 : INFO : EPOCH 7 - PROGRESS: at 55.72% examples, 1074811 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:03,724 : INFO : EPOCH 7 - PROGRESS: at 59.65% examples, 1077656 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:04,727 : INFO : EPOCH 7 - PROGRESS: at 63.53% examples, 1079165 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:05,729 : INFO : EPOCH 7 - PROGRESS: at 67.23% examples, 1078911 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:06,736 : INFO : EPOCH 7 - PROGRESS: at 71.03% examples, 1083323 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:07,756 : INFO : EPOCH 7 - PROGRESS: at 75.22% examples, 1088627 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:08,758 : INFO : EPOCH 7 - PROGRESS: at 78.99% examples, 1093610 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:09,773 : INFO : EPOCH 7 - PROGRESS: at 83.04% examples, 1098258 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:10,782 : INFO : EPOCH 7 - PROGRESS: at 86.53% examples, 1096445 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:11,803 : INFO : EPOCH 7 - PROGRESS: at 90.01% examples, 1090703 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:12,819 : INFO : EPOCH 7 - PROGRESS: at 93.06% examples, 1082541 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 18:00:13,853 : INFO : EPOCH 7 - PROGRESS: at 96.58% examples, 1079075 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:14,802 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 18:00:14,812 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 18:00:14,813 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 18:00:14,814 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 18:00:14,826 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 18:00:14,827 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 18:00:14,828 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 18:00:14,830 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 18:00:14,837 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 18:00:14,840 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 18:00:14,841 : INFO : EPOCH - 7 : training on 41519358 raw words (30348792 effective words) took 28.2s, 1075908 effective words/s\n",
      "2019-09-12 18:00:15,848 : INFO : EPOCH 8 - PROGRESS: at 3.63% examples, 1124460 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:16,852 : INFO : EPOCH 8 - PROGRESS: at 6.63% examples, 1021862 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:17,852 : INFO : EPOCH 8 - PROGRESS: at 8.93% examples, 925649 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:18,854 : INFO : EPOCH 8 - PROGRESS: at 10.82% examples, 868164 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:19,858 : INFO : EPOCH 8 - PROGRESS: at 13.52% examples, 886412 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 18:00:20,859 : INFO : EPOCH 8 - PROGRESS: at 15.87% examples, 875787 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:21,865 : INFO : EPOCH 8 - PROGRESS: at 18.32% examples, 878278 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:22,869 : INFO : EPOCH 8 - PROGRESS: at 20.47% examples, 871012 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:23,872 : INFO : EPOCH 8 - PROGRESS: at 22.83% examples, 861667 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 18:00:24,878 : INFO : EPOCH 8 - PROGRESS: at 25.22% examples, 861313 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:25,881 : INFO : EPOCH 8 - PROGRESS: at 29.10% examples, 878569 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:26,895 : INFO : EPOCH 8 - PROGRESS: at 32.91% examples, 891969 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:27,903 : INFO : EPOCH 8 - PROGRESS: at 36.20% examples, 897258 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:28,905 : INFO : EPOCH 8 - PROGRESS: at 39.75% examples, 905558 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:29,916 : INFO : EPOCH 8 - PROGRESS: at 43.65% examples, 915569 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:30,927 : INFO : EPOCH 8 - PROGRESS: at 47.42% examples, 924300 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:31,930 : INFO : EPOCH 8 - PROGRESS: at 51.04% examples, 930358 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:32,943 : INFO : EPOCH 8 - PROGRESS: at 54.57% examples, 937950 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:33,961 : INFO : EPOCH 8 - PROGRESS: at 58.27% examples, 942795 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:34,975 : INFO : EPOCH 8 - PROGRESS: at 61.86% examples, 947519 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 18:00:35,980 : INFO : EPOCH 8 - PROGRESS: at 65.66% examples, 952876 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:36,981 : INFO : EPOCH 8 - PROGRESS: at 69.10% examples, 955838 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:37,995 : INFO : EPOCH 8 - PROGRESS: at 72.22% examples, 955741 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:39,001 : INFO : EPOCH 8 - PROGRESS: at 75.77% examples, 959178 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:40,006 : INFO : EPOCH 8 - PROGRESS: at 79.10% examples, 962849 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-12 18:00:41,014 : INFO : EPOCH 8 - PROGRESS: at 82.66% examples, 966845 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:42,025 : INFO : EPOCH 8 - PROGRESS: at 86.13% examples, 970255 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:43,051 : INFO : EPOCH 8 - PROGRESS: at 89.96% examples, 972856 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:44,068 : INFO : EPOCH 8 - PROGRESS: at 93.57% examples, 975059 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:45,102 : INFO : EPOCH 8 - PROGRESS: at 97.32% examples, 977497 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:45,800 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 18:00:45,808 : INFO : worker thread finished; awaiting finish of 8 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 18:00:45,824 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 18:00:45,828 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 18:00:45,829 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 18:00:45,839 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 18:00:45,844 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 18:00:45,847 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 18:00:45,848 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 18:00:45,858 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 18:00:45,859 : INFO : EPOCH - 8 : training on 41519358 raw words (30350327 effective words) took 31.0s, 978652 effective words/s\n",
      "2019-09-12 18:00:46,875 : INFO : EPOCH 9 - PROGRESS: at 3.23% examples, 994075 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:47,893 : INFO : EPOCH 9 - PROGRESS: at 6.74% examples, 1024002 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:48,895 : INFO : EPOCH 9 - PROGRESS: at 9.86% examples, 1034087 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:49,899 : INFO : EPOCH 9 - PROGRESS: at 12.64% examples, 1034904 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:50,908 : INFO : EPOCH 9 - PROGRESS: at 15.58% examples, 1022307 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:51,926 : INFO : EPOCH 9 - PROGRESS: at 18.63% examples, 1034747 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:52,930 : INFO : EPOCH 9 - PROGRESS: at 21.65% examples, 1038428 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:53,939 : INFO : EPOCH 9 - PROGRESS: at 24.44% examples, 1042089 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:54,940 : INFO : EPOCH 9 - PROGRESS: at 28.34% examples, 1045053 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:55,952 : INFO : EPOCH 9 - PROGRESS: at 32.39% examples, 1051673 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:00:56,968 : INFO : EPOCH 9 - PROGRESS: at 36.18% examples, 1054384 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:00:57,971 : INFO : EPOCH 9 - PROGRESS: at 40.04% examples, 1057423 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:58,974 : INFO : EPOCH 9 - PROGRESS: at 44.11% examples, 1061761 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:00:59,974 : INFO : EPOCH 9 - PROGRESS: at 47.93% examples, 1063521 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:00,977 : INFO : EPOCH 9 - PROGRESS: at 51.66% examples, 1063886 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:01,982 : INFO : EPOCH 9 - PROGRESS: at 55.37% examples, 1066073 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:03,001 : INFO : EPOCH 9 - PROGRESS: at 58.96% examples, 1063406 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:04,022 : INFO : EPOCH 9 - PROGRESS: at 62.54% examples, 1061043 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 18:01:05,025 : INFO : EPOCH 9 - PROGRESS: at 66.13% examples, 1058549 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:06,027 : INFO : EPOCH 9 - PROGRESS: at 69.71% examples, 1059004 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 18:01:07,030 : INFO : EPOCH 9 - PROGRESS: at 73.27% examples, 1058885 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-12 18:01:08,052 : INFO : EPOCH 9 - PROGRESS: at 76.30% examples, 1052316 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-12 18:01:09,060 : INFO : EPOCH 9 - PROGRESS: at 79.61% examples, 1050954 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:10,062 : INFO : EPOCH 9 - PROGRESS: at 82.88% examples, 1048233 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:11,074 : INFO : EPOCH 9 - PROGRESS: at 84.83% examples, 1030953 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:12,075 : INFO : EPOCH 9 - PROGRESS: at 87.66% examples, 1022082 words/s, in_qsize 20, out_qsize 3\n",
      "2019-09-12 18:01:13,106 : INFO : EPOCH 9 - PROGRESS: at 90.32% examples, 1010958 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:14,121 : INFO : EPOCH 9 - PROGRESS: at 93.85% examples, 1011140 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:15,123 : INFO : EPOCH 9 - PROGRESS: at 97.53% examples, 1012973 words/s, in_qsize 16, out_qsize 3\n",
      "2019-09-12 18:01:15,702 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 18:01:15,714 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 18:01:15,717 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 18:01:15,718 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 18:01:15,734 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 18:01:15,744 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 18:01:15,749 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 18:01:15,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 18:01:15,755 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 18:01:15,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 18:01:15,758 : INFO : EPOCH - 9 : training on 41519358 raw words (30347650 effective words) took 29.9s, 1015238 effective words/s\n",
      "2019-09-12 18:01:16,765 : INFO : EPOCH 10 - PROGRESS: at 3.38% examples, 1052365 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:17,778 : INFO : EPOCH 10 - PROGRESS: at 6.86% examples, 1048728 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:18,787 : INFO : EPOCH 10 - PROGRESS: at 10.02% examples, 1055080 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:19,790 : INFO : EPOCH 10 - PROGRESS: at 12.50% examples, 1026098 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:20,791 : INFO : EPOCH 10 - PROGRESS: at 15.71% examples, 1032641 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:21,795 : INFO : EPOCH 10 - PROGRESS: at 18.67% examples, 1042228 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:22,822 : INFO : EPOCH 10 - PROGRESS: at 21.47% examples, 1030260 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:01:23,828 : INFO : EPOCH 10 - PROGRESS: at 24.27% examples, 1035572 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:01:24,829 : INFO : EPOCH 10 - PROGRESS: at 27.94% examples, 1033372 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-12 18:01:25,834 : INFO : EPOCH 10 - PROGRESS: at 31.59% examples, 1030669 words/s, in_qsize 18, out_qsize 2\n",
      "2019-09-12 18:01:26,835 : INFO : EPOCH 10 - PROGRESS: at 35.33% examples, 1037216 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:27,838 : INFO : EPOCH 10 - PROGRESS: at 39.13% examples, 1038768 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:28,838 : INFO : EPOCH 10 - PROGRESS: at 42.98% examples, 1041325 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:29,857 : INFO : EPOCH 10 - PROGRESS: at 46.91% examples, 1043773 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:30,865 : INFO : EPOCH 10 - PROGRESS: at 50.50% examples, 1041923 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 18:01:31,868 : INFO : EPOCH 10 - PROGRESS: at 53.21% examples, 1029255 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:32,874 : INFO : EPOCH 10 - PROGRESS: at 56.44% examples, 1022385 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:33,875 : INFO : EPOCH 10 - PROGRESS: at 59.75% examples, 1018568 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:34,893 : INFO : EPOCH 10 - PROGRESS: at 63.28% examples, 1017391 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-12 18:01:35,896 : INFO : EPOCH 10 - PROGRESS: at 67.08% examples, 1021262 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:36,912 : INFO : EPOCH 10 - PROGRESS: at 70.69% examples, 1024308 words/s, in_qsize 17, out_qsize 3\n",
      "2019-09-12 18:01:37,913 : INFO : EPOCH 10 - PROGRESS: at 73.93% examples, 1019676 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:38,914 : INFO : EPOCH 10 - PROGRESS: at 77.29% examples, 1021923 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-12 18:01:39,926 : INFO : EPOCH 10 - PROGRESS: at 80.53% examples, 1020872 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:40,926 : INFO : EPOCH 10 - PROGRESS: at 84.04% examples, 1022374 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-12 18:01:41,929 : INFO : EPOCH 10 - PROGRESS: at 87.06% examples, 1017532 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 18:01:42,931 : INFO : EPOCH 10 - PROGRESS: at 90.88% examples, 1019594 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:43,951 : INFO : EPOCH 10 - PROGRESS: at 94.26% examples, 1017789 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-12 18:01:44,951 : INFO : EPOCH 10 - PROGRESS: at 97.59% examples, 1016220 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-12 18:01:45,541 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-12 18:01:45,550 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-12 18:01:45,568 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-12 18:01:45,569 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-12 18:01:45,570 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-12 18:01:45,580 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-12 18:01:45,581 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-12 18:01:45,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-12 18:01:45,590 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-12 18:01:45,591 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-12 18:01:45,591 : INFO : EPOCH - 10 : training on 41519358 raw words (30350603 effective words) took 29.8s, 1017534 effective words/s\n",
      "2019-09-12 18:01:45,592 : INFO : training on a 415193580 raw words (303483054 effective words) took 286.0s, 1061003 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(303483054, 415193580)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checando o output \n",
    "Este primeiro exemplo mostra um caso simples de procurar palavras semelhantes à palavra `dirty`. Tudo o que precisamos fazer aqui é chamar a função `most_similar` e fornecer a palavra` dirty` como o exemplo positivo. Isso retorna o top 10 palavras semelhantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 18:01:45,609 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.8653523921966553),\n",
       " ('stained', 0.7742222547531128),\n",
       " ('unclean', 0.767873227596283),\n",
       " ('grubby', 0.7551994323730469),\n",
       " ('dusty', 0.7500635385513306),\n",
       " ('smelly', 0.738541841506958),\n",
       " ('dingy', 0.7374070286750793),\n",
       " ('soiled', 0.7308399677276611),\n",
       " ('gross', 0.7202204465866089),\n",
       " ('grimy', 0.7143548727035522)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"dirty\"\n",
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso parece muito bom, certo? Vamos dar uma olhada em mais alguns. Vamos ver a similaridade de `polite`,` france` e `shocked`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.9159219861030579),\n",
       " ('friendly', 0.8311355113983154),\n",
       " ('cordial', 0.8110564947128296),\n",
       " ('curteous', 0.7994455695152283),\n",
       " ('professional', 0.7916486263275146),\n",
       " ('attentive', 0.7834433317184448)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos ver as 6 palavras mais similares a 'polite'\n",
    "w1 = [\"polite\"]\n",
    "model.wv.most_similar (positive=w1, topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.6628038883209229),\n",
       " ('england', 0.6498188972473145),\n",
       " ('canada', 0.6462444067001343),\n",
       " ('mexico', 0.6328214406967163),\n",
       " ('gaulle', 0.627234935760498),\n",
       " ('spain', 0.6269464492797852)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos ver as 6 palavras mais similares a 'france'\n",
    "w1 = [\"france\"]\n",
    "model.wv.most_similar(positive=w1, topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrified', 0.8032431602478027),\n",
       " ('amazed', 0.7932386994361877),\n",
       " ('astonished', 0.7562350630760193),\n",
       " ('stunned', 0.7545634508132935),\n",
       " ('appalled', 0.751807689666748),\n",
       " ('dismayed', 0.7456820607185364)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos ver as 6 palavras mais similares a 'shocked'\n",
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso é bom. Você pode até especificar vários exemplos positivos para obter coisas que estão relacionadas no contexto fornecido e usar exemplos negativos para dizer o que não deve ser considerado como relacionado. No exemplo abaixo, estamos pedindo todos os itens que se referem a *cama* (*bed* em inglês):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duvet', 0.70943284034729),\n",
       " ('blanket', 0.6876029968261719),\n",
       " ('mattress', 0.6864297389984131),\n",
       " ('matress', 0.6831876039505005),\n",
       " ('quilt', 0.676246702671051),\n",
       " ('pillowcase', 0.6585795879364014),\n",
       " ('sheets', 0.636309027671814),\n",
       " ('pillows', 0.6242099404335022),\n",
       " ('foam', 0.6231487989425659),\n",
       " ('pillowcases', 0.6110523343086243)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# palavras relacionadas com cama\n",
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade entre duas palavras no vocabulário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode até usar o modelo Word2Vec para retornar a semelhança entre duas palavras que estão presentes no vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7385417"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similaridade de duas palavras diferentes\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similaridades de duas palavras idênticas\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26686907"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similaridade de duas palavras opostas\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debaixo dos panos, os três trechos acima calculam a semelhança de cosseno entre as duas palavras especificadas usando vetores de palavras de cada um. A partir das pontuações, faz sentido que `dirty` seja altamente similar a` smelly`, mas `dirty` é diferente de` clean`. Se você fizer uma semelhança entre duas palavras idênticas, a pontuação será 1.0, já que o intervalo da pontuação de semelhança do cosseno será sempre entre [0.0-1.0]. Você pode ler mais sobre a pontuação de semelhança de cosseno [aqui] (https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontre o estranho\n",
    "Você pode até usar o Word2Vec para encontrar itens estranhos com uma lista de itens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geanderson/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:876: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual dos items abaixo é o estranho da lista?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual dos items abaixo é o estranho da lista?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"car\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo os parâmetros que podem ser utilizados\n",
    "Para treinar o modelo anteriormente, tivemos que definir alguns parâmetros. Agora, vamos tentar entender o que alguns deles significam. Para referência, este é o comando que usamos para treinar o modelo.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec(documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `size`\n",
    "O tamanho do vetor denso para representar cada token ou palavra. Se você tiver dados muito limitados, o tamanho deverá ser um valor muito menor. Se você tiver muitos dados, é bom experimentar vários tamanhos. Um valor de 100-150 funcionou bem para o dataset treinado.\n",
    "\n",
    "### `window`\n",
    "A distância máxima entre a palavra alvo e a palavra vizinha. Se a posição do seu vizinho for maior que a largura máxima da janela à esquerda e à direita, alguns vizinhos não serão considerados como relacionados à palavra de destino. Em teoria, uma janela menor deve fornecer termos mais relacionados. Se você tiver muitos dados, o tamanho da janela não deve importar muito, desde que seja uma janela de tamanho decente. \n",
    "\n",
    "### `min_count`\n",
    "Contagem de frequência mínima de palavras. O modelo ignoraria as palavras que não statisfy o `min_count`. Palavras extremamente raras geralmente não são importantes, então é melhor livrar-se delas. A menos que seu conjunto de dados seja realmente pequeno, isso não afeta realmente o modelo.\n",
    "\n",
    "### `workers`\n",
    "Quantas threads deveríamos usar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quando usar Word2Vec?\n",
    "\n",
    "Existem muitos cenários de aplicações para o Word2Vec. Imagine se você precisa construir um analisador léxico. Treinar um modelo Word2Vec em grandes quantidades de comentários de usuários ajuda você a conseguir isso. Você tem um léxico não apenas para o sentimento, mas para a maioria das palavras no vocabulário.\n",
    "\n",
    "Além dos dados de texto bruto não estruturados, você também pode usar o Word2Vec para obter dados mais estruturados. Por exemplo, se você tivesse tags para um milhão de perguntas e respostas do stackoverflow, poderia encontrar tags relacionadas a uma determinada tag e recomendar as relacionadas para exploração. Você pode fazer isso tratando cada conjunto de tags de coexistência como uma \"frase\" e treinar um modelo Word2Vec nesses dados. Concedido, você ainda precisa de um grande número de exemplos para fazê-lo funcionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
