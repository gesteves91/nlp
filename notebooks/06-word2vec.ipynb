{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciando com Word2Vec com Gensim!\n",
    "  \n",
    "A ideia por trás do Word2Vec é bem simples. Estamos supondo que você pode inferir o significado de uma palavra pela composição que ela mantém. Isso é análogo ao ditado popular \"mostre-me seus amigos e eu direi quem você é\". Então, se você tem duas palavras que têm vizinhos muito semelhantes (ou seja, o contexto de uso é aproximadamente o mesmo), então essas palavras são provavelmente muito semelhantes em significado ou pelo menos altamente relacionadas. Por exemplo, as palavras em inglês `shocked`,` appalled` e `astonished` são tipicamente usadas em um contexto similar.\n",
    "\n",
    "A implementação do Gensim é baseada no artigo [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) e foi extendido com funcionalidades novas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports e logging\n",
    "\n",
    "Primeiro, começamos com os imports e o logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports necessários para configurar o logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Em seguida, manipularemos nosso conjunto de dados. O segredo para fazer o Word2Vec funcionar é ter muitos dados no formato de texto. Neste caso, uma boa base de dados pode ser encontrada no seguinte link: [OpinRank] (http://kavita-ganesan.com/entity-ranking-data/). Este conjunto de dados tem avaliações completas de usuários de carros e hotéis. Eu concatenei especificamente todas as avaliações de hotéis em um arquivo grande que é de cerca de 97MB comprimido e 229MB não compactado. Vamos usar o arquivo compactado. Cada linha neste arquivo representa uma resenha do hotel. Você pode fazer o download do conjunto de dados do Word2Vec do OpinRank aqui.\n",
    "\n",
    "Agora, vamos dar uma olhada mais de perto nesses dados, imprimindo a primeira linha. Você pode ver que esta é uma revisão bastante robusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file = \"../data/reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open ('../data/reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler os arquivos dentro de listas\n",
    "Agora que tivemos uma ideia do nosso conjunto de dados, podemos lê-lo em uma lista para que possamos passar isso para o modelo Word2Vec. Observe no código abaixo, que estou lendo diretamente o arquivo compactado. Também estamos fazendo um pré-processamento moderado das revisões usando `gensim.utils.simple_preprocess (line)`. Isso faz um pré-processamento básico, como tokenização, letras minúsculas, etc, e retorna uma lista de tokens (palavras). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:26:16,810 : INFO : lendo arquivo ../data/reviews_data.txt.gz...esse processo pode demorar\n",
      "2019-09-11 15:26:16,812 : INFO : lido 0 revisoes\n",
      "2019-09-11 15:26:18,580 : INFO : lido 10000 revisoes\n",
      "2019-09-11 15:26:20,085 : INFO : lido 20000 revisoes\n",
      "2019-09-11 15:26:21,789 : INFO : lido 30000 revisoes\n",
      "2019-09-11 15:26:23,446 : INFO : lido 40000 revisoes\n",
      "2019-09-11 15:26:25,204 : INFO : lido 50000 revisoes\n",
      "2019-09-11 15:26:27,363 : INFO : lido 60000 revisoes\n",
      "2019-09-11 15:26:28,979 : INFO : lido 70000 revisoes\n",
      "2019-09-11 15:26:30,683 : INFO : lido 80000 revisoes\n",
      "2019-09-11 15:26:32,540 : INFO : lido 90000 revisoes\n",
      "2019-09-11 15:26:34,084 : INFO : lido 100000 revisoes\n",
      "2019-09-11 15:26:35,938 : INFO : lido 110000 revisoes\n",
      "2019-09-11 15:26:37,289 : INFO : lido 120000 revisoes\n",
      "2019-09-11 15:26:38,634 : INFO : lido 130000 revisoes\n",
      "2019-09-11 15:26:40,343 : INFO : lido 140000 revisoes\n",
      "2019-09-11 15:26:42,207 : INFO : lido 150000 revisoes\n",
      "2019-09-11 15:26:44,116 : INFO : lido 160000 revisoes\n",
      "2019-09-11 15:26:45,472 : INFO : lido 170000 revisoes\n",
      "2019-09-11 15:26:46,920 : INFO : lido 180000 revisoes\n",
      "2019-09-11 15:26:48,376 : INFO : lido 190000 revisoes\n",
      "2019-09-11 15:26:49,918 : INFO : lido 200000 revisoes\n",
      "2019-09-11 15:26:51,553 : INFO : lido 210000 revisoes\n",
      "2019-09-11 15:26:53,211 : INFO : lido 220000 revisoes\n",
      "2019-09-11 15:26:54,712 : INFO : lido 230000 revisoes\n",
      "2019-09-11 15:26:56,289 : INFO : lido 240000 revisoes\n",
      "2019-09-11 15:26:58,555 : INFO : lido 250000 revisoes\n",
      "2019-09-11 15:26:59,298 : INFO : Terminado de ler os arquivos\n"
     ]
    }
   ],
   "source": [
    "def read_input(input_file):\n",
    "    \"\"\"Esse método lê o arquivo de entrada no formato gzip\"\"\"\n",
    "    \n",
    "    logging.info(\"lendo arquivo {0}...esse processo pode demorar\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"lido {0} revisoes\".format (i))\n",
    "            # feito alguns pre-processamentos e retorna uma lista de palavras\n",
    "            # para cada revisão no formato texto\n",
    "            yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "# ler uma revisão tokenizada em uma lista\n",
    "# cada revisão se torna um série de palavras \n",
    "# então isso se torna uma lista de listas\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Terminado de ler os arquivos\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do modelo Word2Vec\n",
    "\n",
    "Treinar o modelo é bastante simples. Você apenas instancia o Word2Vec e passa os comentários que lemos na etapa anterior (os `documentos`). Então, estamos essencialmente passando uma lista de listas. Onde cada lista na lista principal contém um conjunto de tokens de uma revisão do usuário. O Word2Vec usa todos esses tokens para criar internamente um vocabulário. E por vocabulário, quero dizer um conjunto de palavras únicas.\n",
    "\n",
    "Depois de construir o vocabulário, só precisamos chamar `train(...)` para começar a treinar o modelo Word2Vec. O treinamento no conjunto de dados [OpinRank] (http://kavita-ganesan.com/entity-ranking-data/) leva cerca de 10 minutos, portanto, seja paciente ao executar seu código neste conjunto de dados.\n",
    "\n",
    "Nos bastidores, na verdade, estamos treinando uma rede neural simples com uma única camada oculta. Mas, na verdade, não vamos usar a rede neural após o treinamento. Em vez disso, o objetivo é aprender os pesos da camada oculta. Esses pesos são essencialmente os vetores de palavras que estamos tentando aprender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:26:59,302 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-09-11 15:26:59,304 : INFO : collecting all words and their counts\n",
      "2019-09-11 15:26:59,305 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-11 15:26:59,532 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2019-09-11 15:26:59,751 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2019-09-11 15:27:00,008 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2019-09-11 15:27:00,251 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2019-09-11 15:27:00,520 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2019-09-11 15:27:00,783 : INFO : PROGRESS: at sentence #60000, processed 11013726 words, keeping 76786 word types\n",
      "2019-09-11 15:27:01,004 : INFO : PROGRESS: at sentence #70000, processed 12637528 words, keeping 83199 word types\n",
      "2019-09-11 15:27:01,213 : INFO : PROGRESS: at sentence #80000, processed 14099754 words, keeping 88459 word types\n",
      "2019-09-11 15:27:01,431 : INFO : PROGRESS: at sentence #90000, processed 15662152 words, keeping 93357 word types\n",
      "2019-09-11 15:27:01,641 : INFO : PROGRESS: at sentence #100000, processed 17164490 words, keeping 97886 word types\n",
      "2019-09-11 15:27:01,847 : INFO : PROGRESS: at sentence #110000, processed 18652295 words, keeping 102132 word types\n",
      "2019-09-11 15:27:02,055 : INFO : PROGRESS: at sentence #120000, processed 20152532 words, keeping 105923 word types\n",
      "2019-09-11 15:27:02,264 : INFO : PROGRESS: at sentence #130000, processed 21684333 words, keeping 110104 word types\n",
      "2019-09-11 15:27:02,483 : INFO : PROGRESS: at sentence #140000, processed 23330209 words, keeping 114108 word types\n",
      "2019-09-11 15:27:02,692 : INFO : PROGRESS: at sentence #150000, processed 24838757 words, keeping 118174 word types\n",
      "2019-09-11 15:27:02,903 : INFO : PROGRESS: at sentence #160000, processed 26390913 words, keeping 118670 word types\n",
      "2019-09-11 15:27:03,111 : INFO : PROGRESS: at sentence #170000, processed 27913919 words, keeping 123356 word types\n",
      "2019-09-11 15:27:03,339 : INFO : PROGRESS: at sentence #180000, processed 29535615 words, keeping 126748 word types\n",
      "2019-09-11 15:27:03,553 : INFO : PROGRESS: at sentence #190000, processed 31096462 words, keeping 129847 word types\n",
      "2019-09-11 15:27:03,790 : INFO : PROGRESS: at sentence #200000, processed 32805274 words, keeping 133255 word types\n",
      "2019-09-11 15:27:04,010 : INFO : PROGRESS: at sentence #210000, processed 34434201 words, keeping 136364 word types\n",
      "2019-09-11 15:27:04,235 : INFO : PROGRESS: at sentence #220000, processed 36083485 words, keeping 139418 word types\n",
      "2019-09-11 15:27:04,443 : INFO : PROGRESS: at sentence #230000, processed 37571765 words, keeping 142399 word types\n",
      "2019-09-11 15:27:04,674 : INFO : PROGRESS: at sentence #240000, processed 39138193 words, keeping 145232 word types\n",
      "2019-09-11 15:27:04,890 : INFO : PROGRESS: at sentence #250000, processed 40695052 words, keeping 147966 word types\n",
      "2019-09-11 15:27:05,009 : INFO : collected 150059 word types from a corpus of 41519358 raw words and 255404 sentences\n",
      "2019-09-11 15:27:05,010 : INFO : Loading a fresh vocabulary\n",
      "2019-09-11 15:27:05,155 : INFO : effective_min_count=2 retains 70537 unique words (47% of original 150059, drops 79522)\n",
      "2019-09-11 15:27:05,155 : INFO : effective_min_count=2 leaves 41439836 word corpus (99% of original 41519358, drops 79522)\n",
      "2019-09-11 15:27:05,311 : INFO : deleting the raw counts dictionary of 150059 items\n",
      "2019-09-11 15:27:05,316 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2019-09-11 15:27:05,317 : INFO : downsampling leaves estimated 30349251 word corpus (73.2% of prior 41439836)\n",
      "2019-09-11 15:27:05,563 : INFO : estimated required memory for 70537 words and 150 dimensions: 119912900 bytes\n",
      "2019-09-11 15:27:05,563 : INFO : resetting layer weights\n",
      "2019-09-11 15:27:06,191 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-09-11 15:27:07,209 : INFO : EPOCH 1 - PROGRESS: at 3.65% examples, 1118772 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:27:08,216 : INFO : EPOCH 1 - PROGRESS: at 7.20% examples, 1099134 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:27:09,223 : INFO : EPOCH 1 - PROGRESS: at 10.38% examples, 1096864 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:27:10,227 : INFO : EPOCH 1 - PROGRESS: at 13.45% examples, 1096724 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:27:11,237 : INFO : EPOCH 1 - PROGRESS: at 16.53% examples, 1091553 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-11 15:27:12,240 : INFO : EPOCH 1 - PROGRESS: at 19.48% examples, 1094485 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:13,242 : INFO : EPOCH 1 - PROGRESS: at 22.62% examples, 1094617 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:14,242 : INFO : EPOCH 1 - PROGRESS: at 25.77% examples, 1093697 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:15,261 : INFO : EPOCH 1 - PROGRESS: at 28.62% examples, 1056001 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-11 15:27:16,274 : INFO : EPOCH 1 - PROGRESS: at 31.11% examples, 1017966 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:27:17,274 : INFO : EPOCH 1 - PROGRESS: at 33.37% examples, 983225 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:18,280 : INFO : EPOCH 1 - PROGRESS: at 35.97% examples, 964845 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:19,292 : INFO : EPOCH 1 - PROGRESS: at 39.34% examples, 962254 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:27:20,296 : INFO : EPOCH 1 - PROGRESS: at 42.41% examples, 953973 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:21,299 : INFO : EPOCH 1 - PROGRESS: at 46.33% examples, 962296 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:27:22,302 : INFO : EPOCH 1 - PROGRESS: at 49.88% examples, 966262 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:27:23,303 : INFO : EPOCH 1 - PROGRESS: at 53.07% examples, 966477 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:27:24,303 : INFO : EPOCH 1 - PROGRESS: at 56.57% examples, 968188 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:25,318 : INFO : EPOCH 1 - PROGRESS: at 60.25% examples, 972751 words/s, in_qsize 20, out_qsize 5\n",
      "2019-09-11 15:27:26,318 : INFO : EPOCH 1 - PROGRESS: at 63.93% examples, 975405 words/s, in_qsize 16, out_qsize 2\n",
      "2019-09-11 15:27:27,325 : INFO : EPOCH 1 - PROGRESS: at 67.10% examples, 973423 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:28,327 : INFO : EPOCH 1 - PROGRESS: at 70.33% examples, 973899 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:27:29,341 : INFO : EPOCH 1 - PROGRESS: at 73.88% examples, 975516 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:30,352 : INFO : EPOCH 1 - PROGRESS: at 77.37% examples, 980541 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:31,366 : INFO : EPOCH 1 - PROGRESS: at 80.94% examples, 985028 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:32,373 : INFO : EPOCH 1 - PROGRESS: at 84.45% examples, 987837 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:33,373 : INFO : EPOCH 1 - PROGRESS: at 88.16% examples, 990953 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:34,374 : INFO : EPOCH 1 - PROGRESS: at 91.46% examples, 988867 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:35,381 : INFO : EPOCH 1 - PROGRESS: at 94.38% examples, 984182 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:36,382 : INFO : EPOCH 1 - PROGRESS: at 97.47% examples, 981141 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:27:37,162 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:27:37,170 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:27:37,183 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:27:37,189 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:27:37,190 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:27:37,202 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:27:37,203 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:27:37,214 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:27:37,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:27:37,218 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:27:37,219 : INFO : EPOCH - 1 : training on 41519358 raw words (30349153 effective words) took 31.0s, 978295 effective words/s\n",
      "2019-09-11 15:27:38,247 : INFO : EPOCH 2 - PROGRESS: at 2.79% examples, 853770 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:39,248 : INFO : EPOCH 2 - PROGRESS: at 5.75% examples, 876962 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:40,249 : INFO : EPOCH 2 - PROGRESS: at 8.89% examples, 915126 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:41,260 : INFO : EPOCH 2 - PROGRESS: at 11.42% examples, 917371 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:42,264 : INFO : EPOCH 2 - PROGRESS: at 14.05% examples, 921589 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:27:43,280 : INFO : EPOCH 2 - PROGRESS: at 16.90% examples, 929964 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:44,287 : INFO : EPOCH 2 - PROGRESS: at 19.26% examples, 923453 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:45,292 : INFO : EPOCH 2 - PROGRESS: at 21.56% examples, 905044 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:46,317 : INFO : EPOCH 2 - PROGRESS: at 24.13% examples, 913020 words/s, in_qsize 18, out_qsize 2\n",
      "2019-09-11 15:27:47,329 : INFO : EPOCH 2 - PROGRESS: at 28.12% examples, 932368 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:48,348 : INFO : EPOCH 2 - PROGRESS: at 32.22% examples, 949304 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:27:49,356 : INFO : EPOCH 2 - PROGRESS: at 35.44% examples, 948487 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:27:50,382 : INFO : EPOCH 2 - PROGRESS: at 39.06% examples, 951752 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:51,393 : INFO : EPOCH 2 - PROGRESS: at 42.12% examples, 942852 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:52,404 : INFO : EPOCH 2 - PROGRESS: at 45.74% examples, 946015 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:27:53,415 : INFO : EPOCH 2 - PROGRESS: at 49.64% examples, 956787 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:54,418 : INFO : EPOCH 2 - PROGRESS: at 53.29% examples, 965294 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:27:55,420 : INFO : EPOCH 2 - PROGRESS: at 57.25% examples, 973804 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:56,421 : INFO : EPOCH 2 - PROGRESS: at 61.02% examples, 980380 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:57,426 : INFO : EPOCH 2 - PROGRESS: at 64.89% examples, 984106 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:58,426 : INFO : EPOCH 2 - PROGRESS: at 68.13% examples, 984085 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:27:59,439 : INFO : EPOCH 2 - PROGRESS: at 71.61% examples, 987576 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:00,447 : INFO : EPOCH 2 - PROGRESS: at 75.42% examples, 992828 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:01,448 : INFO : EPOCH 2 - PROGRESS: at 78.90% examples, 997773 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:02,451 : INFO : EPOCH 2 - PROGRESS: at 82.46% examples, 1000626 words/s, in_qsize 16, out_qsize 3\n",
      "2019-09-11 15:28:03,458 : INFO : EPOCH 2 - PROGRESS: at 86.02% examples, 1004120 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:04,478 : INFO : EPOCH 2 - PROGRESS: at 89.79% examples, 1005233 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-11 15:28:05,479 : INFO : EPOCH 2 - PROGRESS: at 93.17% examples, 1004587 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:06,491 : INFO : EPOCH 2 - PROGRESS: at 96.68% examples, 1004623 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:07,392 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:28:07,398 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:28:07,412 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:28:07,418 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:28:07,419 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:28:07,428 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:28:07,430 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:28:07,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:28:07,449 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:28:07,453 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:28:07,453 : INFO : EPOCH - 2 : training on 41519358 raw words (30349455 effective words) took 30.2s, 1004006 effective words/s\n",
      "2019-09-11 15:28:08,474 : INFO : EPOCH 3 - PROGRESS: at 3.38% examples, 1037986 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:09,479 : INFO : EPOCH 3 - PROGRESS: at 6.77% examples, 1031606 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:10,486 : INFO : EPOCH 3 - PROGRESS: at 9.62% examples, 996964 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:28:11,488 : INFO : EPOCH 3 - PROGRESS: at 12.10% examples, 986199 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:12,499 : INFO : EPOCH 3 - PROGRESS: at 15.02% examples, 988415 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:13,513 : INFO : EPOCH 3 - PROGRESS: at 18.05% examples, 1001453 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:14,519 : INFO : EPOCH 3 - PROGRESS: at 19.71% examples, 949026 words/s, in_qsize 19, out_qsize 2\n",
      "2019-09-11 15:28:15,535 : INFO : EPOCH 3 - PROGRESS: at 21.73% examples, 911969 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:16,568 : INFO : EPOCH 3 - PROGRESS: at 23.25% examples, 873342 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:28:17,568 : INFO : EPOCH 3 - PROGRESS: at 25.43% examples, 860848 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:18,593 : INFO : EPOCH 3 - PROGRESS: at 28.76% examples, 862792 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:28:19,611 : INFO : EPOCH 3 - PROGRESS: at 32.09% examples, 865756 words/s, in_qsize 15, out_qsize 4\n",
      "2019-09-11 15:28:20,623 : INFO : EPOCH 3 - PROGRESS: at 34.91% examples, 862894 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:21,628 : INFO : EPOCH 3 - PROGRESS: at 38.27% examples, 868270 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:22,668 : INFO : EPOCH 3 - PROGRESS: at 41.62% examples, 869110 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:23,678 : INFO : EPOCH 3 - PROGRESS: at 44.70% examples, 867369 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:24,693 : INFO : EPOCH 3 - PROGRESS: at 47.85% examples, 868998 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:28:25,698 : INFO : EPOCH 3 - PROGRESS: at 50.92% examples, 869291 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:26,699 : INFO : EPOCH 3 - PROGRESS: at 53.91% examples, 871884 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:27,721 : INFO : EPOCH 3 - PROGRESS: at 57.36% examples, 876119 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:28:28,739 : INFO : EPOCH 3 - PROGRESS: at 59.19% examples, 859242 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:29,757 : INFO : EPOCH 3 - PROGRESS: at 61.61% examples, 851902 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:30,769 : INFO : EPOCH 3 - PROGRESS: at 64.98% examples, 853890 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:31,769 : INFO : EPOCH 3 - PROGRESS: at 67.48% examples, 850330 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:32,781 : INFO : EPOCH 3 - PROGRESS: at 69.79% examples, 843922 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:28:33,801 : INFO : EPOCH 3 - PROGRESS: at 71.97% examples, 837263 words/s, in_qsize 20, out_qsize 3\n",
      "2019-09-11 15:28:34,809 : INFO : EPOCH 3 - PROGRESS: at 75.05% examples, 838495 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:35,827 : INFO : EPOCH 3 - PROGRESS: at 77.42% examples, 835315 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:28:36,875 : INFO : EPOCH 3 - PROGRESS: at 79.97% examples, 832472 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:28:37,876 : INFO : EPOCH 3 - PROGRESS: at 81.90% examples, 824258 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:38,879 : INFO : EPOCH 3 - PROGRESS: at 84.06% examples, 818819 words/s, in_qsize 16, out_qsize 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:28:39,893 : INFO : EPOCH 3 - PROGRESS: at 86.89% examples, 819351 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:28:40,898 : INFO : EPOCH 3 - PROGRESS: at 90.04% examples, 821057 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:41,910 : INFO : EPOCH 3 - PROGRESS: at 93.24% examples, 824392 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:42,926 : INFO : EPOCH 3 - PROGRESS: at 96.48% examples, 827059 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:43,928 : INFO : EPOCH 3 - PROGRESS: at 99.33% examples, 826843 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:44,062 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:28:44,075 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:28:44,087 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:28:44,096 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:28:44,102 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:28:44,108 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:28:44,113 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:28:44,117 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:28:44,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:28:44,131 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:28:44,133 : INFO : EPOCH - 3 : training on 41519358 raw words (30344452 effective words) took 36.7s, 827418 effective words/s\n",
      "2019-09-11 15:28:45,166 : INFO : EPOCH 4 - PROGRESS: at 3.05% examples, 921685 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:46,180 : INFO : EPOCH 4 - PROGRESS: at 5.97% examples, 905004 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:47,194 : INFO : EPOCH 4 - PROGRESS: at 8.86% examples, 901119 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:48,194 : INFO : EPOCH 4 - PROGRESS: at 11.45% examples, 916372 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:28:49,195 : INFO : EPOCH 4 - PROGRESS: at 13.77% examples, 898706 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:50,202 : INFO : EPOCH 4 - PROGRESS: at 16.60% examples, 912336 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:28:51,249 : INFO : EPOCH 4 - PROGRESS: at 19.31% examples, 920337 words/s, in_qsize 16, out_qsize 3\n",
      "2019-09-11 15:28:52,259 : INFO : EPOCH 4 - PROGRESS: at 22.25% examples, 931064 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:53,261 : INFO : EPOCH 4 - PROGRESS: at 24.69% examples, 932966 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:54,276 : INFO : EPOCH 4 - PROGRESS: at 28.34% examples, 935786 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:55,286 : INFO : EPOCH 4 - PROGRESS: at 31.97% examples, 940235 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:56,298 : INFO : EPOCH 4 - PROGRESS: at 35.37% examples, 945117 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:57,300 : INFO : EPOCH 4 - PROGRESS: at 38.88% examples, 948092 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:58,306 : INFO : EPOCH 4 - PROGRESS: at 42.50% examples, 951499 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:28:59,326 : INFO : EPOCH 4 - PROGRESS: at 46.20% examples, 954108 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:29:00,329 : INFO : EPOCH 4 - PROGRESS: at 49.61% examples, 956382 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:01,337 : INFO : EPOCH 4 - PROGRESS: at 52.87% examples, 957137 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:02,345 : INFO : EPOCH 4 - PROGRESS: at 56.38% examples, 959740 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:03,347 : INFO : EPOCH 4 - PROGRESS: at 59.77% examples, 960832 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:04,363 : INFO : EPOCH 4 - PROGRESS: at 63.26% examples, 962344 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:05,367 : INFO : EPOCH 4 - PROGRESS: at 66.70% examples, 963507 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-11 15:29:06,384 : INFO : EPOCH 4 - PROGRESS: at 70.00% examples, 964423 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:07,392 : INFO : EPOCH 4 - PROGRESS: at 73.36% examples, 964802 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:08,406 : INFO : EPOCH 4 - PROGRESS: at 76.54% examples, 965435 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:09,411 : INFO : EPOCH 4 - PROGRESS: at 79.78% examples, 966629 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:10,427 : INFO : EPOCH 4 - PROGRESS: at 83.10% examples, 967332 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:11,435 : INFO : EPOCH 4 - PROGRESS: at 86.35% examples, 968190 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:12,443 : INFO : EPOCH 4 - PROGRESS: at 89.94% examples, 969192 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:13,451 : INFO : EPOCH 4 - PROGRESS: at 93.32% examples, 969815 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:29:14,458 : INFO : EPOCH 4 - PROGRESS: at 96.73% examples, 970253 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:15,357 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:29:15,368 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:29:15,377 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:29:15,379 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:29:15,383 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:29:15,386 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:29:15,393 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:29:15,396 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:29:15,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:29:15,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:29:15,412 : INFO : EPOCH - 4 : training on 41519358 raw words (30349302 effective words) took 31.3s, 970476 effective words/s\n",
      "2019-09-11 15:29:16,423 : INFO : EPOCH 5 - PROGRESS: at 3.10% examples, 955972 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:17,432 : INFO : EPOCH 5 - PROGRESS: at 6.66% examples, 1020912 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:18,439 : INFO : EPOCH 5 - PROGRESS: at 9.69% examples, 1006410 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:19,442 : INFO : EPOCH 5 - PROGRESS: at 12.09% examples, 985955 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:20,450 : INFO : EPOCH 5 - PROGRESS: at 14.96% examples, 986103 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:21,457 : INFO : EPOCH 5 - PROGRESS: at 17.76% examples, 988783 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:22,465 : INFO : EPOCH 5 - PROGRESS: at 20.30% examples, 983466 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:23,468 : INFO : EPOCH 5 - PROGRESS: at 23.08% examples, 980490 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:24,470 : INFO : EPOCH 5 - PROGRESS: at 26.08% examples, 981704 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:25,480 : INFO : EPOCH 5 - PROGRESS: at 29.63% examples, 979197 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:26,489 : INFO : EPOCH 5 - PROGRESS: at 33.12% examples, 977190 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:27,502 : INFO : EPOCH 5 - PROGRESS: at 36.17% examples, 968926 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:28,502 : INFO : EPOCH 5 - PROGRESS: at 39.51% examples, 967491 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:29:29,510 : INFO : EPOCH 5 - PROGRESS: at 42.87% examples, 964229 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:30,512 : INFO : EPOCH 5 - PROGRESS: at 46.48% examples, 965727 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:31,512 : INFO : EPOCH 5 - PROGRESS: at 49.84% examples, 966045 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:32,529 : INFO : EPOCH 5 - PROGRESS: at 53.05% examples, 965782 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:33,534 : INFO : EPOCH 5 - PROGRESS: at 56.54% examples, 967249 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:34,534 : INFO : EPOCH 5 - PROGRESS: at 60.05% examples, 969965 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:29:35,546 : INFO : EPOCH 5 - PROGRESS: at 63.55% examples, 970482 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:36,559 : INFO : EPOCH 5 - PROGRESS: at 66.94% examples, 970783 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:37,588 : INFO : EPOCH 5 - PROGRESS: at 70.23% examples, 970857 words/s, in_qsize 16, out_qsize 3\n",
      "2019-09-11 15:29:38,591 : INFO : EPOCH 5 - PROGRESS: at 73.72% examples, 972109 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:39,598 : INFO : EPOCH 5 - PROGRESS: at 76.89% examples, 973055 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:40,601 : INFO : EPOCH 5 - PROGRESS: at 80.04% examples, 973432 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:41,608 : INFO : EPOCH 5 - PROGRESS: at 83.29% examples, 973133 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:29:42,610 : INFO : EPOCH 5 - PROGRESS: at 86.46% examples, 973202 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:43,610 : INFO : EPOCH 5 - PROGRESS: at 90.05% examples, 974014 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:44,626 : INFO : EPOCH 5 - PROGRESS: at 93.36% examples, 973511 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:29:45,631 : INFO : EPOCH 5 - PROGRESS: at 96.79% examples, 974103 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:46,507 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:29:46,517 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:29:46,522 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:29:46,528 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:29:46,529 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:29:46,538 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:29:46,539 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:29:46,539 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:29:46,541 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:29:46,545 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:29:46,546 : INFO : EPOCH - 5 : training on 41519358 raw words (30347904 effective words) took 31.1s, 974961 effective words/s\n",
      "2019-09-11 15:29:46,547 : INFO : training on a 207596790 raw words (151740266 effective words) took 160.4s, 946277 effective words/s\n",
      "2019-09-11 15:29:46,548 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-09-11 15:29:46,548 : INFO : training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-09-11 15:29:47,575 : INFO : EPOCH 1 - PROGRESS: at 3.16% examples, 961197 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:48,578 : INFO : EPOCH 1 - PROGRESS: at 6.30% examples, 961720 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:29:49,582 : INFO : EPOCH 1 - PROGRESS: at 9.39% examples, 968513 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-11 15:29:50,589 : INFO : EPOCH 1 - PROGRESS: at 12.00% examples, 974435 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:29:51,595 : INFO : EPOCH 1 - PROGRESS: at 14.87% examples, 978309 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:52,613 : INFO : EPOCH 1 - PROGRESS: at 17.68% examples, 979559 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:53,623 : INFO : EPOCH 1 - PROGRESS: at 20.28% examples, 979296 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:54,626 : INFO : EPOCH 1 - PROGRESS: at 23.16% examples, 981352 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:29:55,627 : INFO : EPOCH 1 - PROGRESS: at 26.21% examples, 982535 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:29:56,631 : INFO : EPOCH 1 - PROGRESS: at 29.77% examples, 981212 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:57,642 : INFO : EPOCH 1 - PROGRESS: at 33.35% examples, 981537 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:58,651 : INFO : EPOCH 1 - PROGRESS: at 36.75% examples, 981538 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:29:59,660 : INFO : EPOCH 1 - PROGRESS: at 40.27% examples, 981827 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:30:00,675 : INFO : EPOCH 1 - PROGRESS: at 43.96% examples, 982683 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:30:01,689 : INFO : EPOCH 1 - PROGRESS: at 47.47% examples, 982926 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:02,694 : INFO : EPOCH 1 - PROGRESS: at 50.98% examples, 983354 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:30:03,703 : INFO : EPOCH 1 - PROGRESS: at 54.22% examples, 983813 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:04,712 : INFO : EPOCH 1 - PROGRESS: at 57.70% examples, 983328 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:05,713 : INFO : EPOCH 1 - PROGRESS: at 61.10% examples, 983312 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:06,735 : INFO : EPOCH 1 - PROGRESS: at 64.67% examples, 981853 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:07,738 : INFO : EPOCH 1 - PROGRESS: at 68.41% examples, 988879 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:08,740 : INFO : EPOCH 1 - PROGRESS: at 72.05% examples, 994887 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:09,748 : INFO : EPOCH 1 - PROGRESS: at 75.79% examples, 999184 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:10,751 : INFO : EPOCH 1 - PROGRESS: at 78.99% examples, 999929 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:11,769 : INFO : EPOCH 1 - PROGRESS: at 82.21% examples, 998138 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:12,778 : INFO : EPOCH 1 - PROGRESS: at 85.48% examples, 998645 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:13,780 : INFO : EPOCH 1 - PROGRESS: at 89.10% examples, 998733 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:14,781 : INFO : EPOCH 1 - PROGRESS: at 92.85% examples, 1001684 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:15,791 : INFO : EPOCH 1 - PROGRESS: at 96.71% examples, 1005856 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:16,564 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:30:16,570 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:30:16,582 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:30:16,590 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:30:16,592 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:30:16,593 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:30:16,601 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:30:16,603 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:30:16,606 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:30:16,616 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:30:16,617 : INFO : EPOCH - 1 : training on 41519358 raw words (30348337 effective words) took 30.1s, 1009488 effective words/s\n",
      "2019-09-11 15:30:17,631 : INFO : EPOCH 2 - PROGRESS: at 3.57% examples, 1102026 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:18,632 : INFO : EPOCH 2 - PROGRESS: at 7.20% examples, 1105271 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:19,643 : INFO : EPOCH 2 - PROGRESS: at 10.45% examples, 1106489 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:30:20,668 : INFO : EPOCH 2 - PROGRESS: at 13.55% examples, 1102111 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:30:21,669 : INFO : EPOCH 2 - PROGRESS: at 16.72% examples, 1104910 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:22,681 : INFO : EPOCH 2 - PROGRESS: at 19.71% examples, 1106400 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:30:23,686 : INFO : EPOCH 2 - PROGRESS: at 22.95% examples, 1108388 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:24,692 : INFO : EPOCH 2 - PROGRESS: at 26.36% examples, 1109344 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:25,695 : INFO : EPOCH 2 - PROGRESS: at 30.31% examples, 1108424 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-11 15:30:26,701 : INFO : EPOCH 2 - PROGRESS: at 34.33% examples, 1109512 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:27,706 : INFO : EPOCH 2 - PROGRESS: at 38.26% examples, 1110280 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:30:28,718 : INFO : EPOCH 2 - PROGRESS: at 42.28% examples, 1108503 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:29,723 : INFO : EPOCH 2 - PROGRESS: at 46.35% examples, 1109981 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:30:30,727 : INFO : EPOCH 2 - PROGRESS: at 50.15% examples, 1108579 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:31,728 : INFO : EPOCH 2 - PROGRESS: at 53.75% examples, 1107968 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-11 15:30:32,729 : INFO : EPOCH 2 - PROGRESS: at 57.72% examples, 1109157 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:33,742 : INFO : EPOCH 2 - PROGRESS: at 61.59% examples, 1109500 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:34,748 : INFO : EPOCH 2 - PROGRESS: at 65.61% examples, 1109928 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:35,768 : INFO : EPOCH 2 - PROGRESS: at 69.34% examples, 1109320 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:36,769 : INFO : EPOCH 2 - PROGRESS: at 72.96% examples, 1108271 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:37,774 : INFO : EPOCH 2 - PROGRESS: at 76.58% examples, 1107954 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:38,776 : INFO : EPOCH 2 - PROGRESS: at 80.16% examples, 1108261 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:39,789 : INFO : EPOCH 2 - PROGRESS: at 83.84% examples, 1107957 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:40,799 : INFO : EPOCH 2 - PROGRESS: at 87.68% examples, 1108082 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-11 15:30:41,802 : INFO : EPOCH 2 - PROGRESS: at 91.58% examples, 1108114 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:42,808 : INFO : EPOCH 2 - PROGRESS: at 95.43% examples, 1108502 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:43,812 : INFO : EPOCH 2 - PROGRESS: at 99.31% examples, 1108960 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:43,941 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:30:43,947 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:30:43,955 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:30:43,959 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:30:43,965 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:30:43,975 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:30:43,976 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:30:43,977 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:30:43,980 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:30:43,988 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:30:43,989 : INFO : EPOCH - 2 : training on 41519358 raw words (30350219 effective words) took 27.4s, 1109029 effective words/s\n",
      "2019-09-11 15:30:45,001 : INFO : EPOCH 3 - PROGRESS: at 3.48% examples, 1075333 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:46,002 : INFO : EPOCH 3 - PROGRESS: at 7.18% examples, 1102748 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:47,011 : INFO : EPOCH 3 - PROGRESS: at 10.41% examples, 1103060 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:48,014 : INFO : EPOCH 3 - PROGRESS: at 13.53% examples, 1106713 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:49,026 : INFO : EPOCH 3 - PROGRESS: at 16.68% examples, 1104682 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-11 15:30:50,035 : INFO : EPOCH 3 - PROGRESS: at 19.68% examples, 1106880 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:30:51,037 : INFO : EPOCH 3 - PROGRESS: at 22.90% examples, 1108185 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:52,039 : INFO : EPOCH 3 - PROGRESS: at 26.18% examples, 1107178 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:53,046 : INFO : EPOCH 3 - PROGRESS: at 30.21% examples, 1107548 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:54,046 : INFO : EPOCH 3 - PROGRESS: at 34.12% examples, 1107163 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:55,046 : INFO : EPOCH 3 - PROGRESS: at 38.04% examples, 1108101 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:56,047 : INFO : EPOCH 3 - PROGRESS: at 42.04% examples, 1106405 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:57,065 : INFO : EPOCH 3 - PROGRESS: at 46.09% examples, 1105675 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:30:58,071 : INFO : EPOCH 3 - PROGRESS: at 49.94% examples, 1106445 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:30:59,088 : INFO : EPOCH 3 - PROGRESS: at 53.62% examples, 1106186 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:31:00,090 : INFO : EPOCH 3 - PROGRESS: at 57.60% examples, 1107396 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:01,096 : INFO : EPOCH 3 - PROGRESS: at 61.43% examples, 1107508 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:02,096 : INFO : EPOCH 3 - PROGRESS: at 65.37% examples, 1106879 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:03,114 : INFO : EPOCH 3 - PROGRESS: at 69.13% examples, 1106862 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:04,116 : INFO : EPOCH 3 - PROGRESS: at 72.79% examples, 1106960 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:05,126 : INFO : EPOCH 3 - PROGRESS: at 76.42% examples, 1106821 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:06,137 : INFO : EPOCH 3 - PROGRESS: at 79.87% examples, 1104356 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:07,139 : INFO : EPOCH 3 - PROGRESS: at 83.54% examples, 1104454 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:08,142 : INFO : EPOCH 3 - PROGRESS: at 87.23% examples, 1104423 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:09,143 : INFO : EPOCH 3 - PROGRESS: at 91.20% examples, 1105015 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:10,144 : INFO : EPOCH 3 - PROGRESS: at 95.04% examples, 1105738 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:11,151 : INFO : EPOCH 3 - PROGRESS: at 98.87% examples, 1105341 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:11,388 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:31:11,392 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:31:11,402 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:31:11,420 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:31:11,422 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:31:11,425 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:31:11,426 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:31:11,428 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:31:11,443 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:31:11,444 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:31:11,444 : INFO : EPOCH - 3 : training on 41519358 raw words (30345381 effective words) took 27.4s, 1105479 effective words/s\n",
      "2019-09-11 15:31:12,450 : INFO : EPOCH 4 - PROGRESS: at 3.55% examples, 1104090 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:13,454 : INFO : EPOCH 4 - PROGRESS: at 7.22% examples, 1111853 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:14,455 : INFO : EPOCH 4 - PROGRESS: at 10.45% examples, 1112093 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:15,467 : INFO : EPOCH 4 - PROGRESS: at 13.58% examples, 1113167 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:16,475 : INFO : EPOCH 4 - PROGRESS: at 16.81% examples, 1114983 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:31:17,479 : INFO : EPOCH 4 - PROGRESS: at 19.79% examples, 1116488 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:18,482 : INFO : EPOCH 4 - PROGRESS: at 22.98% examples, 1115164 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:19,483 : INFO : EPOCH 4 - PROGRESS: at 26.42% examples, 1116139 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:20,490 : INFO : EPOCH 4 - PROGRESS: at 30.42% examples, 1115365 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:21,507 : INFO : EPOCH 4 - PROGRESS: at 34.40% examples, 1113251 words/s, in_qsize 17, out_qsize 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:31:22,533 : INFO : EPOCH 4 - PROGRESS: at 38.36% examples, 1112769 words/s, in_qsize 20, out_qsize 3\n",
      "2019-09-11 15:31:23,533 : INFO : EPOCH 4 - PROGRESS: at 42.47% examples, 1114906 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:24,542 : INFO : EPOCH 4 - PROGRESS: at 46.50% examples, 1113939 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:25,542 : INFO : EPOCH 4 - PROGRESS: at 50.32% examples, 1112966 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:26,548 : INFO : EPOCH 4 - PROGRESS: at 54.02% examples, 1113621 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:27,551 : INFO : EPOCH 4 - PROGRESS: at 57.94% examples, 1113451 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:28,562 : INFO : EPOCH 4 - PROGRESS: at 61.63% examples, 1110721 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:29,565 : INFO : EPOCH 4 - PROGRESS: at 65.46% examples, 1107760 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:31:30,582 : INFO : EPOCH 4 - PROGRESS: at 69.20% examples, 1107424 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:31,587 : INFO : EPOCH 4 - PROGRESS: at 72.96% examples, 1108681 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:32,604 : INFO : EPOCH 4 - PROGRESS: at 76.60% examples, 1108129 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:33,608 : INFO : EPOCH 4 - PROGRESS: at 80.21% examples, 1108633 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:34,608 : INFO : EPOCH 4 - PROGRESS: at 83.91% examples, 1108929 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:31:35,616 : INFO : EPOCH 4 - PROGRESS: at 87.75% examples, 1109484 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:36,621 : INFO : EPOCH 4 - PROGRESS: at 91.51% examples, 1107599 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:37,625 : INFO : EPOCH 4 - PROGRESS: at 95.30% examples, 1107575 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:38,641 : INFO : EPOCH 4 - PROGRESS: at 99.11% examples, 1106801 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:38,808 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:31:38,812 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:31:38,824 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:31:38,825 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:31:38,828 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:31:38,838 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:31:38,840 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:31:38,843 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:31:38,850 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:31:38,855 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:31:38,856 : INFO : EPOCH - 4 : training on 41519358 raw words (30350396 effective words) took 27.4s, 1107450 effective words/s\n",
      "2019-09-11 15:31:39,876 : INFO : EPOCH 5 - PROGRESS: at 3.32% examples, 1016658 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:40,882 : INFO : EPOCH 5 - PROGRESS: at 6.59% examples, 1006062 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:41,889 : INFO : EPOCH 5 - PROGRESS: at 9.89% examples, 1039430 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:42,895 : INFO : EPOCH 5 - PROGRESS: at 12.92% examples, 1056419 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:43,899 : INFO : EPOCH 5 - PROGRESS: at 16.18% examples, 1066278 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:44,905 : INFO : EPOCH 5 - PROGRESS: at 19.20% examples, 1074203 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:45,914 : INFO : EPOCH 5 - PROGRESS: at 22.35% examples, 1077901 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:46,915 : INFO : EPOCH 5 - PROGRESS: at 25.55% examples, 1084245 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:31:47,918 : INFO : EPOCH 5 - PROGRESS: at 29.44% examples, 1081345 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-11 15:31:48,918 : INFO : EPOCH 5 - PROGRESS: at 33.44% examples, 1085001 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:49,922 : INFO : EPOCH 5 - PROGRESS: at 37.14% examples, 1084480 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:50,927 : INFO : EPOCH 5 - PROGRESS: at 41.19% examples, 1086699 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:51,930 : INFO : EPOCH 5 - PROGRESS: at 45.19% examples, 1087102 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:31:52,945 : INFO : EPOCH 5 - PROGRESS: at 49.12% examples, 1088555 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:53,947 : INFO : EPOCH 5 - PROGRESS: at 52.85% examples, 1090547 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:54,954 : INFO : EPOCH 5 - PROGRESS: at 56.75% examples, 1092332 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:55,961 : INFO : EPOCH 5 - PROGRESS: at 60.59% examples, 1093241 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:31:56,967 : INFO : EPOCH 5 - PROGRESS: at 64.61% examples, 1093599 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:31:57,967 : INFO : EPOCH 5 - PROGRESS: at 68.37% examples, 1095716 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:31:58,970 : INFO : EPOCH 5 - PROGRESS: at 71.88% examples, 1095521 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-11 15:31:59,980 : INFO : EPOCH 5 - PROGRESS: at 75.80% examples, 1097389 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:32:00,988 : INFO : EPOCH 5 - PROGRESS: at 79.36% examples, 1098079 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:32:01,995 : INFO : EPOCH 5 - PROGRESS: at 83.04% examples, 1098576 words/s, in_qsize 16, out_qsize 3\n",
      "2019-09-11 15:32:02,998 : INFO : EPOCH 5 - PROGRESS: at 86.78% examples, 1099918 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:32:04,005 : INFO : EPOCH 5 - PROGRESS: at 90.78% examples, 1100452 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:05,011 : INFO : EPOCH 5 - PROGRESS: at 94.52% examples, 1100044 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:06,020 : INFO : EPOCH 5 - PROGRESS: at 98.40% examples, 1100807 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:06,367 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:32:06,369 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:32:06,382 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:32:06,388 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:32:06,403 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:32:06,407 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:32:06,408 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:32:06,414 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:32:06,415 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:32:06,417 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:32:06,418 : INFO : EPOCH - 5 : training on 41519358 raw words (30347777 effective words) took 27.6s, 1101303 effective words/s\n",
      "2019-09-11 15:32:07,442 : INFO : EPOCH 6 - PROGRESS: at 3.54% examples, 1077075 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:32:08,449 : INFO : EPOCH 6 - PROGRESS: at 7.23% examples, 1103364 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:09,449 : INFO : EPOCH 6 - PROGRESS: at 10.45% examples, 1104408 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:10,451 : INFO : EPOCH 6 - PROGRESS: at 13.55% examples, 1106459 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:11,461 : INFO : EPOCH 6 - PROGRESS: at 16.72% examples, 1106318 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:32:12,481 : INFO : EPOCH 6 - PROGRESS: at 19.68% examples, 1103900 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:32:13,485 : INFO : EPOCH 6 - PROGRESS: at 22.94% examples, 1107290 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:32:14,492 : INFO : EPOCH 6 - PROGRESS: at 26.36% examples, 1109341 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:15,492 : INFO : EPOCH 6 - PROGRESS: at 30.39% examples, 1111009 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:16,497 : INFO : EPOCH 6 - PROGRESS: at 34.23% examples, 1107673 words/s, in_qsize 20, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:32:17,506 : INFO : EPOCH 6 - PROGRESS: at 37.40% examples, 1088821 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:18,516 : INFO : EPOCH 6 - PROGRESS: at 41.33% examples, 1087263 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:19,525 : INFO : EPOCH 6 - PROGRESS: at 45.39% examples, 1088136 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:20,529 : INFO : EPOCH 6 - PROGRESS: at 49.31% examples, 1090873 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:21,530 : INFO : EPOCH 6 - PROGRESS: at 52.92% examples, 1090905 words/s, in_qsize 19, out_qsize 1\n",
      "2019-09-11 15:32:22,537 : INFO : EPOCH 6 - PROGRESS: at 56.83% examples, 1092238 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:23,539 : INFO : EPOCH 6 - PROGRESS: at 60.61% examples, 1092541 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:24,541 : INFO : EPOCH 6 - PROGRESS: at 64.61% examples, 1092784 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:25,550 : INFO : EPOCH 6 - PROGRESS: at 68.34% examples, 1094033 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:26,562 : INFO : EPOCH 6 - PROGRESS: at 71.88% examples, 1093762 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:27,580 : INFO : EPOCH 6 - PROGRESS: at 75.63% examples, 1092959 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:28,589 : INFO : EPOCH 6 - PROGRESS: at 78.99% examples, 1091491 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:29,600 : INFO : EPOCH 6 - PROGRESS: at 82.75% examples, 1092698 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:30,608 : INFO : EPOCH 6 - PROGRESS: at 86.47% examples, 1094103 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:31,632 : INFO : EPOCH 6 - PROGRESS: at 90.41% examples, 1093548 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:32,655 : INFO : EPOCH 6 - PROGRESS: at 94.35% examples, 1094621 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:33,667 : INFO : EPOCH 6 - PROGRESS: at 98.24% examples, 1095725 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:34,058 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:32:34,059 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:32:34,060 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:32:34,065 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:32:34,073 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:32:34,078 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:32:34,090 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:32:34,090 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:32:34,096 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:32:34,098 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:32:34,099 : INFO : EPOCH - 6 : training on 41519358 raw words (30346966 effective words) took 27.7s, 1096529 effective words/s\n",
      "2019-09-11 15:32:35,107 : INFO : EPOCH 7 - PROGRESS: at 3.56% examples, 1102701 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:32:36,124 : INFO : EPOCH 7 - PROGRESS: at 7.24% examples, 1107322 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:37,131 : INFO : EPOCH 7 - PROGRESS: at 10.49% examples, 1109436 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:38,139 : INFO : EPOCH 7 - PROGRESS: at 13.62% examples, 1111928 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:39,148 : INFO : EPOCH 7 - PROGRESS: at 16.75% examples, 1108227 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:40,161 : INFO : EPOCH 7 - PROGRESS: at 19.77% examples, 1110160 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:41,162 : INFO : EPOCH 7 - PROGRESS: at 22.98% examples, 1111364 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:42,164 : INFO : EPOCH 7 - PROGRESS: at 26.32% examples, 1109908 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:43,175 : INFO : EPOCH 7 - PROGRESS: at 30.42% examples, 1111737 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:32:44,181 : INFO : EPOCH 7 - PROGRESS: at 34.42% examples, 1111816 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:45,195 : INFO : EPOCH 7 - PROGRESS: at 38.30% examples, 1110244 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:46,200 : INFO : EPOCH 7 - PROGRESS: at 42.39% examples, 1111497 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:47,206 : INFO : EPOCH 7 - PROGRESS: at 46.29% examples, 1108281 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:48,206 : INFO : EPOCH 7 - PROGRESS: at 50.13% examples, 1108242 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:49,213 : INFO : EPOCH 7 - PROGRESS: at 53.75% examples, 1107651 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:50,219 : INFO : EPOCH 7 - PROGRESS: at 57.69% examples, 1108132 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:51,230 : INFO : EPOCH 7 - PROGRESS: at 61.54% examples, 1108221 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:52,230 : INFO : EPOCH 7 - PROGRESS: at 65.49% examples, 1107561 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:53,239 : INFO : EPOCH 7 - PROGRESS: at 69.19% examples, 1107310 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:54,241 : INFO : EPOCH 7 - PROGRESS: at 72.90% examples, 1107683 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:55,245 : INFO : EPOCH 7 - PROGRESS: at 76.55% examples, 1108181 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:56,265 : INFO : EPOCH 7 - PROGRESS: at 80.17% examples, 1107801 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:57,285 : INFO : EPOCH 7 - PROGRESS: at 83.86% examples, 1107176 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:32:58,289 : INFO : EPOCH 7 - PROGRESS: at 87.66% examples, 1107620 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:32:59,290 : INFO : EPOCH 7 - PROGRESS: at 91.58% examples, 1107740 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:00,293 : INFO : EPOCH 7 - PROGRESS: at 95.30% examples, 1106917 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:01,301 : INFO : EPOCH 7 - PROGRESS: at 99.16% examples, 1107048 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:01,464 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:33:01,466 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:33:01,472 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:33:01,476 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:33:01,484 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:33:01,491 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:33:01,493 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:33:01,494 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:33:01,501 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:33:01,502 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:33:01,503 : INFO : EPOCH - 7 : training on 41519358 raw words (30347841 effective words) took 27.4s, 1107681 effective words/s\n",
      "2019-09-11 15:33:02,508 : INFO : EPOCH 8 - PROGRESS: at 3.46% examples, 1075074 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:03,532 : INFO : EPOCH 8 - PROGRESS: at 7.12% examples, 1083183 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:33:04,536 : INFO : EPOCH 8 - PROGRESS: at 10.35% examples, 1094120 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:05,536 : INFO : EPOCH 8 - PROGRESS: at 13.36% examples, 1092017 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:06,554 : INFO : EPOCH 8 - PROGRESS: at 16.61% examples, 1096103 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:07,572 : INFO : EPOCH 8 - PROGRESS: at 19.61% examples, 1098053 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:08,573 : INFO : EPOCH 8 - PROGRESS: at 22.78% examples, 1097660 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:09,576 : INFO : EPOCH 8 - PROGRESS: at 26.00% examples, 1098619 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:33:10,589 : INFO : EPOCH 8 - PROGRESS: at 29.97% examples, 1095986 words/s, in_qsize 20, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:33:11,602 : INFO : EPOCH 8 - PROGRESS: at 33.86% examples, 1095432 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:12,607 : INFO : EPOCH 8 - PROGRESS: at 37.74% examples, 1095728 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:13,615 : INFO : EPOCH 8 - PROGRESS: at 41.74% examples, 1094407 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:14,621 : INFO : EPOCH 8 - PROGRESS: at 45.70% examples, 1094457 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:15,630 : INFO : EPOCH 8 - PROGRESS: at 49.55% examples, 1094831 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:16,641 : INFO : EPOCH 8 - PROGRESS: at 53.22% examples, 1095311 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:33:17,652 : INFO : EPOCH 8 - PROGRESS: at 57.15% examples, 1095743 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:33:18,658 : INFO : EPOCH 8 - PROGRESS: at 60.88% examples, 1094749 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:33:19,661 : INFO : EPOCH 8 - PROGRESS: at 64.86% examples, 1094620 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:20,661 : INFO : EPOCH 8 - PROGRESS: at 68.55% examples, 1096379 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:21,675 : INFO : EPOCH 8 - PROGRESS: at 72.20% examples, 1096711 words/s, in_qsize 20, out_qsize 2\n",
      "2019-09-11 15:33:22,680 : INFO : EPOCH 8 - PROGRESS: at 76.01% examples, 1098026 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:23,688 : INFO : EPOCH 8 - PROGRESS: at 79.55% examples, 1098114 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:24,691 : INFO : EPOCH 8 - PROGRESS: at 83.28% examples, 1099340 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:33:25,692 : INFO : EPOCH 8 - PROGRESS: at 86.91% examples, 1099343 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:26,707 : INFO : EPOCH 8 - PROGRESS: at 90.91% examples, 1099528 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:33:27,714 : INFO : EPOCH 8 - PROGRESS: at 94.60% examples, 1098559 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:28,715 : INFO : EPOCH 8 - PROGRESS: at 98.37% examples, 1098684 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:29,077 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:33:29,086 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:33:29,089 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:33:29,090 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:33:29,102 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:33:29,106 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:33:29,108 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:33:29,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:33:29,114 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:33:29,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:33:29,116 : INFO : EPOCH - 8 : training on 41519358 raw words (30349421 effective words) took 27.6s, 1099313 effective words/s\n",
      "2019-09-11 15:33:30,124 : INFO : EPOCH 9 - PROGRESS: at 3.55% examples, 1101679 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:33:31,129 : INFO : EPOCH 9 - PROGRESS: at 7.22% examples, 1110644 words/s, in_qsize 20, out_qsize 1\n",
      "2019-09-11 15:33:32,132 : INFO : EPOCH 9 - PROGRESS: at 10.47% examples, 1113070 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:33,136 : INFO : EPOCH 9 - PROGRESS: at 13.59% examples, 1114172 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:34,141 : INFO : EPOCH 9 - PROGRESS: at 16.80% examples, 1116398 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:35,144 : INFO : EPOCH 9 - PROGRESS: at 19.73% examples, 1114053 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:36,150 : INFO : EPOCH 9 - PROGRESS: at 22.93% examples, 1112749 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:37,160 : INFO : EPOCH 9 - PROGRESS: at 26.39% examples, 1114465 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:38,170 : INFO : EPOCH 9 - PROGRESS: at 30.44% examples, 1115158 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:33:39,171 : INFO : EPOCH 9 - PROGRESS: at 34.42% examples, 1114780 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:40,183 : INFO : EPOCH 9 - PROGRESS: at 38.34% examples, 1114361 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:41,197 : INFO : EPOCH 9 - PROGRESS: at 42.38% examples, 1113292 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:42,204 : INFO : EPOCH 9 - PROGRESS: at 46.29% examples, 1109798 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:43,209 : INFO : EPOCH 9 - PROGRESS: at 50.11% examples, 1108814 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:44,212 : INFO : EPOCH 9 - PROGRESS: at 53.72% examples, 1108481 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:45,218 : INFO : EPOCH 9 - PROGRESS: at 57.63% examples, 1108041 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:33:46,222 : INFO : EPOCH 9 - PROGRESS: at 61.54% examples, 1109796 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:47,225 : INFO : EPOCH 9 - PROGRESS: at 65.49% examples, 1108896 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:48,242 : INFO : EPOCH 9 - PROGRESS: at 69.25% examples, 1109227 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:49,252 : INFO : EPOCH 9 - PROGRESS: at 73.02% examples, 1109832 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:50,260 : INFO : EPOCH 9 - PROGRESS: at 76.53% examples, 1107993 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:51,262 : INFO : EPOCH 9 - PROGRESS: at 80.03% examples, 1106968 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:33:52,262 : INFO : EPOCH 9 - PROGRESS: at 83.63% examples, 1106080 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:53,271 : INFO : EPOCH 9 - PROGRESS: at 87.30% examples, 1105411 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:54,286 : INFO : EPOCH 9 - PROGRESS: at 91.31% examples, 1105664 words/s, in_qsize 20, out_qsize 3\n",
      "2019-09-11 15:33:55,286 : INFO : EPOCH 9 - PROGRESS: at 95.12% examples, 1106156 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:56,287 : INFO : EPOCH 9 - PROGRESS: at 98.78% examples, 1104384 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:33:56,553 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:33:56,561 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:33:56,568 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:33:56,569 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:33:56,572 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:33:56,579 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:33:56,586 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:33:56,589 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:33:56,592 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:33:56,595 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:33:56,595 : INFO : EPOCH - 9 : training on 41519358 raw words (30350301 effective words) took 27.5s, 1104714 effective words/s\n",
      "2019-09-11 15:33:57,603 : INFO : EPOCH 10 - PROGRESS: at 3.48% examples, 1080716 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:58,603 : INFO : EPOCH 10 - PROGRESS: at 6.91% examples, 1062518 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:33:59,609 : INFO : EPOCH 10 - PROGRESS: at 9.83% examples, 1036789 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:00,632 : INFO : EPOCH 10 - PROGRESS: at 12.59% examples, 1032295 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:01,635 : INFO : EPOCH 10 - PROGRESS: at 15.70% examples, 1031280 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:34:02,639 : INFO : EPOCH 10 - PROGRESS: at 18.39% examples, 1024365 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:03,646 : INFO : EPOCH 10 - PROGRESS: at 21.52% examples, 1034263 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:04,671 : INFO : EPOCH 10 - PROGRESS: at 24.05% examples, 1025109 words/s, in_qsize 18, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:34:05,676 : INFO : EPOCH 10 - PROGRESS: at 25.87% examples, 972801 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:06,733 : INFO : EPOCH 10 - PROGRESS: at 28.41% examples, 938351 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:34:07,746 : INFO : EPOCH 10 - PROGRESS: at 30.70% examples, 911266 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:34:08,753 : INFO : EPOCH 10 - PROGRESS: at 33.62% examples, 902758 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:09,754 : INFO : EPOCH 10 - PROGRESS: at 37.40% examples, 917571 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:34:10,756 : INFO : EPOCH 10 - PROGRESS: at 41.48% examples, 931436 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:11,771 : INFO : EPOCH 10 - PROGRESS: at 44.82% examples, 929444 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:34:12,772 : INFO : EPOCH 10 - PROGRESS: at 48.63% examples, 940115 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:13,786 : INFO : EPOCH 10 - PROGRESS: at 52.36% examples, 948237 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:34:14,787 : INFO : EPOCH 10 - PROGRESS: at 56.16% examples, 957235 words/s, in_qsize 20, out_qsize 0\n",
      "2019-09-11 15:34:15,791 : INFO : EPOCH 10 - PROGRESS: at 59.84% examples, 962943 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:16,801 : INFO : EPOCH 10 - PROGRESS: at 63.73% examples, 969261 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:17,807 : INFO : EPOCH 10 - PROGRESS: at 67.25% examples, 971952 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:34:18,808 : INFO : EPOCH 10 - PROGRESS: at 70.55% examples, 973519 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:19,829 : INFO : EPOCH 10 - PROGRESS: at 73.27% examples, 964901 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:34:20,847 : INFO : EPOCH 10 - PROGRESS: at 75.48% examples, 951746 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:21,874 : INFO : EPOCH 10 - PROGRESS: at 77.72% examples, 941795 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:34:22,884 : INFO : EPOCH 10 - PROGRESS: at 80.12% examples, 933584 words/s, in_qsize 17, out_qsize 2\n",
      "2019-09-11 15:34:23,884 : INFO : EPOCH 10 - PROGRESS: at 83.67% examples, 938675 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:24,909 : INFO : EPOCH 10 - PROGRESS: at 86.47% examples, 934879 words/s, in_qsize 18, out_qsize 1\n",
      "2019-09-11 15:34:25,913 : INFO : EPOCH 10 - PROGRESS: at 90.31% examples, 939570 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:26,914 : INFO : EPOCH 10 - PROGRESS: at 93.93% examples, 943246 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:27,915 : INFO : EPOCH 10 - PROGRESS: at 97.69% examples, 948320 words/s, in_qsize 19, out_qsize 0\n",
      "2019-09-11 15:34:28,448 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-09-11 15:34:28,450 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-09-11 15:34:28,455 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-09-11 15:34:28,463 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-09-11 15:34:28,467 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-09-11 15:34:28,473 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-09-11 15:34:28,477 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-11 15:34:28,480 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-11 15:34:28,484 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-11 15:34:28,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 15:34:28,487 : INFO : EPOCH - 10 : training on 41519358 raw words (30348812 effective words) took 31.9s, 951797 effective words/s\n",
      "2019-09-11 15:34:28,488 : INFO : training on a 415193580 raw words (303485451 effective words) took 281.9s, 1076420 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(303485451, 415193580)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos checar o output \n",
    "Este primeiro exemplo mostra um caso simples de procurar palavras semelhantes à palavra `dirty`. Tudo o que precisamos fazer aqui é chamar a função `most_similar` e fornecer a palavra` dirty` como o exemplo positivo. Isso retorna o top 10 palavras semelhantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 15:34:28,504 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.8593920469284058),\n",
       " ('stained', 0.7805181741714478),\n",
       " ('smelly', 0.7688528299331665),\n",
       " ('dusty', 0.7665583491325378),\n",
       " ('unclean', 0.763653576374054),\n",
       " ('grubby', 0.7523776292800903),\n",
       " ('gross', 0.7272483110427856),\n",
       " ('soiled', 0.7140095233917236),\n",
       " ('disgusting', 0.7074264287948608),\n",
       " ('dingy', 0.7069816589355469)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"dirty\"\n",
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso parece muito bom, certo? Vamos dar uma olhada em mais alguns. Vamos ver a similaridade de `educado`,` frança` e `chocado`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.917888343334198),\n",
       " ('friendly', 0.8240551948547363),\n",
       " ('cordial', 0.796963095664978),\n",
       " ('professional', 0.7924618721008301),\n",
       " ('attentive', 0.775162935256958),\n",
       " ('curteous', 0.7709380984306335)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos ver as 6 palavras mais similares a 'polite'\n",
    "w1 = [\"polite\"]\n",
    "model.wv.most_similar (positive=w1, topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canada', 0.6640556454658508),\n",
       " ('germany', 0.6611374616622925),\n",
       " ('spain', 0.6501389741897583),\n",
       " ('england', 0.6393054723739624),\n",
       " ('mexico', 0.5927436351776123),\n",
       " ('thailand', 0.5918599367141724)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos ver as 6 palavras mais similares a 'france'\n",
    "w1 = [\"france\"]\n",
    "model.wv.most_similar(positive=w1, topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrified', 0.8404176235198975),\n",
       " ('astonished', 0.7953061461448669),\n",
       " ('amazed', 0.7878398895263672),\n",
       " ('appalled', 0.7607062458992004),\n",
       " ('dismayed', 0.7574317455291748),\n",
       " ('stunned', 0.7563004493713379)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos ver as 6 palavras mais similares a 'france'\n",
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso é bom. Você pode até especificar vários exemplos positivos para obter coisas que estão relacionadas no contexto fornecido e fornecer exemplos negativos para dizer o que não deve ser considerado como relacionado. No exemplo abaixo, estamos pedindo todos os itens que se referem *cama* (*bed* em inglês):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duvet', 0.70943284034729),\n",
       " ('blanket', 0.6876029968261719),\n",
       " ('mattress', 0.6864297389984131),\n",
       " ('matress', 0.6831876039505005),\n",
       " ('quilt', 0.676246702671051),\n",
       " ('pillowcase', 0.6585795879364014),\n",
       " ('sheets', 0.636309027671814),\n",
       " ('pillows', 0.6242099404335022),\n",
       " ('foam', 0.6231487989425659),\n",
       " ('pillowcases', 0.6110523343086243)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# palavras relacionadas com cama\n",
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade entre duas palavras no vocabulário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode até usar o modelo Word2Vec para retornar a semelhança entre duas palavras que estão presentes no vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76885283"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similaridade de duas palavras diferentes\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similaridades de duas palavras idênticas\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26405865"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similaridade de duas palavras opostas\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debaixo dos panos, os três trechos acima calculam a semelhança de cosseno entre as duas palavras especificadas usando vetores de palavras de cada um. A partir das pontuações, faz sentido que `dirty` seja altamente similar a` smelly`, mas `dirty` é diferente de` clean`. Se você fizer uma semelhança entre duas palavras idênticas, a pontuação será 1.0, já que o intervalo da pontuação de semelhança do cosseno será sempre entre [0.0-1.0]. Você pode ler mais sobre a pontuação de semelhança de cosseno [aqui] (https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontre o estranho\n",
    "Você pode até usar o Word2Vec para encontrar itens estranhos com uma lista de itens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geanderson/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:876: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual dos items abaixo é o estranho da lista?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual dos items abaixo é o estranho da lista?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"car\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo os parâmetros que podem ser utilizados\n",
    "Para treinar o modelo anteriormente, tivemos que definir alguns parâmetros. Agora, vamos tentar entender o que alguns deles significam. Para referência, este é o comando que usamos para treinar o modelo.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec(documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `size`\n",
    "O tamanho do vetor denso para representar cada token ou palavra. Se você tiver dados muito limitados, o tamanho deverá ser um valor muito menor. Se você tiver muitos dados, é bom experimentar vários tamanhos. Um valor de 100-150 funcionou bem para o dataset treinado.\n",
    "\n",
    "### `window`\n",
    "A distância máxima entre a palavra alvo e a palavra vizinha. Se a posição do seu vizinho for maior que a largura máxima da janela à esquerda e à direita, alguns vizinhos não serão considerados como relacionados à palavra de destino. Em teoria, uma janela menor deve fornecer termos mais relacionados. Se você tiver muitos dados, o tamanho da janela não deve importar muito, desde que seja uma janela de tamanho decente. \n",
    "\n",
    "### `min_count`\n",
    "Contagem de frequência mínima de palavras. O modelo ignoraria as palavras que não statisfy o `min_count`. Palavras extremamente raras geralmente não são importantes, então é melhor livrar-se delas. A menos que seu conjunto de dados seja realmente pequeno, isso não afeta realmente o modelo.\n",
    "\n",
    "### `workers`\n",
    "Quantas threads deveríamos usar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quando usar Word2Vec?\n",
    "\n",
    "Existem muitos cenários de aplicativos para o Word2Vec. Imagine se você precisa construir um léxico de sentimento. Treinar um modelo Word2Vec em grandes quantidades de comentários de usuários ajuda você a conseguir isso. Você tem um léxico não apenas para o sentimento, mas para a maioria das palavras no vocabulário.\n",
    "\n",
    "Além dos dados de texto bruto não estruturados, você também pode usar o Word2Vec para obter dados mais estruturados. Por exemplo, se você tivesse tags para um milhão de perguntas e respostas do stackoverflow, poderia encontrar tags relacionadas a uma determinada tag e recomendar as relacionadas para exploração. Você pode fazer isso tratando cada conjunto de tags de coexistência como uma \"frase\" e treinar um modelo Word2Vec nesses dados. Concedido, você ainda precisa de um grande número de exemplos para fazê-lo funcionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
